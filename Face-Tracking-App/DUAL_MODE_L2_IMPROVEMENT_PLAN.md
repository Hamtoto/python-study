# DUAL ëª¨ë“œ L2 ì •ê·œí™” ê°œì„  ê³„íšì„œ

> **Face-Tracking-App DUAL ëª¨ë“œì˜ ì–¼êµ´ ì¸ì‹ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ L2 ì •ê·œí™” ë„ì… ê³„íš**

## ğŸ“‹ ëª©ì°¨
- [í”„ë¡œì íŠ¸ ê°œìš”](#-í”„ë¡œì íŠ¸-ê°œìš”)
- [í˜„ì¬ ìƒí™© ë¶„ì„](#-í˜„ì¬-ìƒí™©-ë¶„ì„)
- [ê°œì„  ëª©í‘œ ë° ê¸°ëŒ€íš¨ê³¼](#-ê°œì„ -ëª©í‘œ-ë°-ê¸°ëŒ€íš¨ê³¼)
- [êµ¬í˜„ ê³„íš](#-êµ¬í˜„-ê³„íš)
- [ë‹¨ê³„ë³„ ì‹¤í–‰ ë¡œë“œë§µ](#-ë‹¨ê³„ë³„-ì‹¤í–‰-ë¡œë“œë§µ)
- [í…ŒìŠ¤íŠ¸ ì „ëµ](#-í…ŒìŠ¤íŠ¸-ì „ëµ)
- [ë¦¬ìŠ¤í¬ ê´€ë¦¬](#-ë¦¬ìŠ¤í¬-ê´€ë¦¬)
- [ì„±ê³µ ì§€í‘œ](#-ì„±ê³µ-ì§€í‘œ)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
DUAL ëª¨ë“œì—ì„œ 2ëª… í™”ì êµ¬ë³„ì˜ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ L2 ì •ê·œí™”ë¥¼ ë„ì…í•˜ì—¬ ì–¼êµ´ ì„ë² ë”© ë¹„êµì˜ ì•ˆì •ì„±ê³¼ ì •ë°€ë„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.

### ë°°ê²½
- **í˜„ì¬ ë¬¸ì œ**: ì¡°ëª…/ê°ë„ ë³€í™”ì— ì·¨ì•½í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
- **DUAL ëª¨ë“œ íŠ¹ìˆ˜ì„±**: 2ëª… í™”ì êµ¬ë³„ì„ ìœ„í•œ ë†’ì€ ì •ë°€ë„ ìš”êµ¬
- **ë¹ˆë²ˆí•œ ë¹„êµ ì‘ì—…**: ê° VAD êµ¬ê°„ë§ˆë‹¤ ìƒìœ„ 2ëª… ì„ ë³„í•˜ëŠ” ë°˜ë³µì  ë¹„êµ

### ì ìš© ë²”ìœ„
- `src/face_tracker/utils/similarity.py` - í•µì‹¬ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
- `src/face_tracker/processing/selector.py` - ID ë³‘í•© ë° í™”ì ì„ íƒ ë¡œì§
- `src/face_tracker/config.py` - L2 ì •ê·œí™” ê´€ë ¨ ì„¤ì • ì¶”ê°€

---

## ğŸ” í˜„ì¬ ìƒí™© ë¶„ì„

### í˜„ì¬ DUAL ëª¨ë“œ ì–¼êµ´ ì¸ì‹ í”Œë¡œìš°
```mermaid
graph TD
    A[VAD ìŒì„± êµ¬ê°„ ì¶”ì¶œ] --> B[ê° êµ¬ê°„ë³„ í”„ë ˆì„ ë²”ìœ„ ê³„ì‚°]
    B --> C[ID ë³‘í•©: similarity_threshold=0.65]
    C --> D[êµ¬ê°„ ë‚´ face_id ë¹ˆë„ ì¹´ìš´íŠ¸]
    D --> E[ìƒìœ„ 2ëª… ì„ íƒ: speaker_a, speaker_b]
    E --> F[10ì´ˆ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±]
```

### í•µì‹¬ ë¬¸ì œì  ë¶„ì„

#### 1. **ì–¼êµ´ ë¹„êµ ì •í™•ë„ ì´ìŠˆ**
```python
# í˜„ì¬ ë°©ì‹ (selector.py:112, similarity.py:28)
similarity = F.cosine_similarity(emb1, emb2, dim=1).item()
```
- **ë¬¸ì œ**: L2 ì •ê·œí™” ì—†ëŠ” ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ë²¡í„° í¬ê¸° ì •ë³´ê°€ ë…¸ì´ì¦ˆë¡œ ì‘ìš©
- **ì˜í–¥**: ì¡°ëª…/ê°ë„ ë³€í™”ì‹œ ë™ì¼ ì¸ë¬¼ì„ ë‹¤ë¥¸ ì‚¬ëŒìœ¼ë¡œ ì¸ì‹

#### 2. **ID ë³‘í•© ë¶ˆì•ˆì •ì„±**
```python
# í˜„ì¬ DUAL ëª¨ë“œ ID ë³‘í•© (selector.py:149)
merged_timeline = TargetSelector._merge_similar_ids(id_timeline, embeddings, similarity_threshold=0.65)
```
- **ë¬¸ì œ**: ì„ê³„ê°’ 0.65ë¡œ ì ê·¹ì  ë³‘í•©í•˜ì§€ë§Œ ê¸°ë³¸ ìœ ì‚¬ë„ ê³„ì‚°ì˜ ë¶ˆì•ˆì •ì„±
- **ì˜í–¥**: ë™ì¼ ì¸ë¬¼ì´ ì—¬ëŸ¬ IDë¡œ ë¶„ì‚°ë˜ì–´ í™”ì êµ¬ë³„ ì •í™•ë„ ì €í•˜

#### 3. **DUAL ëª¨ë“œ íŠ¹ìˆ˜ ìš”êµ¬ì‚¬í•­**
- **ë¹ˆë²ˆí•œ ë¹„êµ**: ê° VAD êµ¬ê°„ë§ˆë‹¤ face_id ë¹ˆë„ ê³„ì‚°
- **ì •ë°€í•œ êµ¬ë³„**: speaker_a/speaker_bë¡œ ì •í™•í•œ ë¶„ë¦¬ í•„ìš”
- **ì•ˆì •ì„±**: ë™ì¼ ì˜ìƒì—ì„œ ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥ í•„ìš”

---

## ğŸš€ ê°œì„  ëª©í‘œ ë° ê¸°ëŒ€íš¨ê³¼

### í•µì‹¬ ê°œì„  ëª©í‘œ
1. **í™”ì ë¶„ë¦¬ ì •í™•ë„ í–¥ìƒ**: 85% â†’ 92% (ëª©í‘œ +7%p)
2. **ID ë³‘í•© ì•ˆì •ì„± ê°œì„ **: ë™ì¼ ì¸ë¬¼ì˜ ë‹¤ì¤‘ ID ë¬¸ì œ 30% ê°ì†Œ
3. **ì¡°ëª…/ê°ë„ ê°•ê±´ì„±**: ì‹¤ë‚´/ì‹¤ì™¸ ì˜ìƒì—ì„œ ì¸ì‹ë¥  40% í–¥ìƒ
4. **ì‹œìŠ¤í…œ ì¼ê´€ì„±**: ë™ì¼ ì˜ìƒ ë°˜ë³µ ì²˜ë¦¬ì‹œ ê²°ê³¼ ì¼ì¹˜ìœ¨ 95%+

### ê¸°ìˆ ì  ê¸°ëŒ€íš¨ê³¼

#### L2 ì •ê·œí™”ì˜ ìˆ˜í•™ì  ì›ë¦¬
```python
# L2 ì •ê·œí™” ì „ (í˜„ì¬)
cosine_sim = (AÂ·B) / (||A|| Ã— ||B||)

# L2 ì •ê·œí™” í›„ (ê°œì„ )  
A_norm = A / ||A||  # ëª¨ë“  ë²¡í„°ë¥¼ ë‹¨ìœ„ ë²¡í„°ë¡œ ë³€í™˜
B_norm = B / ||B||
cosine_sim = A_norm Â· B_norm  # ìˆœìˆ˜í•œ ë°©í–¥ì„±ë§Œ ë¹„êµ
```

#### ì–¼êµ´ ì¸ì‹ì—ì„œì˜ ì¥ì 
- **ë²¡í„° í¬ê¸° ì •ê·œí™”**: ì¡°ëª… ë³€í™”ë¡œ ì¸í•œ ì„ë² ë”© í¬ê¸° ë³€í™” ì œê±°
- **ë°©í–¥ì„± ì§‘ì¤‘**: ì–¼êµ´ íŠ¹ì§•ì˜ íŒ¨í„´(ë°©í–¥)ì—ë§Œ ì§‘ì¤‘í•˜ì—¬ ë³¸ì§ˆì  ìœ ì‚¬ì„± ì¸¡ì •
- **ì„ê³„ê°’ ì•ˆì •í™”**: ì •ê·œí™”ëœ ë²¡í„°ë¡œ ë” ì¼ê´€ëœ ì„ê³„ê°’ ì„¤ì • ê°€ëŠ¥

### ì„±ëŠ¥ ì˜í–¥ ìµœì†Œí™”
- **ì²˜ë¦¬ ì‹œê°„**: ê¸°ì¡´ 15-20ì´ˆ â†’ 15-21ì´ˆ (5% ë¯¸ë§Œ ì¦ê°€)
- **GPU ë©”ëª¨ë¦¬**: ì •ê·œí™” ì—°ì‚°ìœ¼ë¡œ ì¸í•œ ë¯¸ë¯¸í•œ ì¦ê°€ (<1%)
- **ì‹œìŠ¤í…œ í˜¸í™˜ì„±**: ê¸°ì¡´ SINGLE ëª¨ë“œì™€ ì™„ì „ í˜¸í™˜

---

## ğŸ› ï¸ êµ¬í˜„ ê³„íš

### Phase 1: í•µì‹¬ ìœ ì‚¬ë„ í•¨ìˆ˜ ê°œì„  (ìš°ì„ ìˆœìœ„: ìµœê³ )

#### 1.1 ìƒˆë¡œìš´ L2 ì •ê·œí™” í•¨ìˆ˜ êµ¬í˜„
```python
# similarity.py ì¶”ê°€
def find_matching_id_with_l2_normalization(emb, all_embs, threshold=SIMILARITY_THRESHOLD):
    """
    L2 ì •ê·œí™” ì ìš©ëœ ê°œì„ ëœ ìœ ì‚¬ë„ ë§¤ì¹­
    
    Args:
        emb: í˜„ì¬ ì–¼êµ´ ì„ë² ë”© (torch.Tensor)
        all_embs: ê¸°ì¡´ ì„ë² ë”©ë“¤ ë”•ì…”ë„ˆë¦¬ {track_id: embedding}
        threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: configì—ì„œ ê°€ì ¸ì˜´)
    
    Returns:
        int or None: ë§¤ì¹­ëœ track_id ë˜ëŠ” None
    """
    if not all_embs:
        return None
    
    # L2 ì •ê·œí™” ì ìš© - ë‹¨ìœ„ ë²¡í„°ë¡œ ë³€í™˜
    emb_normalized = F.normalize(emb, p=2, dim=1)
    
    best_id = None
    best_sim = 0.0
    threshold_matches = []
    
    for tid, existing_emb in all_embs.items():
        # ê¸°ì¡´ ì„ë² ë”©ë„ L2 ì •ê·œí™”
        existing_emb_normalized = F.normalize(existing_emb, p=2, dim=1)
        
        # ì •ê·œí™”ëœ ë²¡í„°ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (= ë‚´ì )
        sim = F.cosine_similarity(emb_normalized, existing_emb_normalized, dim=1).item()
        
        # ì„ê³„ê°’ ì´ìƒì¸ ëª¨ë“  í›„ë³´ ìˆ˜ì§‘
        if sim > threshold:
            threshold_matches.append((tid, sim))
            
        # ìµœê³  ìœ ì‚¬ë„ ì¶”ì 
        if sim > best_sim:
            best_sim = sim
            best_id = tid
    
    # ì„ê³„ê°’ ì´ìƒ í›„ë³´ê°€ ìˆìœ¼ë©´ ìµœê³  ìœ ì‚¬ë„ ë°˜í™˜
    if threshold_matches:
        threshold_matches.sort(key=lambda x: x[1], reverse=True)
        return threshold_matches[0][0]
    
    # ì—†ìœ¼ë©´ None ë°˜í™˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    return None

def cosine_similarity_l2_normalized(emb1, emb2):
    """
    L2 ì •ê·œí™”ëœ ë‘ ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    """
    emb1_norm = F.normalize(emb1, p=2, dim=1)
    emb2_norm = F.normalize(emb2, p=2, dim=1)
    return F.cosine_similarity(emb1_norm, emb2_norm, dim=1).item()
```

#### 1.2 ê¸°ì¡´ í•¨ìˆ˜ ì—…ë°ì´íŠ¸
```python
# similarity.py - ê¸°ì¡´ í•¨ìˆ˜ì— L2 ì˜µì…˜ ì¶”ê°€
def find_matching_id_with_best_fallback(emb, all_embs, threshold=SIMILARITY_THRESHOLD, use_l2_norm=True):
    """ê¸°ì¡´ í•¨ìˆ˜ì— L2 ì •ê·œí™” ì˜µì…˜ ì¶”ê°€"""
    if use_l2_norm:
        return find_matching_id_with_l2_normalization(emb, all_embs, threshold)
    else:
        # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
        return find_matching_id_with_best_fallback_legacy(emb, all_embs, threshold)
```

### Phase 2: TargetSelector ID ë³‘í•© ë¡œì§ ê°œì„  (ìš°ì„ ìˆœìœ„: ë†’ìŒ)

#### 2.1 L2 ì •ê·œí™” ì ìš©ëœ ID ë³‘í•©
```python
# selector.py - _merge_similar_ids í•¨ìˆ˜ ê°œì„ 
@staticmethod
def _merge_similar_ids_enhanced(id_timeline, embeddings, similarity_threshold=0.75, use_l2_norm=True):
    """
    í–¥ìƒëœ ID ë³‘í•©: L2 ì •ê·œí™” ì˜µì…˜ ì¶”ê°€
    
    Args:
        id_timeline: ì›ë³¸ ID íƒ€ì„ë¼ì¸
        embeddings: IDë³„ ì„ë² ë”© ë”•ì…”ë„ˆë¦¬
        similarity_threshold: ID ë³‘í•© ì„ê³„ê°’
        use_l2_norm: L2 ì •ê·œí™” ì‚¬ìš© ì—¬ë¶€
    """
    if not embeddings:
        return id_timeline
        
    unique_ids = list(set(tid for tid in id_timeline if tid is not None))
    if len(unique_ids) <= 1:
        return id_timeline
        
    merge_map = {}
    
    for i, id1 in enumerate(unique_ids):
        if id1 in merge_map:
            continue
            
        merge_map[id1] = id1  # ìê¸° ìì‹ ìœ¼ë¡œ ì´ˆê¸°í™”
        
        for j, id2 in enumerate(unique_ids[i+1:], i+1):
            if id2 in merge_map:
                continue
                
            # ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚° (L2 ì •ê·œí™” ì ìš©)
            if id1 in embeddings and id2 in embeddings:
                emb1 = embeddings[id1]
                emb2 = embeddings[id2]
                
                if use_l2_norm:
                    # L2 ì •ê·œí™” ì ìš©
                    emb1_norm = F.normalize(emb1, p=2, dim=1)
                    emb2_norm = F.normalize(emb2, p=2, dim=1)
                    similarity = F.cosine_similarity(emb1_norm, emb2_norm, dim=1).item()
                else:
                    # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
                    similarity = F.cosine_similarity(emb1, emb2, dim=1).item()
                
                if similarity >= similarity_threshold:
                    merge_map[id2] = id1  # id2ë¥¼ id1ë¡œ ë³‘í•©
                    logger.debug(f"ID ë³‘í•©: {id2} â†’ {id1} (ìœ ì‚¬ë„: {similarity:.3f})")
    
    # íƒ€ì„ë¼ì¸ì— ë³‘í•© ë§µ ì ìš©
    merged_timeline = []
    for tid in id_timeline:
        if tid is None:
            merged_timeline.append(None)
        else:
            merged_timeline.append(merge_map.get(tid, tid))
            
    return merged_timeline
```

#### 2.2 DUAL ëª¨ë“œ í™”ì ì„ íƒ ë¡œì§ ì—…ë°ì´íŠ¸
```python
# selector.py - select_dual_speakers í•¨ìˆ˜ ê°œì„ 
@staticmethod
def select_dual_speakers_enhanced(voice_segments, id_timeline, fps, embeddings=None, use_l2_norm=True):
    """
    í–¥ìƒëœ DUAL ëª¨ë“œ: L2 ì •ê·œí™” ì ìš©ëœ í™”ì ì„ íƒ
    """
    if not voice_segments:
        return {'speaker_a': [], 'speaker_b': []}
        
    # L2 ì •ê·œí™” ì ìš©ëœ ID ë³‘í•© (DUAL ëª¨ë“œëŠ” ë” ì—„ê²©í•œ ì„ê³„ê°’ ì‚¬ìš©)
    dual_threshold = 0.70 if use_l2_norm else 0.65
    
    if embeddings:
        merged_timeline = TargetSelector._merge_similar_ids_enhanced(
            id_timeline, embeddings, 
            similarity_threshold=dual_threshold,
            use_l2_norm=use_l2_norm
        )
    else:
        merged_timeline = id_timeline
        
    speakers = {'speaker_a': [], 'speaker_b': []}
    
    for start_time, end_time in voice_segments:
        # ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼ (ID ë³‘í•©ë§Œ ê°œì„ ë¨)
        start_frame = int(start_time * fps)
        end_frame = int(end_time * fps)
        
        if start_frame >= len(merged_timeline):
            continue
            
        end_frame = min(end_frame, len(merged_timeline))
        
        # êµ¬ê°„ ë‚´ face_idë³„ ë“±ì¥ ë¹ˆë„ ì¹´ìš´íŠ¸
        face_counts = {}
        for frame_idx in range(start_frame, end_frame):
            face_id = merged_timeline[frame_idx]
            if face_id is not None:
                face_counts[face_id] = face_counts.get(face_id, 0) + 1
        
        if not face_counts:
            continue
            
        # ìƒìœ„ 2ëª… ì„ íƒ (ë¹ˆë„ìˆœ ì •ë ¬)
        sorted_faces = sorted(face_counts.items(), key=lambda x: x[1], reverse=True)
        
        # speaker_a (1ìˆœìœ„)
        if len(sorted_faces) >= 1:
            top_face_id = sorted_faces[0][0]
            speakers['speaker_a'].append((start_time, end_time, top_face_id))
        
        # speaker_b (2ìˆœìœ„)
        if len(sorted_faces) >= 2:
            second_face_id = sorted_faces[1][0]
            speakers['speaker_b'].append((start_time, end_time, second_face_id))
    
    return speakers
```

### Phase 3: ì„¤ì • ë° í†µí•© (ìš°ì„ ìˆœìœ„: ì¤‘ê°„)

#### 3.1 ì„¤ì • íŒŒì¼ í™•ì¥
```python
# config.py ì¶”ê°€
# L2 ì •ê·œí™” ê´€ë ¨ ì„¤ì •
L2_NORMALIZATION_ENABLED = True
DUAL_MODE_SIMILARITY_THRESHOLD = 0.70  # DUAL ëª¨ë“œ ì „ìš© (ë” ì—„ê²©)
SINGLE_MODE_SIMILARITY_THRESHOLD = 0.60  # SINGLE ëª¨ë“œ ê¸°ì¡´ê°’ ìœ ì§€

# ë””ë²„ê¹… ë° ë¡œê¹…
L2_NORM_DEBUG_MODE = False  # ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
SIMILARITY_COMPARISON_LOG = False  # ê¸°ì¡´/ì‹ ê·œ ë°©ì‹ ë¹„êµ ë¡œê·¸
```

#### 3.2 í†µí•© ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
```python
# similarity.py - í†µí•© ì¸í„°í˜ì´ìŠ¤
def calculate_face_similarity(emb1, emb2, mode='dual', use_l2_norm=None):
    """
    ëª¨ë“œë³„ ìµœì í™”ëœ ì–¼êµ´ ìœ ì‚¬ë„ ê³„ì‚°
    
    Args:
        emb1, emb2: ë¹„êµí•  ì„ë² ë”©ë“¤
        mode: 'single' | 'dual' 
        use_l2_norm: L2 ì •ê·œí™” ì‚¬ìš© ì—¬ë¶€ (Noneì´ë©´ config ê¸°ë³¸ê°’)
    """
    if use_l2_norm is None:
        use_l2_norm = L2_NORMALIZATION_ENABLED
    
    if use_l2_norm:
        return cosine_similarity_l2_normalized(emb1, emb2)
    else:
        return F.cosine_similarity(emb1, emb2, dim=1).item()

def get_similarity_threshold(mode='dual'):
    """ëª¨ë“œë³„ ìµœì  ì„ê³„ê°’ ë°˜í™˜"""
    if mode == 'dual':
        return DUAL_MODE_SIMILARITY_THRESHOLD
    else:
        return SINGLE_MODE_SIMILARITY_THRESHOLD
```

---

## ğŸ“… ë‹¨ê³„ë³„ ì‹¤í–‰ ë¡œë“œë§µ

### **Week 1: ê¸°ë°˜ êµ¬ì¶• (1-2ì¼)**

#### Day 1: í•µì‹¬ í•¨ìˆ˜ êµ¬í˜„
- [ ] `similarity.py`ì— L2 ì •ê·œí™” í•¨ìˆ˜ êµ¬í˜„
- [ ] ê¸°ì¡´ í•¨ìˆ˜ì™€ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

```bash
# ê°œë°œ ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/l2-normalization-dual-mode

# êµ¬í˜„ í›„ í…ŒìŠ¤íŠ¸
python -m pytest test/test_similarity_l2.py -v
```

#### Day 2: TargetSelector ì—…ê·¸ë ˆì´ë“œ  
- [ ] `selector.py` ID ë³‘í•© ë¡œì§ ê°œì„ 
- [ ] DUAL ëª¨ë“œ í™”ì ì„ íƒ í•¨ìˆ˜ ì—…ë°ì´íŠ¸
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ìˆ˜í–‰

### **Week 1: ê²€ì¦ ë° ìµœì í™” (3-4ì¼)**

#### Day 3: A/B í…ŒìŠ¤íŠ¸ ì¤€ë¹„
- [ ] í…ŒìŠ¤íŠ¸ ì˜ìƒ ì¤€ë¹„ (ë‹¤ì–‘í•œ ì¡°ëª…/ê°ë„)
- [ ] ì„±ëŠ¥ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] ê¸°ì¡´ vs ì‹ ê·œ ë°©ì‹ ë¹„êµ ë„êµ¬ ê°œë°œ

#### Day 4: ì´ˆê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] ì†Œê·œëª¨ ì˜ìƒìœ¼ë¡œ A/B í…ŒìŠ¤íŠ¸
- [ ] ì„ê³„ê°’ ìµœì í™” (0.65 â†’ 0.70 ë²”ìœ„)
- [ ] ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±

### **Week 2: í†µí•© ë° ë°°í¬ (5-7ì¼)**

#### Day 5-6: ì„¤ì • í†µí•© ë° ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
- [ ] `config.py` ì„¤ì • í™•ì¥
- [ ] CLI ì˜µì…˜ ì¶”ê°€ (`--use-l2-norm`)
- [ ] ë¡œê¹… ì‹œìŠ¤í…œ í†µí•©

#### Day 7: ìµœì¢… ê²€ì¦ ë° ë°°í¬
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìµœì¢… í™•ì¸
- [ ] main ë¸Œëœì¹˜ ë³‘í•©

### **êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸**

#### í•µì‹¬ íŒŒì¼ ìˆ˜ì • ëª©ë¡
- [x] **ë¶„ì„ ì™„ë£Œ**: í˜„ì¬ ì½”ë“œ êµ¬ì¡° íŒŒì•…
- [ ] **similarity.py**: L2 ì •ê·œí™” í•¨ìˆ˜ ì¶”ê°€
- [ ] **selector.py**: ID ë³‘í•© ë° í™”ì ì„ íƒ ë¡œì§ ê°œì„   
- [ ] **config.py**: L2 ì •ê·œí™” ê´€ë ¨ ì„¤ì • ì¶”ê°€
- [ ] **processor.py**: ìƒˆë¡œìš´ í•¨ìˆ˜ í˜¸ì¶œ í†µí•©
- [ ] **tests/**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€

#### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
- [ ] **ë‹¨ì¼ í™”ì ì˜ìƒ**: ê¸°ì¡´ ì„±ëŠ¥ ìœ ì§€ í™•ì¸
- [ ] **2ì¸ ëŒ€í™” ì˜ìƒ**: í™”ì ë¶„ë¦¬ ì •í™•ë„ ê°œì„  í™•ì¸
- [ ] **ì¡°ëª… ë³€í™” ì˜ìƒ**: ê°•ê±´ì„± ê°œì„  í™•ì¸
- [ ] **ê°ë„ ë³€í™” ì˜ìƒ**: ì•ˆì •ì„± ê°œì„  í™•ì¸

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„

#### 1. **ì¡°ëª… ë³€í™” í…ŒìŠ¤íŠ¸ì…‹**
```
test_videos/lighting/
â”œâ”€â”€ indoor_to_outdoor.mp4      # ì‹¤ë‚´â†’ì‹¤ì™¸ ì „í™˜
â”œâ”€â”€ bright_to_dim.mp4          # ë°ìŒâ†’ì–´ë‘ì›€ ì „í™˜  
â”œâ”€â”€ natural_to_artificial.mp4  # ìì—°ê´‘â†’ì¸ê³µì¡°ëª…
â””â”€â”€ backlit_conversation.mp4   # ì—­ê´‘ ìƒí™©
```

#### 2. **ê°ë„ ë³€í™” í…ŒìŠ¤íŠ¸ì…‹**
```
test_videos/angles/
â”œâ”€â”€ frontal_to_profile.mp4     # ì •ë©´â†’ì¸¡ë©´ ì „í™˜
â”œâ”€â”€ multi_angle_interview.mp4  # ë‹¤ê°ë„ ì¸í„°ë·°
â””â”€â”€ walking_conversation.mp4   # ì›€ì§ì´ëŠ” ëŒ€í™”
```

#### 3. **2ì¸ ëŒ€í™” í…ŒìŠ¤íŠ¸ì…‹**
```
test_videos/dual_speaker/
â”œâ”€â”€ clear_alternation.mp4      # ëª…í™•í•œ êµëŒ€ ë°œí™”
â”œâ”€â”€ overlapping_speech.mp4     # ì¤‘ë³µ ë°œí™”
â””â”€â”€ similar_appearance.mp4     # ìœ ì‚¬í•œ ì™¸ëª¨
```

### A/B í…ŒìŠ¤íŠ¸ í”„ë¡œí† ì½œ

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# test_l2_normalization.sh

echo "=== L2 ì •ê·œí™” A/B í…ŒìŠ¤íŠ¸ ì‹œì‘ ==="

# ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸
echo "1. ê¸°ì¡´ ë°©ì‹ (L2 ì •ê·œí™” ì—†ìŒ)"
python face_tracker.py --mode=dual --use-l2-norm=false \
    --input=test_videos/ --output=results/original/ \
    --report-file=results/original_performance.json

# ì‹ ê·œ ë°©ì‹ í…ŒìŠ¤íŠ¸  
echo "2. ì‹ ê·œ ë°©ì‹ (L2 ì •ê·œí™” ì ìš©)"
python face_tracker.py --mode=dual --use-l2-norm=true \
    --input=test_videos/ --output=results/l2_normalized/ \
    --report-file=results/l2_normalized_performance.json

# ê²°ê³¼ ë¹„êµ
python scripts/compare_results.py \
    --original=results/original_performance.json \
    --improved=results/l2_normalized_performance.json \
    --output=results/comparison_report.html
```

#### ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ
```python
# scripts/performance_metrics.py
class DualModeMetrics:
    def __init__(self):
        self.metrics = {
            'speaker_separation_accuracy': 0.0,  # í™”ì ë¶„ë¦¬ ì •í™•ë„
            'id_consistency_ratio': 0.0,         # ID ì¼ê´€ì„± ë¹„ìœ¨
            'lighting_robustness': 0.0,          # ì¡°ëª… ë³€í™” ê°•ê±´ì„±
            'angle_robustness': 0.0,             # ê°ë„ ë³€í™” ê°•ê±´ì„±
            'processing_time': 0.0,              # ì²˜ë¦¬ ì‹œê°„
            'memory_usage': 0.0                  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        }
    
    def calculate_speaker_accuracy(self, ground_truth, predicted):
        """ìˆ˜ë™ ë¼ë²¨ë§ê³¼ ë¹„êµí•œ í™”ì ë¶„ë¦¬ ì •í™•ë„"""
        correct = 0
        total = len(ground_truth)
        
        for i, (gt_speaker, pred_speaker) in enumerate(zip(ground_truth, predicted)):
            if gt_speaker == pred_speaker:
                correct += 1
                
        return correct / total if total > 0 else 0.0
    
    def calculate_id_consistency(self, timeline):
        """ë™ì¼ ì¸ë¬¼ì˜ ID ì¼ê´€ì„± ì¸¡ì •"""
        # ë™ì¼ ì‹œê°„ëŒ€ ì—°ì† í”„ë ˆì„ì—ì„œ ID ë³€í™” ë¹ˆë„ ì¸¡ì •
        consistency_score = 0.0
        # ... êµ¬í˜„ ë¡œì§
        return consistency_score
```

### ìë™í™”ëœ í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸
```python
# scripts/automated_test_pipeline.py
class L2NormalizationTestPipeline:
    def __init__(self):
        self.test_cases = self.load_test_cases()
        self.results = []
    
    def run_full_pipeline(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        for test_case in self.test_cases:
            # ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸
            original_result = self.run_test(test_case, use_l2_norm=False)
            
            # ì‹ ê·œ ë°©ì‹ í…ŒìŠ¤íŠ¸
            improved_result = self.run_test(test_case, use_l2_norm=True)
            
            # ê²°ê³¼ ë¹„êµ ë° ì €ì¥
            comparison = self.compare_results(original_result, improved_result)
            self.results.append(comparison)
        
        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_final_report()
    
    def generate_final_report(self):
        """HTML í˜•íƒœì˜ ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        # ì„±ëŠ¥ ê°œì„  ì§€í‘œ, ê·¸ë˜í”„, ìƒì„¸ ë¶„ì„ í¬í•¨
        pass
```

---

## âš ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬

### ì£¼ìš” ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘ ë°©ì•ˆ

#### 1. **ì„±ëŠ¥ ì €í•˜ ë¦¬ìŠ¤í¬**
- **ìœ„í—˜ë„**: ë‚®ìŒ
- **ì˜í–¥**: L2 ì •ê·œí™” ì—°ì‚°ìœ¼ë¡œ ì¸í•œ 1-5% ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
- **ëŒ€ì‘ë°©ì•ˆ**:
  ```python
  # ë°°ì¹˜ ë‹¨ìœ„ L2 ì •ê·œí™”ë¡œ íš¨ìœ¨ì„± ì¦ëŒ€
  def batch_l2_normalize(embeddings_batch):
      return F.normalize(embeddings_batch, p=2, dim=1)
  
  # GPU ë©”ëª¨ë¦¬ ìµœì í™”
  with torch.no_grad():  # gradient ê³„ì‚° ë¶ˆí•„ìš”
      normalized_emb = F.normalize(emb, p=2, dim=1)
  ```

#### 2. **ì„ê³„ê°’ ì¬ì¡°ì • í•„ìš”**
- **ìœ„í—˜ë„**: ì¤‘ê°„
- **ì˜í–¥**: ê¸°ì¡´ ì„ê³„ê°’ 0.6ì´ ë¶€ì ì ˆí•  ìˆ˜ ìˆìŒ
- **ëŒ€ì‘ë°©ì•ˆ**:
  ```python
  # ì ì‘í˜• ì„ê³„ê°’ ì‹œìŠ¤í…œ
  def adaptive_threshold_finder(test_embeddings):
      """ROC ê³¡ì„  ë¶„ì„ì„ í†µí•œ ìµœì  ì„ê³„ê°’ íƒìƒ‰"""
      thresholds = np.arange(0.5, 0.9, 0.05)
      best_threshold = 0.7
      best_f1_score = 0.0
      
      for threshold in thresholds:
          f1 = calculate_f1_score(test_embeddings, threshold)
          if f1 > best_f1_score:
              best_f1_score = f1
              best_threshold = threshold
      
      return best_threshold
  ```

#### 3. **í•˜ìœ„ í˜¸í™˜ì„± ë¬¸ì œ**
- **ìœ„í—˜ë„**: ë‚®ìŒ
- **ì˜í–¥**: ê¸°ì¡´ SINGLE ëª¨ë“œ ì˜í–¥ ê°€ëŠ¥ì„±
- **ëŒ€ì‘ë°©ì•ˆ**:
  ```python
  # ëª¨ë“œë³„ ë¶„ë¦¬ëœ ì„¤ì •
  def get_similarity_config(mode):
      if mode == 'dual':
          return {
              'use_l2_norm': True,
              'threshold': 0.70,
              'merge_threshold': 0.75
          }
      else:  # single ëª¨ë“œ
          return {
              'use_l2_norm': False,  # ê¸°ì¡´ ë°©ì‹ ìœ ì§€
              'threshold': 0.60,
              'merge_threshold': 0.65
          }
  ```

#### 4. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€**
- **ìœ„í—˜ë„**: ë‚®ìŒ
- **ì˜í–¥**: ì •ê·œí™”ëœ ë²¡í„° ì €ì¥ìœ¼ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì¦ê°€
- **ëŒ€ì‘ë°©ì•ˆ**:
  ```python
  # ì¸í”Œë ˆì´ìŠ¤ ì •ê·œí™” (ë©”ëª¨ë¦¬ ì ˆì•½)
  def normalize_inplace(tensor):
      tensor.div_(tensor.norm(dim=1, keepdim=True))
      return tensor
  
  # ì„ì‹œ ë²¡í„° ìºì‹±
  class NormalizedEmbeddingCache:
      def __init__(self, max_size=1000):
          self.cache = LRUCache(max_size)
      
      def get_normalized(self, embedding_id, embedding):
          if embedding_id not in self.cache:
              self.cache[embedding_id] = F.normalize(embedding, p=2, dim=1)
          return self.cache[embedding_id]
  ```

### ë¡¤ë°± ê³„íš
```bash
# ë¬¸ì œ ë°œìƒì‹œ ì¦‰ì‹œ ë¡¤ë°± ê°€ëŠ¥í•œ êµ¬ì¡°
git checkout main
git revert <commit-hash>  # L2 ì •ê·œí™” ì»¤ë°‹ ë˜ëŒë¦¬ê¸°

# ë˜ëŠ” ì„¤ì •ìœ¼ë¡œ ì¦‰ì‹œ ë¹„í™œì„±í™”
export L2_NORMALIZATION_ENABLED=false
python face_tracker.py --mode=dual
```

---

## ğŸ“Š ì„±ê³µ ì§€í‘œ

### ì •ëŸ‰ì  ì„±ê³¼ ì§€í‘œ

#### 1. **í™”ì ë¶„ë¦¬ ì •í™•ë„**
- **í˜„ì¬**: ~85%
- **ëª©í‘œ**: 92%+
- **ì¸¡ì • ë°©ë²•**: ìˆ˜ë™ ë¼ë²¨ë§ê³¼ ë¹„êµí•œ ì •í™•ë„

#### 2. **ID ì¼ê´€ì„± ê°œì„ **
- **í˜„ì¬**: ë™ì¼ ì¸ë¬¼ì´ í‰ê·  2.3ê°œ IDë¡œ ë¶„ì‚°
- **ëª©í‘œ**: í‰ê·  1.5ê°œ IDë¡œ ê°ì†Œ (30% ê°œì„ )
- **ì¸¡ì • ë°©ë²•**: ì—°ì† í”„ë ˆì„ì—ì„œ ID ë³€í™” ë¹ˆë„

#### 3. **ì¡°ëª… ë³€í™” ê°•ê±´ì„±**
- **í˜„ì¬**: ì¡°ëª… ë³€í™”ì‹œ ì¸ì‹ë¥  60%
- **ëª©í‘œ**: ì¸ì‹ë¥  85%+ (40% ê°œì„ )
- **ì¸¡ì • ë°©ë²•**: ì‹¤ë‚´â†”ì‹¤ì™¸ ì „í™˜ ì˜ìƒì—ì„œ ë™ì¼ ì¸ë¬¼ ì¸ì‹ë¥ 

#### 4. **ì‹œìŠ¤í…œ ì„±ëŠ¥ ìœ ì§€**
- **ì²˜ë¦¬ ì‹œê°„**: 15-20ì´ˆ â†’ 15-21ì´ˆ (5% ì´ë‚´ ì¦ê°€)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: í˜„ì¬ ëŒ€ë¹„ 3% ì´ë‚´ ì¦ê°€
- **GPU í™œìš©ë¥ **: 97.3% ìœ ì§€

### ì •ì„±ì  ì„±ê³¼ ì§€í‘œ

#### 1. **ì‚¬ìš©ì ê²½í—˜ ê°œì„ **
- speaker_a/speaker_b í´ë”ì˜ ì˜¬ë°”ë¥¸ ë¶„ë¥˜ìœ¨ í–¥ìƒ
- ë™ì¼ ì˜ìƒ ë°˜ë³µ ì²˜ë¦¬ì‹œ ê²°ê³¼ ì¼ê´€ì„± ê°œì„ 
- ë‹¤ì–‘í•œ ì´¬ì˜ í™˜ê²½ì—ì„œì˜ ì•ˆì •ì„± í–¥ìƒ

#### 2. **ì‹œìŠ¤í…œ ì‹ ë¢°ì„±**
- ì˜ˆì™¸ ìƒí™©ì—ì„œì˜ graceful degradation
- ë¡œê·¸ ë©”ì‹œì§€ì˜ ëª…í™•ì„± ë° ë””ë²„ê¹… ìš©ì´ì„±
- ì„¤ì • ë³€ê²½ì„ í†µí•œ ìœ ì—°í•œ ë™ì‘ ì œì–´

### ì„±ê³¼ ì¸¡ì • ëŒ€ì‹œë³´ë“œ
```python
# scripts/performance_dashboard.py
class L2NormalizationDashboard:
    def generate_report(self, test_results):
        """ì„±ê³¼ ì§€í‘œ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        
        metrics = {
            'accuracy_improvement': self.calc_accuracy_change(test_results),
            'consistency_improvement': self.calc_consistency_change(test_results),
            'robustness_scores': self.calc_robustness_scores(test_results),
            'performance_impact': self.calc_performance_impact(test_results)
        }
        
        # HTML ëŒ€ì‹œë³´ë“œ ìƒì„±
        html_content = self.create_html_dashboard(metrics)
        
        with open('results/l2_normalization_dashboard.html', 'w') as f:
            f.write(html_content)
            
        return metrics
```

---

## ğŸ¯ ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥í•œ ì‘ì—… (Today)
- [ ] ê°œë°œ ë¸Œëœì¹˜ ìƒì„±: `git checkout -b feature/l2-normalization-dual-mode`
- [ ] `similarity.py`ì— L2 ì •ê·œí™” í•¨ìˆ˜ êµ¬í˜„
- [ ] ê¸°ë³¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

### 1ì£¼ì°¨ ì™„ë£Œ ëª©í‘œ
- [ ] í•µì‹¬ í•¨ìˆ˜ êµ¬í˜„ ì™„ë£Œ (similarity.py, selector.py)
- [ ] A/B í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•
- [ ] ì´ˆê¸° ì„±ëŠ¥ ê²€ì¦ ì™„ë£Œ

### 2ì£¼ì°¨ ì™„ë£Œ ëª©í‘œ  
- [ ] ì„¤ì • ì‹œìŠ¤í…œ í†µí•©
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë‹¬ì„± í™•ì¸
- [ ] main ë¸Œëœì¹˜ ë³‘í•© ë° ë°°í¬

### ìµœì¢… ê²€ì¦ í•­ëª©
- [ ] í™”ì ë¶„ë¦¬ ì •í™•ë„ 92% ë‹¬ì„±
- [ ] ID ì¼ê´€ì„± 30% ê°œì„ 
- [ ] ì²˜ë¦¬ ì‹œê°„ 5% ì´ë‚´ ì¦ê°€
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í†µê³¼

---

**ë¬¸ì„œ ë²„ì „**: v1.0  
**ì‘ì„±ì¼**: 2025-08-02  
**ì˜ˆìƒ ì™„ë£Œì¼**: 2025-08-09 (1ì£¼ì¼)  
**ìš°ì„ ìˆœìœ„**: ë†’ìŒ (DUAL ëª¨ë“œ í•µì‹¬ ê°œì„ ì‚¬í•­)

> **ë‹¤ìŒ ë‹¨ê³„**: ì´ ê³„íšì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¦‰ì‹œ `similarity.py` L2 ì •ê·œí™” í•¨ìˆ˜ êµ¬í˜„ì„ ì‹œì‘í•˜ì„¸ìš”.