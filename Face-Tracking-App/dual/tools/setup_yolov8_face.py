#!/usr/bin/env python3
"""
YOLOv8 Face Detection ëª¨ë¸ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
Ultralytics YOLOv8ì„ ì„¤ì¹˜í•˜ê³  face detection ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ/ë³€í™˜í•©ë‹ˆë‹¤.
"""

import os
import sys
import subprocess
from pathlib import Path
import requests

def run_command(cmd, description=""):
    """ëª…ë ¹ ì‹¤í–‰ í—¬í¼"""
    if description:
        print(f"\nğŸ“Œ {description}")
    print(f"$ {cmd}")
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âŒ Error: {result.stderr}")
        return False
    if result.stdout:
        print(result.stdout)
    return True

def install_ultralytics():
    """Ultralytics íŒ¨í‚¤ì§€ ì„¤ì¹˜"""
    print("ğŸš€ Installing Ultralytics YOLOv8...")
    
    # Ultralytics ì„¤ì¹˜
    if not run_command("pip install ultralytics", "Installing ultralytics package"):
        return False
    
    # ì¶”ê°€ ì˜ì¡´ì„±
    deps = [
        "onnx",
        "onnxruntime-gpu",  # GPU ì§€ì›
        "onnx-simplifier",
        "tensorrt"  # TensorRTëŠ” ë³„ë„ ì„¤ì¹˜ í•„ìš”í•  ìˆ˜ ìˆìŒ
    ]
    
    for dep in deps:
        run_command(f"pip install {dep}", f"Installing {dep}")
    
    return True

def download_yolov8_face_models():
    """YOLOv8 face detection ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    print("\nğŸ“¥ Downloading YOLOv8 face detection models...")
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    weights_dir = Path("weights")
    weights_dir.mkdir(exist_ok=True)
    
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    # GitHubì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
    # akanametov/yolo-face ë¦¬í¬ì§€í† ë¦¬ ê¸°ë°˜
    models_to_download = {
        "yolov8n-face": {
            "url": "https://github.com/akanametov/yolo-face/releases/download/v0.1.0/yolov8n-face.pt",
            "description": "YOLOv8 nano face detection (fastest)"
        },
        "yolov8s-face": {
            "url": "https://github.com/akanametov/yolo-face/releases/download/v0.1.0/yolov8s-face.pt",
            "description": "YOLOv8 small face detection (balanced)"
        }
    }
    
    downloaded_models = []
    
    for model_name, info in models_to_download.items():
        pt_path = weights_dir / f"{model_name}.pt"
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if pt_path.exists():
            print(f"âœ… {model_name}.pt already exists")
            downloaded_models.append(pt_path)
            continue
        
        print(f"\nDownloading {model_name}...")
        print(f"  {info['description']}")
        
        try:
            # ë‹¤ìš´ë¡œë“œ
            response = requests.get(info["url"], stream=True, timeout=30)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(pt_path, 'wb') as f:
                downloaded = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"\r  Progress: {percent:.1f}%", end="")
            
            print(f"\nâœ… Downloaded: {pt_path}")
            downloaded_models.append(pt_path)
            
        except Exception as e:
            print(f"âŒ Failed to download {model_name}: {e}")
            # ëŒ€ì•ˆ: ultralytics ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
            print("  Trying alternative: using base YOLOv8 model...")
            alternative_cmd = f"yolo task=detect mode=download model=yolov8n.pt"
            if run_command(alternative_cmd):
                downloaded_models.append(Path("yolov8n.pt"))
    
    return downloaded_models

def export_to_onnx(model_paths):
    """PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜"""
    print("\nğŸ”„ Exporting models to ONNX...")
    
    models_dir = Path("models")
    exported_models = []
    
    for pt_path in model_paths:
        if not pt_path.exists():
            print(f"âš ï¸ Model not found: {pt_path}")
            continue
        
        onnx_path = models_dir / f"{pt_path.stem}.onnx"
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if onnx_path.exists():
            print(f"âœ… {onnx_path.name} already exists")
            exported_models.append(onnx_path)
            continue
        
        print(f"\nExporting {pt_path.name} to ONNX...")
        
        # Ultralytics CLI ì‚¬ìš©
        export_cmd = f"yolo export model={pt_path} format=onnx opset=16 simplify=True imgsz=640"
        
        if run_command(export_cmd, "Using YOLO export command"):
            # ìƒì„±ëœ ONNX íŒŒì¼ ì´ë™
            expected_onnx = pt_path.with_suffix('.onnx')
            if expected_onnx.exists():
                import shutil
                shutil.move(str(expected_onnx), str(onnx_path))
                print(f"âœ… Exported: {onnx_path}")
                exported_models.append(onnx_path)
        else:
            print(f"âŒ Failed to export {pt_path.name}")
            
            # ëŒ€ì•ˆ: Python API ì‚¬ìš©
            print("  Trying Python API...")
            try:
                from ultralytics import YOLO
                model = YOLO(str(pt_path))
                model.export(format="onnx", opset=16, simplify=True, imgsz=640)
                
                expected_onnx = pt_path.with_suffix('.onnx')
                if expected_onnx.exists():
                    import shutil
                    shutil.move(str(expected_onnx), str(onnx_path))
                    print(f"âœ… Exported via Python API: {onnx_path}")
                    exported_models.append(onnx_path)
            except Exception as e:
                print(f"âŒ Python API also failed: {e}")
    
    return exported_models

def export_to_tensorrt(onnx_paths):
    """ONNX ëª¨ë¸ì„ TensorRTë¡œ ë³€í™˜"""
    print("\nğŸš€ Exporting models to TensorRT...")
    
    engines_dir = Path("engines")
    engines_dir.mkdir(exist_ok=True)
    
    exported_engines = []
    
    for onnx_path in onnx_paths:
        if not onnx_path.exists():
            print(f"âš ï¸ ONNX model not found: {onnx_path}")
            continue
        
        engine_path = engines_dir / f"{onnx_path.stem}_fp16.engine"
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
        if engine_path.exists():
            print(f"âœ… {engine_path.name} already exists")
            exported_engines.append(engine_path)
            continue
        
        print(f"\nExporting {onnx_path.name} to TensorRT...")
        
        # TensorRT ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
        trt_cmd = f"python tools/convert_to_tensorrt.py --onnx {onnx_path} --engine {engine_path} --precision fp16 --max-batch 8"
        
        if run_command(trt_cmd, "Using TensorRT conversion script"):
            print(f"âœ… Exported: {engine_path}")
            exported_engines.append(engine_path)
        else:
            print(f"âš ï¸ TensorRT conversion failed for {onnx_path.name}")
            print("  This is optional - ONNX model can still be used")
    
    return exported_engines

def test_models():
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Testing models...")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ë˜ëŠ” ë‹¤ìš´ë¡œë“œ
    test_image = Path("test_face.jpg")
    
    if not test_image.exists():
        print("Downloading test image...")
        test_url = "https://ultralytics.com/images/bus.jpg"
        try:
            response = requests.get(test_url)
            response.raise_for_status()
            with open(test_image, 'wb') as f:
                f.write(response.content)
            print(f"âœ… Downloaded test image: {test_image}")
        except:
            print("âš ï¸ Could not download test image")
            return
    
    # ONNX ëª¨ë¸ í…ŒìŠ¤íŠ¸
    models_dir = Path("models")
    for onnx_file in models_dir.glob("*.onnx"):
        print(f"\nTesting {onnx_file.name}...")
        test_cmd = f"yolo predict model={onnx_file} source={test_image} save=True"
        if run_command(test_cmd):
            print(f"âœ… {onnx_file.name} works!")
        else:
            print(f"âš ï¸ {onnx_file.name} test failed")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ YOLOv8 Face Detection Setup")
    print("=" * 60)
    
    # 1. Ultralytics ì„¤ì¹˜
    if not install_ultralytics():
        print("âŒ Failed to install ultralytics")
        return 1
    
    # 2. Face detection ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    pt_models = download_yolov8_face_models()
    
    if not pt_models:
        print("âŒ No models downloaded")
        # ê¸°ë³¸ YOLOv8 ëª¨ë¸ ì‚¬ìš©
        print("Using default YOLOv8 model...")
        run_command("yolo task=detect mode=download model=yolov8n.pt")
        pt_models = [Path("yolov8n.pt")]
    
    # 3. ONNX ë³€í™˜
    onnx_models = export_to_onnx(pt_models)
    
    if not onnx_models:
        print("âš ï¸ No ONNX models created")
    
    # 4. TensorRT ë³€í™˜ (ì„ íƒì )
    if onnx_models:
        trt_engines = export_to_tensorrt(onnx_models)
        if trt_engines:
            print(f"\nâœ… Created {len(trt_engines)} TensorRT engines")
    
    # 5. í…ŒìŠ¤íŠ¸
    if onnx_models:
        test_models()
    
    # 6. ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š Setup Summary")
    print("=" * 60)
    
    print(f"âœ… PyTorch models: {len(pt_models)}")
    for p in pt_models:
        if p.exists():
            size_mb = p.stat().st_size / (1024 * 1024)
            print(f"   - {p.name} ({size_mb:.1f} MB)")
    
    print(f"\nâœ… ONNX models: {len(onnx_models)}")
    for p in onnx_models:
        if p.exists():
            size_mb = p.stat().st_size / (1024 * 1024)
            print(f"   - {p.name} ({size_mb:.1f} MB)")
    
    engines_dir = Path("engines")
    if engines_dir.exists():
        engines = list(engines_dir.glob("*.engine"))
        if engines:
            print(f"\nâœ… TensorRT engines: {len(engines)}")
            for p in engines:
                size_mb = p.stat().st_size / (1024 * 1024)
                print(f"   - {p.name} ({size_mb:.1f} MB)")
    
    print("\nğŸ‰ Setup complete! You can now use these models for face detection.")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())