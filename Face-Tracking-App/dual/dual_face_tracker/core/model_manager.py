#!/usr/bin/env python3
"""
ModelManager - MTCNNê³¼ FaceNet ëª¨ë¸ ê´€ë¦¬
ë“€ì–¼ í˜ì´ìŠ¤ íŠ¸ë˜í‚¹ ì‹œìŠ¤í…œì˜ í•µì‹¬ ëª¨ë¸ ë¡œë”
"""

import torch
import torch.nn as nn
from facenet_pytorch import MTCNN, InceptionResnetV1
import numpy as np
from typing import List, Optional, Tuple, Union
import logging

class ModelManager:
    """
    MTCNNê³¼ FaceNet ëª¨ë¸ì„ ê´€ë¦¬í•˜ëŠ” ì‹±ê¸€í†¤ í´ë˜ìŠ¤
    GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ê´€ë¦¬ ë° ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
    """
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ModelManager, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.mtcnn = None
        self.facenet = None
        self.logger = logging.getLogger(__name__)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._init_models()
        self._initialized = True
        
    def _init_models(self):
        """MTCNNê³¼ FaceNet ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # MTCNN ì´ˆê¸°í™” (ì–¼êµ´ ê²€ì¶œ)
            self.mtcnn = MTCNN(
                image_size=160,
                margin=0,
                min_face_size=20,
                thresholds=[0.6, 0.7, 0.7],
                factor=0.709,
                post_process=False,
                device=self.device,
                keep_all=True,
                selection_method='largest_over_threshold'
            )
            
            # FaceNet ì´ˆê¸°í™” (ì„ë² ë”© ì¶”ì¶œ)
            self.facenet = InceptionResnetV1(
                pretrained='vggface2',
                device=self.device
            ).eval()
            
            # GPUë¡œ ì´ë™
            if self.device.type == 'cuda':
                self.facenet = self.facenet.cuda()
                
            self.logger.info(f"âœ… ModelManager ì´ˆê¸°í™” ì™„ë£Œ (device: {self.device})")
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def detect_faces(self, image: Union[np.ndarray, torch.Tensor], min_confidence: float = 0.9):
        """
        ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê²€ì¶œ
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (H, W, C) numpy array ë˜ëŠ” tensor
            min_confidence: ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            boxes: ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ [(x1, y1, x2, y2), ...]
            probs: ì‹ ë¢°ë„ ë¦¬ìŠ¤íŠ¸
            landmarks: ëœë“œë§ˆí¬ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        """
        if self.mtcnn is None:
            raise RuntimeError("MTCNN ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            
        try:
            # numpy arrayë¥¼ PIL Imageë¡œ ë³€í™˜
            if isinstance(image, np.ndarray):
                from PIL import Image
                if image.dtype != np.uint8:
                    image = (image * 255).astype(np.uint8)
                image = Image.fromarray(image)
            
            # MTCNNìœ¼ë¡œ ì–¼êµ´ ê²€ì¶œ
            boxes, probs, landmarks = self.mtcnn.detect(image, landmarks=True)
            
            if boxes is None:
                return [], [], []
                
            # ì‹ ë¢°ë„ í•„í„°ë§
            valid_indices = probs >= min_confidence
            
            valid_boxes = boxes[valid_indices] if boxes is not None else []
            valid_probs = probs[valid_indices] if probs is not None else []
            valid_landmarks = landmarks[valid_indices] if landmarks is not None else []
            
            return valid_boxes.tolist(), valid_probs.tolist(), valid_landmarks.tolist()
            
        except Exception as e:
            self.logger.error(f"ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return [], [], []
    
    def extract_embeddings(self, faces: List[np.ndarray], batch_size: int = 8):
        """
        ì–¼êµ´ ì´ë¯¸ì§€ë“¤ì—ì„œ ì„ë² ë”© ë²¡í„° ì¶”ì¶œ
        
        Args:
            faces: ì–¼êµ´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ê°ê° 160x160 í¬ê¸°)
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            embeddings: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸ (512ì°¨ì›)
        """
        if self.facenet is None:
            raise RuntimeError("FaceNet ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            
        if not faces:
            return []
            
        try:
            embeddings = []
            
            # ë°°ì¹˜ë³„ ì²˜ë¦¬
            for i in range(0, len(faces), batch_size):
                batch_faces = faces[i:i+batch_size]
                
                # ì „ì²˜ë¦¬: numpy â†’ tensor
                batch_tensors = []
                for face in batch_faces:
                    if isinstance(face, np.ndarray):
                        # 0-255 â†’ -1 to 1 ì •ê·œí™”
                        face = face.astype(np.float32) / 127.5 - 1.0
                        # HWC â†’ CHW
                        if len(face.shape) == 3:
                            face = np.transpose(face, (2, 0, 1))
                        # Tensor ë³€í™˜
                        face_tensor = torch.from_numpy(face).to(self.device)
                    else:
                        face_tensor = face.to(self.device)
                    
                    batch_tensors.append(face_tensor)
                
                # ë°°ì¹˜ í…ì„œ ìƒì„±
                batch_tensor = torch.stack(batch_tensors)
                
                # ì„ë² ë”© ì¶”ì¶œ
                with torch.no_grad():
                    batch_embeddings = self.facenet(batch_tensor)
                    
                # CPUë¡œ ì´ë™í•˜ì—¬ ì €ì¥
                embeddings.extend(batch_embeddings.cpu().numpy())
            
            return embeddings
            
        except Exception as e:
            self.logger.error(f"ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def crop_and_align_faces(self, image: Union[np.ndarray, torch.Tensor], boxes: List[List[float]]):
        """
        ê²€ì¶œëœ ì–¼êµ´ ë°•ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–¼êµ´ì„ ìë¥´ê³  ì •ë ¬
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            boxes: ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸ [(x1, y1, x2, y2), ...]
            
        Returns:
            cropped_faces: ìë¥¸ ì–¼êµ´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (160x160)
        """
        if not boxes:
            return []
            
        try:
            cropped_faces = []
            
            # PIL Imageë¡œ ë³€í™˜
            if isinstance(image, np.ndarray):
                from PIL import Image
                if image.dtype != np.uint8:
                    image = (image * 255).astype(np.uint8)
                pil_image = Image.fromarray(image)
            else:
                pil_image = image
            
            for box in boxes:
                x1, y1, x2, y2 = map(int, box)
                
                # ë°”ìš´ë”© ë°•ìŠ¤ í¬ë¡­
                cropped = pil_image.crop((x1, y1, x2, y2))
                
                # 160x160ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                cropped = cropped.resize((160, 160))
                
                # numpy arrayë¡œ ë³€í™˜
                cropped_np = np.array(cropped)
                cropped_faces.append(cropped_np)
            
            return cropped_faces
            
        except Exception as e:
            self.logger.error(f"ì–¼êµ´ í¬ë¡­ ì‹¤íŒ¨: {e}")
            return []
    
    def compute_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """
        ë‘ ì„ë² ë”© ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            embedding1, embedding2: 512ì°¨ì› ì„ë² ë”© ë²¡í„°
            
        Returns:
            similarity: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0~1)
        """
        try:
            # L2 ì •ê·œí™”
            embedding1 = embedding1 / np.linalg.norm(embedding1)
            embedding2 = embedding2 / np.linalg.norm(embedding2)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            similarity = np.dot(embedding1, embedding2)
            
            # 0~1 ë²”ìœ„ë¡œ ë³€í™˜
            similarity = (similarity + 1) / 2
            
            return float(similarity)
            
        except Exception as e:
            self.logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def process_frame(self, frame: np.ndarray, min_confidence: float = 0.9):
        """
        í”„ë ˆì„ì—ì„œ ì–¼êµ´ ê²€ì¶œ â†’ í¬ë¡­ â†’ ì„ë² ë”© ì¶”ì¶œê¹Œì§€ í•œë²ˆì— ì²˜ë¦¬
        
        Args:
            frame: ì…ë ¥ í”„ë ˆì„ (H, W, C)
            min_confidence: ìµœì†Œ ì‹ ë¢°ë„
            
        Returns:
            results: [{'box': [x1,y1,x2,y2], 'confidence': float, 'embedding': np.array}, ...]
        """
        # ì–¼êµ´ ê²€ì¶œ
        boxes, probs, _ = self.detect_faces(frame, min_confidence)
        
        if not boxes:
            return []
        
        # ì–¼êµ´ í¬ë¡­
        cropped_faces = self.crop_and_align_faces(frame, boxes)
        
        # ì„ë² ë”© ì¶”ì¶œ
        embeddings = self.extract_embeddings(cropped_faces)
        
        # ê²°ê³¼ ì¡°í•©
        results = []
        for i, (box, prob, embedding) in enumerate(zip(boxes, probs, embeddings)):
            results.append({
                'box': box,
                'confidence': prob,
                'embedding': embedding
            })
        
        return results
    
    def get_model_info(self) -> dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'device': str(self.device),
            'mtcnn_loaded': self.mtcnn is not None,
            'facenet_loaded': self.facenet is not None,
            'cuda_available': torch.cuda.is_available(),
            'gpu_memory': torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
        }
    
    def cleanup(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        self.logger.info("ModelManager ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜
def get_model_manager() -> ModelManager:
    """ModelManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return ModelManager()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª ModelManager í…ŒìŠ¤íŠ¸")
    
    manager = ModelManager()
    info = manager.get_model_info()
    
    print(f"Device: {info['device']}")
    print(f"MTCNN: {info['mtcnn_loaded']}")
    print(f"FaceNet: {info['facenet_loaded']}")
    print(f"CUDA: {info['cuda_available']}")
    
    print("âœ… ModelManager í…ŒìŠ¤íŠ¸ ì™„ë£Œ")