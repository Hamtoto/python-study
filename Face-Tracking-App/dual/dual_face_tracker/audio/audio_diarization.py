"""
Audio Diarization System for Dual Face Tracking
Phase C: Speaker Diarization + Face-Speaker Matching

pyannote.audio ê¸°ë°˜ í™”ì ë¶„í• ë¡œ ì¤‘ê°„ í™”ì êµì²´ ê°ì§€ ë° ì–¼êµ´-í™”ì ë§¤ì¹­
"""

import numpy as np
import time
import logging
from typing import Dict, Any, Optional, List, Tuple, Union
from dataclasses import dataclass
from collections import defaultdict, Counter
import json

# pyannote.audio ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
try:
    from pyannote.audio import Pipeline
    from pyannote.audio.core.io import AudioFile
    HAS_PYANNOTE = True
except ImportError:
    HAS_PYANNOTE = False
    print("âš ï¸ pyannote.audio not available - using mock diarization")

# ì˜¤ë””ì˜¤ ì²˜ë¦¬
try:
    import librosa
    HAS_LIBROSA = True
except ImportError:
    HAS_LIBROSA = False
    print("âš ï¸ librosa not available - limited audio processing")


@dataclass
class SpeakerSegment:
    """í™”ì êµ¬ê°„ ë°ì´í„° í´ë˜ìŠ¤"""
    speaker_id: str
    start_time: float
    end_time: float
    confidence: float
    duration: float = 0.0
    
    def __post_init__(self):
        self.duration = self.end_time - self.start_time


@dataclass
class SpeakerProfile:
    """í™”ì í”„ë¡œíŒŒì¼ ë°ì´í„° í´ë˜ìŠ¤"""
    speaker_id: str
    total_duration: float
    segment_count: int
    avg_segment_duration: float
    speaking_ratio: float
    time_segments: List[Tuple[float, float]]
    confidence_scores: List[float]


@dataclass
class FaceSpeakerMatch:
    """ì–¼êµ´-í™”ì ë§¤ì¹­ ê²°ê³¼"""
    face_id: str  # 'A' or 'B'
    speaker_id: str
    confidence: float
    match_type: str  # 'temporal', 'frequency', 'correlation'
    supporting_evidence: Dict[str, float]


class SpeakerDiarization:
    """pyannote.audio ê¸°ë°˜ í™”ì ë¶„í• """
    
    def __init__(self, model_name: str = "pyannote/speaker-diarization-3.1"):
        """
        SpeakerDiarization ì´ˆê¸°í™”
        
        Args:
            model_name: pyannote.audio ëª¨ë¸ ì´ë¦„
        """
        self.model_name = model_name
        self.logger = logging.getLogger(__name__)
        self.pipeline = None
        
        # pyannote.audio íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        if HAS_PYANNOTE:
            try:
                self.pipeline = self._load_pretrained_model()
                if self.pipeline:
                    self.logger.info(f"âœ… pyannote.audio ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
                else:
                    self.logger.warning("âš ï¸ pyannote.audio ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - Mock ëª¨ë“œë¡œ ë™ì‘")
            except Exception as e:
                self.logger.warning(f"pyannote.audio ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - Mock ëª¨ë“œë¡œ ë™ì‘")
                self.pipeline = None
        else:
            self.logger.info("pyannote.audio ë¯¸ì‚¬ìš© - Mock ëª¨ë“œë¡œ ë™ì‘")
    
    def _load_pretrained_model(self) -> Optional[Any]:
        """ì‚¬ì „ í›ˆë ¨ëœ diarization ëª¨ë¸ ë¡œë“œ"""
        try:
            # Hugging Face í† í°ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
            pipeline = Pipeline.from_pretrained(self.model_name)
            return pipeline
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ì¸ì¦ í† í°ì´ í•„ìš”í•œ ê²½ìš°
            self.logger.info("ğŸ’¡ Hugging Face í† í°ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            self.logger.info("   huggingface-cli login")
            self.logger.info("   ë˜ëŠ” í™˜ê²½ë³€ìˆ˜: HF_TOKEN=your_token")
            return None
    
    def diarize_audio(self, video_path: str, min_speakers: int = 2, max_speakers: int = 4) -> List[SpeakerSegment]:
        """ì˜¤ë””ì˜¤ì—ì„œ í™”ìë³„ êµ¬ê°„ ì¶”ì¶œ
        
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            min_speakers: ìµœì†Œ í™”ì ìˆ˜
            max_speakers: ìµœëŒ€ í™”ì ìˆ˜
            
        Returns:
            í™”ìë³„ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
        """
        try:
            self.logger.info(f"ğŸ¤ í™”ì ë¶„í•  ì‹œì‘: {video_path}")
            
            if self.pipeline:
                return self._pyannote_diarize(video_path, min_speakers, max_speakers)
            else:
                return self._mock_diarize(video_path, min_speakers, max_speakers)
                
        except Exception as e:
            self.logger.error(f"í™”ì ë¶„í•  ì‹¤íŒ¨: {e}")
            return self._mock_diarize(video_path, min_speakers, max_speakers)
    
    def _pyannote_diarize(self, video_path: str, min_speakers: int, max_speakers: int) -> List[SpeakerSegment]:
        """pyannote.audioë¡œ ì‹¤ì œ í™”ì ë¶„í• """
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
            audio_file = AudioFile(video_path)
            
            # í™”ì ë¶„í•  ì‹¤í–‰
            diarization = self.pipeline(audio_file, min_speakers=min_speakers, max_speakers=max_speakers)
            
            # ê²°ê³¼ ë³€í™˜
            segments = []
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                segment = SpeakerSegment(
                    speaker_id=speaker,
                    start_time=turn.start,
                    end_time=turn.end,
                    confidence=0.8  # pyannoteëŠ” ì‹ ë¢°ë„ë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
                )
                segments.append(segment)
            
            # ì‹œê°„ìˆœ ì •ë ¬
            segments.sort(key=lambda x: x.start_time)
            
            self.logger.info(f"âœ… pyannote í™”ì ë¶„í•  ì™„ë£Œ: {len(segments)}ê°œ êµ¬ê°„, "
                           f"{len(set(s.speaker_id for s in segments))}ëª… í™”ì")
            
            return segments
            
        except Exception as e:
            self.logger.error(f"pyannote í™”ì ë¶„í•  ì‹¤íŒ¨: {e}")
            return []
    
    def _mock_diarize(self, video_path: str, min_speakers: int, max_speakers: int) -> List[SpeakerSegment]:
        """Mock í™”ì ë¶„í•  (pyannote ì—†ì´)"""
        try:
            # ë¹„ë””ì˜¤ ê¸¸ì´ ì¶”ì •
            import cv2
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 60.0
            cap.release()
            
            # Mock í™”ì êµ¬ê°„ ìƒì„± (êµëŒ€ë¡œ ë§í•˜ëŠ” íŒ¨í„´)
            segments = []
            speakers = [f"SPEAKER_{i:02d}" for i in range(min_speakers)]
            
            # 3-8ì´ˆ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ êµëŒ€ë¡œ í• ë‹¹
            current_time = 0.0
            speaker_idx = 0
            
            while current_time < duration:
                # 3-8ì´ˆ ëœë¤ êµ¬ê°„
                segment_duration = 3.0 + np.random.random() * 5.0
                end_time = min(current_time + segment_duration, duration)
                
                if end_time - current_time < 0.5:  # ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
                    break
                
                segment = SpeakerSegment(
                    speaker_id=speakers[speaker_idx],
                    start_time=current_time,
                    end_time=end_time,
                    confidence=0.7 + np.random.random() * 0.2
                )
                segments.append(segment)
                
                # ë‹¤ìŒ í™”ìë¡œ ì „í™˜ (70% í™•ë¥ ë¡œ êµëŒ€, 30% í™•ë¥ ë¡œ ê³„ì†)
                if np.random.random() < 0.7:
                    speaker_idx = (speaker_idx + 1) % len(speakers)
                
                # 0.5-2ì´ˆ ì¹¨ë¬µ êµ¬ê°„
                silence_duration = 0.5 + np.random.random() * 1.5
                current_time = end_time + silence_duration
            
            self.logger.info(f"âœ… Mock í™”ì ë¶„í•  ì™„ë£Œ: {len(segments)}ê°œ êµ¬ê°„, "
                           f"{len(speakers)}ëª… í™”ì (ì‹œë®¬ë ˆì´ì…˜)")
            
            return segments
            
        except Exception as e:
            self.logger.error(f"Mock í™”ì ë¶„í•  ì‹¤íŒ¨: {e}")
            return []
    
    def analyze_speaker_profiles(self, segments: List[SpeakerSegment], total_duration: float) -> Dict[str, SpeakerProfile]:
        """í™”ìë³„ í”„ë¡œíŒŒì¼ ë¶„ì„
        
        Args:
            segments: í™”ì êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
            total_duration: ì „ì²´ ì˜ìƒ ê¸¸ì´
            
        Returns:
            í™”ì IDë³„ í”„ë¡œíŒŒì¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            profiles = {}
            
            # í™”ìë³„ êµ¬ê°„ ê·¸ë£¹í™”
            speaker_segments = defaultdict(list)
            for segment in segments:
                speaker_segments[segment.speaker_id].append(segment)
            
            # ê° í™”ìë³„ í”„ë¡œíŒŒì¼ ê³„ì‚°
            for speaker_id, speaker_segments_list in speaker_segments.items():
                # ê¸°ë³¸ í†µê³„
                total_speaking_duration = sum(s.duration for s in speaker_segments_list)
                segment_count = len(speaker_segments_list)
                avg_segment_duration = total_speaking_duration / segment_count if segment_count > 0 else 0.0
                speaking_ratio = total_speaking_duration / total_duration if total_duration > 0 else 0.0
                
                # ì‹œê°„ êµ¬ê°„ê³¼ ì‹ ë¢°ë„
                time_segments = [(s.start_time, s.end_time) for s in speaker_segments_list]
                confidence_scores = [s.confidence for s in speaker_segments_list]
                
                profile = SpeakerProfile(
                    speaker_id=speaker_id,
                    total_duration=total_speaking_duration,
                    segment_count=segment_count,
                    avg_segment_duration=avg_segment_duration,
                    speaking_ratio=speaking_ratio,
                    time_segments=time_segments,
                    confidence_scores=confidence_scores
                )
                
                profiles[speaker_id] = profile
            
            self.logger.info(f"í™”ì í”„ë¡œíŒŒì¼ ë¶„ì„ ì™„ë£Œ: {len(profiles)}ëª…")
            for speaker_id, profile in profiles.items():
                self.logger.info(f"  {speaker_id}: {profile.speaking_ratio:.1%} ({profile.total_duration:.1f}ì´ˆ, "
                               f"{profile.segment_count}êµ¬ê°„)")
            
            return profiles
            
        except Exception as e:
            self.logger.error(f"í™”ì í”„ë¡œíŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_speaker_timeline(self, segments: List[SpeakerSegment], fps: float = 30.0) -> List[Optional[str]]:
        """í”„ë ˆì„ë³„ í™”ì íƒ€ì„ë¼ì¸ ìƒì„±
        
        Args:
            segments: í™”ì êµ¬ê°„ ë¦¬ìŠ¤íŠ¸
            fps: í”„ë ˆì„ë ˆì´íŠ¸
            
        Returns:
            í”„ë ˆì„ë³„ í™”ì ID ë¦¬ìŠ¤íŠ¸ (Noneì€ ì¹¨ë¬µ)
        """
        try:
            if not segments:
                return []
            
            # ì „ì²´ ê¸¸ì´ ê³„ì‚°
            total_duration = max(s.end_time for s in segments)
            total_frames = int(total_duration * fps) + 1
            
            # í”„ë ˆì„ë³„ í™”ì í• ë‹¹
            timeline = [None] * total_frames
            
            for segment in segments:
                start_frame = int(segment.start_time * fps)
                end_frame = int(segment.end_time * fps)
                
                for frame_idx in range(start_frame, min(end_frame, total_frames)):
                    timeline[frame_idx] = segment.speaker_id
            
            self.logger.info(f"í™”ì íƒ€ì„ë¼ì¸ ìƒì„± ì™„ë£Œ: {total_frames}í”„ë ˆì„, "
                           f"{len([t for t in timeline if t is not None])}í”„ë ˆì„ í™”ì í™œë™")
            
            return timeline
            
        except Exception as e:
            self.logger.error(f"í™”ì íƒ€ì„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return []


class DiarizationMatcher:
    """í™”ì êµ¬ê°„ê³¼ ì–¼êµ´ ì¶”ì  ë§¤ì¹­"""
    
    def __init__(self):
        """DiarizationMatcher ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(__name__)
        self.matching_history = []
    
    def match_speakers_to_faces(self, diar_segments: List[SpeakerSegment], 
                               face_timeline: List[Dict[str, Any]], 
                               fps: float = 30.0) -> Dict[str, str]:
        """í™”ì IDì™€ ì–¼êµ´ ID ë§¤ì¹­
        
        Args:
            diar_segments: í™”ì ë¶„í•  ê²°ê³¼
            face_timeline: í”„ë ˆì„ë³„ ì–¼êµ´ ì¶”ì  ê²°ê³¼ [{'A': face_info, 'B': face_info}, ...]
            fps: í”„ë ˆì„ë ˆì´íŠ¸
            
        Returns:
            {'SPEAKER_00': 'A', 'SPEAKER_01': 'B'} ë§¤ì¹­ ê²°ê³¼
        """
        try:
            self.logger.info(f"ğŸ”— í™”ì-ì–¼êµ´ ë§¤ì¹­ ì‹œì‘: {len(diar_segments)}ê°œ í™”ì êµ¬ê°„, "
                           f"{len(face_timeline)}ê°œ í”„ë ˆì„")
            
            if not diar_segments or not face_timeline:
                return {}
            
            # í™”ì íƒ€ì„ë¼ì¸ ìƒì„±
            speaker_timeline = self._get_speaker_timeline_from_segments(diar_segments, len(face_timeline))
            
            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„
            temporal_matches = self._temporal_matching(speaker_timeline, face_timeline)
            frequency_matches = self._frequency_matching(diar_segments, face_timeline, fps)
            correlation_matches = self._correlation_matching(speaker_timeline, face_timeline)
            
            # íˆ¬í‘œ ê¸°ë°˜ ìµœì¢… ë§¤ì¹­
            final_matches = self._vote_based_matching(temporal_matches, frequency_matches, correlation_matches)
            
            self.logger.info(f"âœ… í™”ì-ì–¼êµ´ ë§¤ì¹­ ì™„ë£Œ: {final_matches}")
            return final_matches
            
        except Exception as e:
            self.logger.error(f"í™”ì-ì–¼êµ´ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {}
    
    def _get_speaker_timeline_from_segments(self, segments: List[SpeakerSegment], total_frames: int) -> List[Optional[str]]:
        """í™”ì êµ¬ê°„ì—ì„œ í”„ë ˆì„ë³„ íƒ€ì„ë¼ì¸ ìƒì„±"""
        timeline = [None] * total_frames
        fps = 30.0  # ê¸°ë³¸ í”„ë ˆì„ë ˆì´íŠ¸
        
        for segment in segments:
            start_frame = int(segment.start_time * fps)
            end_frame = int(segment.end_time * fps)
            
            for frame_idx in range(start_frame, min(end_frame, total_frames)):
                timeline[frame_idx] = segment.speaker_id
        
        return timeline
    
    def _temporal_matching(self, speaker_timeline: List[Optional[str]], 
                          face_timeline: List[Dict[str, Any]]) -> Dict[str, str]:
        """ì‹œê°„ì  ë™ì‹œ ë“±ì¥ ê¸°ë°˜ ë§¤ì¹­"""
        try:
            # í™”ìë³„ë¡œ ì–¼êµ´ A/Bì™€ ë™ì‹œ ë“±ì¥ íšŸìˆ˜ ê³„ì‚°
            speaker_face_cooccurrence = defaultdict(lambda: {'A': 0, 'B': 0})
            
            min_length = min(len(speaker_timeline), len(face_timeline))
            
            for frame_idx in range(min_length):
                current_speaker = speaker_timeline[frame_idx]
                face_frame = face_timeline[frame_idx]
                
                if current_speaker and isinstance(face_frame, dict):
                    # ì–¼êµ´ A/Bê°€ ìˆëŠ”ì§€ í™•ì¸
                    if 'A' in face_frame and face_frame['A'] is not None:
                        speaker_face_cooccurrence[current_speaker]['A'] += 1
                    if 'B' in face_frame and face_frame['B'] is not None:
                        speaker_face_cooccurrence[current_speaker]['B'] += 1
            
            # ê° í™”ìë¥¼ ë” ë§ì´ ë™ì‹œ ë“±ì¥í•œ ì–¼êµ´ì— ë§¤ì¹­
            temporal_matches = {}
            used_faces = set()
            
            # ë™ì‹œ ë“±ì¥ íšŸìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            speakers_sorted = sorted(speaker_face_cooccurrence.keys(), 
                                   key=lambda s: max(speaker_face_cooccurrence[s]['A'], 
                                                   speaker_face_cooccurrence[s]['B']), 
                                   reverse=True)
            
            for speaker in speakers_sorted:
                counts = speaker_face_cooccurrence[speaker]
                if counts['A'] > counts['B'] and 'A' not in used_faces:
                    temporal_matches[speaker] = 'A'
                    used_faces.add('A')
                elif counts['B'] > counts['A'] and 'B' not in used_faces:
                    temporal_matches[speaker] = 'B'
                    used_faces.add('B')
                elif 'A' not in used_faces:
                    temporal_matches[speaker] = 'A'
                    used_faces.add('A')
                elif 'B' not in used_faces:
                    temporal_matches[speaker] = 'B'
                    used_faces.add('B')
            
            self.logger.debug(f"ì‹œê°„ì  ë§¤ì¹­: {temporal_matches}")
            return temporal_matches
            
        except Exception as e:
            self.logger.error(f"ì‹œê°„ì  ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {}
    
    def _frequency_matching(self, segments: List[SpeakerSegment], 
                           face_timeline: List[Dict[str, Any]], fps: float) -> Dict[str, str]:
        """ë°œí™” ë¹ˆë„ vs ì–¼êµ´ í¬ê¸°/ì¤‘ì‹¬ë„ ë§¤ì¹­"""
        try:
            # í™”ìë³„ ë°œí™” í†µê³„
            speaker_stats = {}
            for segment in segments:
                if segment.speaker_id not in speaker_stats:
                    speaker_stats[segment.speaker_id] = {
                        'total_duration': 0.0,
                        'segment_count': 0,
                        'avg_confidence': 0.0
                    }
                
                stats = speaker_stats[segment.speaker_id]
                stats['total_duration'] += segment.duration
                stats['segment_count'] += 1
                stats['avg_confidence'] = (stats['avg_confidence'] * (stats['segment_count'] - 1) + segment.confidence) / stats['segment_count']
            
            # ì–¼êµ´ë³„ í‰ê·  í¬ê¸°/ì¤‘ì‹¬ë„ ê³„ì‚°
            face_stats = {'A': [], 'B': []}
            
            for frame_data in face_timeline:
                if isinstance(frame_data, dict):
                    for face_id in ['A', 'B']:
                        if face_id in frame_data and frame_data[face_id] is not None:
                            face_info = frame_data[face_id]
                            # ì–¼êµ´ í¬ê¸° ì¶”ì • (ë°•ìŠ¤ê°€ ìˆë‹¤ê³  ê°€ì •)
                            if hasattr(face_info, 'bbox') or isinstance(face_info, dict):
                                if hasattr(face_info, 'bbox'):
                                    bbox = face_info.bbox
                                elif isinstance(face_info, dict) and 'bbox' in face_info:
                                    bbox = face_info['bbox']
                                else:
                                    bbox = [0, 0, 100, 100]  # ê¸°ë³¸ê°’
                                
                                if len(bbox) >= 4:
                                    size = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                                    face_stats[face_id].append(size)
            
            # ì–¼êµ´ë³„ í‰ê·  í¬ê¸°
            face_avg_sizes = {}
            for face_id in ['A', 'B']:
                if face_stats[face_id]:
                    face_avg_sizes[face_id] = np.mean(face_stats[face_id])
                else:
                    face_avg_sizes[face_id] = 0
            
            # ë§¤ì¹­: ë” ë§ì´ ë§í•˜ëŠ” í™”ì â†’ ë” í° ì–¼êµ´
            speakers_by_duration = sorted(speaker_stats.keys(), 
                                        key=lambda s: speaker_stats[s]['total_duration'], 
                                        reverse=True)
            faces_by_size = sorted(face_avg_sizes.keys(), 
                                 key=lambda f: face_avg_sizes[f], 
                                 reverse=True)
            
            frequency_matches = {}
            for i, speaker in enumerate(speakers_by_duration):
                if i < len(faces_by_size):
                    frequency_matches[speaker] = faces_by_size[i]
            
            self.logger.debug(f"ë¹ˆë„ ë§¤ì¹­: {frequency_matches} "
                            f"(í™”ì ë°œí™”ì‹œê°„: {[(s, f'{speaker_stats[s]['total_duration']:.1f}s') for s in speakers_by_duration]})")
            return frequency_matches
            
        except Exception as e:
            self.logger.error(f"ë¹ˆë„ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {}
    
    def _correlation_matching(self, speaker_timeline: List[Optional[str]], 
                             face_timeline: List[Dict[str, Any]]) -> Dict[str, str]:
        """í™”ì í™œë™ê³¼ ì–¼êµ´ ì›€ì§ì„ ìƒê´€ê´€ê³„ ë§¤ì¹­"""
        try:
            # ê°„ë‹¨í•œ ìƒê´€ê´€ê³„: í™”ìê°€ ë§í•  ë•Œ ì–¼êµ´ ë³€í™” ê°ì§€
            # (ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤-ë¹„ë””ì˜¤ ìƒê´€ê´€ê³„ ì‚¬ìš©í•´ì•¼ í•¨)
            
            # ê¸°ë³¸ ë§¤ì¹­ (ì„ì‹œ)
            unique_speakers = list(set([s for s in speaker_timeline if s is not None]))
            face_ids = ['A', 'B']
            
            correlation_matches = {}
            for i, speaker in enumerate(unique_speakers):
                if i < len(face_ids):
                    correlation_matches[speaker] = face_ids[i]
            
            self.logger.debug(f"ìƒê´€ê´€ê³„ ë§¤ì¹­: {correlation_matches}")
            return correlation_matches
            
        except Exception as e:
            self.logger.error(f"ìƒê´€ê´€ê³„ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {}
    
    def _vote_based_matching(self, temporal: Dict[str, str], 
                            frequency: Dict[str, str], 
                            correlation: Dict[str, str]) -> Dict[str, str]:
        """íˆ¬í‘œ ê¸°ë°˜ ìµœì¢… ë§¤ì¹­ ê²°ì •"""
        try:
            # ëª¨ë“  í™”ì ìˆ˜ì§‘
            all_speakers = set(list(temporal.keys()) + list(frequency.keys()) + list(correlation.keys()))
            
            final_matches = {}
            
            for speaker in all_speakers:
                votes = {}
                
                # ê° ë°©ë²•ë³„ íˆ¬í‘œ
                if speaker in temporal:
                    face = temporal[speaker]
                    votes[face] = votes.get(face, 0) + 2  # ì‹œê°„ì  ë§¤ì¹­ì€ ê°€ì¤‘ì¹˜ ë†’ìŒ
                
                if speaker in frequency:
                    face = frequency[speaker]
                    votes[face] = votes.get(face, 0) + 1.5
                
                if speaker in correlation:
                    face = correlation[speaker]
                    votes[face] = votes.get(face, 0) + 1
                
                # ìµœë‹¤ ë“í‘œ ì–¼êµ´ ì„ íƒ
                if votes:
                    best_face = max(votes.keys(), key=lambda f: votes[f])
                    final_matches[speaker] = best_face
            
            # ì¤‘ë³µ ì œê±° (í•œ ì–¼êµ´ì— ì—¬ëŸ¬ í™”ì í• ë‹¹ëœ ê²½ìš°)
            face_to_speaker = {}
            conflicts = defaultdict(list)
            
            for speaker, face in final_matches.items():
                if face in face_to_speaker:
                    conflicts[face].append(speaker)
                    conflicts[face].append(face_to_speaker[face])
                else:
                    face_to_speaker[face] = speaker
            
            # ì¶©ëŒ í•´ê²° (ë” ë§ì´ ë§í•˜ëŠ” í™”ì ìš°ì„ )
            for face, conflicting_speakers in conflicts.items():
                # frequency ë§¤ì¹­ì—ì„œ ë” ë†’ì€ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ì§„ í™”ì ì„ íƒ
                best_speaker = conflicting_speakers[0]  # ì„ì‹œë¡œ ì²« ë²ˆì§¸ ì„ íƒ
                
                # ë‹¤ë¥¸ í™”ìë“¤ì€ ë‚¨ì€ ì–¼êµ´ì— í• ë‹¹
                for speaker in conflicting_speakers[1:]:
                    available_faces = ['A', 'B']
                    used_faces = set(face_to_speaker.keys())
                    remaining_faces = [f for f in available_faces if f not in used_faces]
                    
                    if remaining_faces:
                        face_to_speaker[remaining_faces[0]] = speaker
                
                face_to_speaker[face] = best_speaker
            
            # ê²°ê³¼ ë’¤ì§‘ê¸° (speaker -> face)
            result = {speaker: face for face, speaker in face_to_speaker.items()}
            
            self.logger.info(f"íˆ¬í‘œ ê¸°ë°˜ ìµœì¢… ë§¤ì¹­: {result}")
            return result
            
        except Exception as e:
            self.logger.error(f"íˆ¬í‘œ ê¸°ë°˜ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_realtime_speaker_change(self, current_frame: int, speaker_timeline: List[Optional[str]], 
                                   window_size: int = 90) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ í™”ì ë³€ê²½ ê°ì§€ (3ì´ˆ ìœˆë„ìš° @ 30fps)
        
        Args:
            current_frame: í˜„ì¬ í”„ë ˆì„ ë²ˆí˜¸
            speaker_timeline: í”„ë ˆì„ë³„ í™”ì íƒ€ì„ë¼ì¸
            window_size: ë¶„ì„ ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ 90í”„ë ˆì„ = 3ì´ˆ)
            
        Returns:
            í™”ì ë³€ê²½ ì •ë³´
        """
        try:
            if current_frame < window_size or current_frame >= len(speaker_timeline):
                return {'speaker_change': False, 'current_speaker': None}
            
            # í˜„ì¬ ìœˆë„ìš°ì™€ ì´ì „ ìœˆë„ìš°
            current_window = speaker_timeline[current_frame-window_size//2:current_frame+window_size//2]
            prev_window = speaker_timeline[current_frame-window_size:current_frame-window_size//2]
            
            # ê° ìœˆë„ìš°ì˜ ì£¼ìš” í™”ì
            current_speakers = [s for s in current_window if s is not None]
            prev_speakers = [s for s in prev_window if s is not None]
            
            current_main = Counter(current_speakers).most_common(1)
            prev_main = Counter(prev_speakers).most_common(1)
            
            current_speaker = current_main[0][0] if current_main else None
            prev_speaker = prev_main[0][0] if prev_main else None
            
            speaker_change = (current_speaker != prev_speaker) and (current_speaker is not None)
            
            result = {
                'speaker_change': speaker_change,
                'current_speaker': current_speaker,
                'prev_speaker': prev_speaker,
                'confidence': current_main[0][1] / len(current_speakers) if current_main and current_speakers else 0.0
            }
            
            if speaker_change:
                self.logger.info(f"ğŸ”„ í™”ì ë³€ê²½ ê°ì§€ (í”„ë ˆì„ {current_frame}): {prev_speaker} â†’ {current_speaker}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì‹¤ì‹œê°„ í™”ì ë³€ê²½ ê°ì§€ ì‹¤íŒ¨: {e}")
            return {'speaker_change': False, 'current_speaker': None}


# í†µí•© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_audio_diarization():
    """Audio Diarization ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Audio Diarization ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. SpeakerDiarization í…ŒìŠ¤íŠ¸
    print("\n1. SpeakerDiarization í…ŒìŠ¤íŠ¸")
    diarizer = SpeakerDiarization()
    
    print(f"   pyannote.audio ì‚¬ìš© ê°€ëŠ¥: {diarizer.pipeline is not None}")
    
    # Mock ë¹„ë””ì˜¤ë¡œ í™”ì ë¶„í•  í…ŒìŠ¤íŠ¸
    mock_video_path = "test_video.mp4"  # ì‹¤ì œë¡œëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŒ
    segments = diarizer.diarize_audio(mock_video_path, min_speakers=2, max_speakers=3)
    
    print(f"   ê²€ì¶œëœ í™”ì êµ¬ê°„: {len(segments)}ê°œ")
    if segments:
        speakers = set(s.speaker_id for s in segments)
        print(f"   í™”ì ID: {speakers}")
        print(f"   ì²« ë²ˆì§¸ êµ¬ê°„: {segments[0].speaker_id} ({segments[0].start_time:.1f}-{segments[0].end_time:.1f}ì´ˆ)")
    
    # í™”ì í”„ë¡œíŒŒì¼ ë¶„ì„
    if segments:
        total_duration = max(s.end_time for s in segments)
        profiles = diarizer.analyze_speaker_profiles(segments, total_duration)
        print(f"   í™”ì í”„ë¡œíŒŒì¼: {len(profiles)}ê°œ")
        
        for speaker_id, profile in profiles.items():
            print(f"     {speaker_id}: {profile.speaking_ratio:.1%} ë°œí™” "
                  f"({profile.total_duration:.1f}ì´ˆ, {profile.segment_count}êµ¬ê°„)")
    
    # 2. DiarizationMatcher í…ŒìŠ¤íŠ¸
    print("\n2. DiarizationMatcher í…ŒìŠ¤íŠ¸")
    matcher = DiarizationMatcher()
    
    # Mock ì–¼êµ´ íƒ€ì„ë¼ì¸ ìƒì„±
    mock_face_timeline = []
    for i in range(100):  # 100í”„ë ˆì„
        face_data = {
            'A': {'bbox': [50, 50, 150, 150]} if i % 3 != 0 else None,
            'B': {'bbox': [200, 50, 300, 150]} if i % 4 != 0 else None
        }
        mock_face_timeline.append(face_data)
    
    # í™”ì-ì–¼êµ´ ë§¤ì¹­ í…ŒìŠ¤íŠ¸
    if segments:
        matches = matcher.match_speakers_to_faces(segments, mock_face_timeline)
        print(f"   í™”ì-ì–¼êµ´ ë§¤ì¹­ ê²°ê³¼: {matches}")
        
        # ì‹¤ì‹œê°„ í™”ì ë³€ê²½ ê°ì§€ í…ŒìŠ¤íŠ¸
        speaker_timeline = diarizer.get_speaker_timeline(segments, fps=30.0)
        if speaker_timeline and len(speaker_timeline) > 90:
            change_info = matcher.get_realtime_speaker_change(95, speaker_timeline)
            print(f"   í™”ì ë³€ê²½ ê°ì§€ (95í”„ë ˆì„): {change_info}")
    
    # 3. í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
    print("\n3. í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    
    if segments and mock_face_timeline:
        # ì „ì²´ íŒŒì´í”„ë¼ì¸
        print("   1) í™”ì ë¶„í•  â†’ 2) í™”ì-ì–¼êµ´ ë§¤ì¹­ â†’ 3) ì‹¤ì‹œê°„ ë³€ê²½ ê°ì§€")
        
        # í™”ì íƒ€ì„ë¼ì¸ ìƒì„±
        timeline = diarizer.get_speaker_timeline(segments, fps=30.0)
        print(f"   í™”ì íƒ€ì„ë¼ì¸: {len(timeline)}í”„ë ˆì„")
        
        # íƒ€ì„ë¼ì¸ ë¶„ì„
        if timeline:
            active_frames = [t for t in timeline if t is not None]
            print(f"   í™œì„± í”„ë ˆì„: {len(active_frames)}/{len(timeline)} ({len(active_frames)/len(timeline)*100:.1f}%)")
            
            speaker_distribution = Counter(active_frames)
            print(f"   í™”ì ë¶„í¬: {dict(speaker_distribution)}")
    
    print("\nâœ… Audio Diarization ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_audio_diarization()