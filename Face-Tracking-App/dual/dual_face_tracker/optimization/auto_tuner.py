"""
ìë™ ì„±ëŠ¥ íŠœë‹ ì‹œìŠ¤í…œ

ì‹¤í–‰ ì¤‘ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ìë™ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import time
import json
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
from enum import Enum

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

from ..utils.logger import logger
from ..utils.exceptions import OptimizationError


class TuningMode(Enum):
    """íŠœë‹ ëª¨ë“œ"""
    CONSERVATIVE = "conservative"    # ì•ˆì „í•œ ìµœì í™”
    BALANCED = "balanced"           # ê· í˜•ì¡íŒ ìµœì í™”
    AGGRESSIVE = "aggressive"       # ê³µê²©ì  ìµœì í™”


@dataclass
class TuningParameter:
    """íŠœë‹ íŒŒë¼ë¯¸í„° ì •ì˜"""
    name: str
    current_value: Any
    min_value: Any
    max_value: Any
    step_size: Any
    impact_weight: float = 1.0  # ì„±ëŠ¥ ì˜í–¥ë„ ê°€ì¤‘ì¹˜
    
    def can_increase(self) -> bool:
        """ì¦ê°€ ê°€ëŠ¥ ì—¬ë¶€"""
        return self.current_value < self.max_value
    
    def can_decrease(self) -> bool:
        """ê°ì†Œ ê°€ëŠ¥ ì—¬ë¶€"""
        return self.current_value > self.min_value
    
    def increase(self):
        """ê°’ ì¦ê°€"""
        if self.can_increase():
            if isinstance(self.current_value, int):
                self.current_value = min(self.max_value, self.current_value + self.step_size)
            else:
                self.current_value = min(self.max_value, self.current_value * self.step_size)
    
    def decrease(self):
        """ê°’ ê°ì†Œ"""
        if self.can_decrease():
            if isinstance(self.current_value, int):
                self.current_value = max(self.min_value, self.current_value - self.step_size)
            else:
                self.current_value = max(self.min_value, self.current_value / self.step_size)


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ì§€í‘œ"""
    timestamp: float
    fps: float
    gpu_utilization: float
    memory_usage_mb: float
    processing_latency: float
    error_rate: float
    throughput_score: float = 0  # ì¢…í•© ì²˜ë¦¬ëŸ‰ ì ìˆ˜
    
    def calculate_score(self) -> float:
        """ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (0-100)"""
        # FPS ì ìˆ˜ (30fpsë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”)
        fps_score = min(100, (self.fps / 30) * 100)
        
        # GPU í™œìš©ë¥  ì ìˆ˜ (70-90%ê°€ ìµœì )
        if 70 <= self.gpu_utilization <= 90:
            gpu_score = 100
        elif self.gpu_utilization < 70:
            gpu_score = (self.gpu_utilization / 70) * 100
        else:
            gpu_score = max(0, 100 - (self.gpu_utilization - 90) * 2)
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ ì ìˆ˜ (80% ì´í•˜ê°€ ì•ˆì „)
        memory_percent = self.memory_usage_mb / 32000 * 100  # 32GB ê¸°ì¤€
        if memory_percent <= 80:
            memory_score = 100
        else:
            memory_score = max(0, 100 - (memory_percent - 80) * 5)
        
        # ì§€ì—°ì‹œê°„ ì ìˆ˜ (50ms ì´í•˜ê°€ ì¢‹ìŒ)
        if self.processing_latency <= 50:
            latency_score = 100
        else:
            latency_score = max(0, 100 - (self.processing_latency - 50))
        
        # ì—ëŸ¬ìœ¨ ì ìˆ˜ (0%ê°€ ìµœì )
        error_score = max(0, 100 - self.error_rate * 100)
        
        # ê°€ì¤‘ í‰ê· 
        self.throughput_score = (
            fps_score * 0.3 +
            gpu_score * 0.25 +
            memory_score * 0.2 +
            latency_score * 0.15 +
            error_score * 0.1
        )
        
        return self.throughput_score


class AutoTuner:
    """
    ìë™ ì„±ëŠ¥ íŠœë„ˆ
    
    ê¸°ëŠ¥:
    - ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ìë™ ì¡°ì •
    - ë°°ì¹˜ í¬ê¸° ìµœì í™”
    - GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
    - ì¸ì½”ë”© í’ˆì§ˆ/ì†ë„ ê· í˜• ì¡°ì •
    - A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ìµœì ê°’ íƒìƒ‰
    - ì„±ëŠ¥ ê¸°ë¡ ë° ë¶„ì„
    """
    
    def __init__(self, 
                 mode: TuningMode = TuningMode.BALANCED,
                 tuning_interval: float = 30.0,
                 min_samples: int = 5):
        """
        Args:
            mode: íŠœë‹ ëª¨ë“œ
            tuning_interval: íŠœë‹ ì‹¤í–‰ ê°„ê²© (ì´ˆ)
            min_samples: íŠœë‹ ì „ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        """
        self.mode = mode
        self.tuning_interval = tuning_interval
        self.min_samples = min_samples
        
        # íŠœë‹ íŒŒë¼ë¯¸í„°ë“¤
        self.parameters = self._init_parameters()
        
        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ (ìµœê·¼ 100ê°œ)
        self.performance_history = deque(maxlen=100)
        
        # íŠœë‹ ê¸°ë¡
        self.tuning_history: List[Dict[str, Any]] = []
        
        # ìµœì  ì„¤ì • ê¸°ë¡
        self.best_config: Optional[Dict[str, Any]] = None
        self.best_score: float = 0
        
        # í˜„ì¬ íŠœë‹ ìƒíƒœ
        self.is_tuning = False
        self.last_tuning_time = 0
        self.tuning_round = 0
        
        # ì•ˆì •ì„± ì²´í¬
        self.consecutive_improvements = 0
        self.consecutive_degradations = 0
        
        logger.info(f"âš™ï¸ AutoTuner ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë“œ: {mode.value})")
    
    def _init_parameters(self) -> Dict[str, TuningParameter]:
        """íŠœë‹ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”"""
        params = {}
        
        # ë°°ì¹˜ í¬ê¸°
        params['batch_size'] = TuningParameter(
            name='batch_size',
            current_value=4,
            min_value=1,
            max_value=16,
            step_size=1,
            impact_weight=0.8
        )
        
        # CUDA ìŠ¤íŠ¸ë¦¼ ìˆ˜
        params['cuda_streams'] = TuningParameter(
            name='cuda_streams',
            current_value=4,
            min_value=2,
            max_value=8,
            step_size=1,
            impact_weight=0.6
        )
        
        # ë©”ëª¨ë¦¬ í’€ í¬ê¸° (MB)
        params['memory_pool_mb'] = TuningParameter(
            name='memory_pool_mb',
            current_value=2048,
            min_value=512,
            max_value=8192,
            step_size=512,
            impact_weight=0.4
        )
        
        # ì¸ì½”ë”© í’ˆì§ˆ (CRF ê°’)
        params['encoding_crf'] = TuningParameter(
            name='encoding_crf',
            current_value=23,
            min_value=18,
            max_value=28,
            step_size=1,
            impact_weight=0.3
        )
        
        # í”„ë ˆì„ ìŠ¤í‚µ ë¹„ìœ¨ (0.0 = ìŠ¤í‚µ ì—†ìŒ)
        params['frame_skip_ratio'] = TuningParameter(
            name='frame_skip_ratio',
            current_value=0.0,
            min_value=0.0,
            max_value=0.5,
            step_size=0.1,
            impact_weight=0.5
        )
        
        return params
    
    def add_performance_sample(self, 
                             fps: float,
                             gpu_util: float,
                             memory_mb: float,
                             latency_ms: float,
                             error_rate: float = 0.0):
        """ì„±ëŠ¥ ìƒ˜í”Œ ì¶”ê°€"""
        metrics = PerformanceMetrics(
            timestamp=time.time(),
            fps=fps,
            gpu_utilization=gpu_util,
            memory_usage_mb=memory_mb,
            processing_latency=latency_ms,
            error_rate=error_rate
        )
        
        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        score = metrics.calculate_score()
        
        self.performance_history.append(metrics)
        
        logger.debug(f"ğŸ“Š ì„±ëŠ¥ ìƒ˜í”Œ ì¶”ê°€: FPS={fps:.1f}, GPU={gpu_util:.1f}%, "
                    f"ë©”ëª¨ë¦¬={memory_mb:.0f}MB, ì ìˆ˜={score:.1f}")
        
        # ìµœê³  ì„±ëŠ¥ ê¸°ë¡ ì—…ë°ì´íŠ¸
        if score > self.best_score:
            self.best_score = score
            self.best_config = self.get_current_config()
            logger.info(f"ğŸ† ìµœê³  ì„±ëŠ¥ ê°±ì‹ : {score:.1f}ì ")
        
        # ìë™ íŠœë‹ íŠ¸ë¦¬ê±°
        self._check_auto_tuning()
    
    def _check_auto_tuning(self):
        """ìë™ íŠœë‹ í•„ìš”ì„± ì²´í¬"""
        current_time = time.time()
        
        # ê°„ê²© ì²´í¬
        if current_time - self.last_tuning_time < self.tuning_interval:
            return
        
        # ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ì²´í¬
        if len(self.performance_history) < self.min_samples:
            return
        
        # íŠœë‹ ì‹¤í–‰
        self.run_auto_tuning()
    
    def run_auto_tuning(self):
        """ìë™ íŠœë‹ ì‹¤í–‰"""
        if self.is_tuning:
            return
        
        self.is_tuning = True
        self.last_tuning_time = time.time()
        self.tuning_round += 1
        
        logger.info(f"ğŸ”§ ìë™ íŠœë‹ ì‹œì‘ (ë¼ìš´ë“œ {self.tuning_round})")
        
        try:
            # í˜„ì¬ ì„±ëŠ¥ ë¶„ì„
            current_perf = self._analyze_current_performance()
            
            # íŠœë‹ ì „ëµ ê²°ì •
            tuning_actions = self._decide_tuning_actions(current_perf)
            
            # íŠœë‹ ì‹¤í–‰
            improvements = self._apply_tuning_actions(tuning_actions)
            
            # ê²°ê³¼ ê¸°ë¡
            self._record_tuning_result(current_perf, tuning_actions, improvements)
            
            logger.info(f"âœ… ìë™ íŠœë‹ ì™„ë£Œ: {len(improvements)}ê°œ ê°œì„ ")
            
        except Exception as e:
            logger.error(f"âŒ ìë™ íŠœë‹ ì‹¤íŒ¨: {e}")
        finally:
            self.is_tuning = False
    
    def _analyze_current_performance(self) -> Dict[str, float]:
        """í˜„ì¬ ì„±ëŠ¥ ë¶„ì„"""
        if not self.performance_history:
            return {}
        
        recent_samples = list(self.performance_history)[-self.min_samples:]
        
        # í‰ê·  ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        avg_fps = sum(m.fps for m in recent_samples) / len(recent_samples)
        avg_gpu = sum(m.gpu_utilization for m in recent_samples) / len(recent_samples)
        avg_memory = sum(m.memory_usage_mb for m in recent_samples) / len(recent_samples)
        avg_latency = sum(m.processing_latency for m in recent_samples) / len(recent_samples)
        avg_error = sum(m.error_rate for m in recent_samples) / len(recent_samples)
        avg_score = sum(m.calculate_score() for m in recent_samples) / len(recent_samples)
        
        # ì„±ëŠ¥ ë³€í™” íŠ¸ë Œë“œ ë¶„ì„
        if len(recent_samples) >= 3:
            early_score = sum(m.calculate_score() for m in recent_samples[:2]) / 2
            late_score = sum(m.calculate_score() for m in recent_samples[-2:]) / 2
            trend = late_score - early_score
        else:
            trend = 0
        
        return {
            'avg_fps': avg_fps,
            'avg_gpu_util': avg_gpu,
            'avg_memory_mb': avg_memory,
            'avg_latency': avg_latency,
            'avg_error_rate': avg_error,
            'avg_score': avg_score,
            'trend': trend
        }
    
    def _decide_tuning_actions(self, current_perf: Dict[str, float]) -> List[Tuple[str, str]]:
        """íŠœë‹ ì•¡ì…˜ ê²°ì •"""
        actions = []
        
        avg_fps = current_perf.get('avg_fps', 0)
        avg_gpu = current_perf.get('avg_gpu_util', 0)
        avg_memory = current_perf.get('avg_memory_mb', 0)
        avg_latency = current_perf.get('avg_latency', 0)
        
        # ë‚®ì€ FPS ë¬¸ì œ
        if avg_fps < 20:
            if avg_gpu < 70:  # GPU í™œìš©ë¥ ì´ ë‚®ìœ¼ë©´
                actions.append(('batch_size', 'increase'))
                actions.append(('cuda_streams', 'increase'))
            else:  # GPUê°€ í¬í™”ë˜ë©´
                actions.append(('encoding_crf', 'increase'))  # í’ˆì§ˆ ë‚®ì¶°ì„œ ì†ë„ í–¥ìƒ
                actions.append(('frame_skip_ratio', 'increase'))  # í”„ë ˆì„ ìŠ¤í‚µ
        
        # ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory_percent = avg_memory / 32000 * 100
        if memory_percent > 85:
            actions.append(('batch_size', 'decrease'))
            actions.append(('memory_pool_mb', 'decrease'))
        
        # ë†’ì€ ì§€ì—°ì‹œê°„
        if avg_latency > 100:
            actions.append(('batch_size', 'decrease'))
            actions.append(('frame_skip_ratio', 'increase'))
        
        # GPU í™œìš©ë¥ ì´ ë„ˆë¬´ ë‚®ìŒ
        if avg_gpu < 50:
            actions.append(('batch_size', 'increase'))
            actions.append(('cuda_streams', 'increase'))
        
        # ëª¨ë“œë³„ ì¶”ê°€ ì•¡ì…˜
        if self.mode == TuningMode.AGGRESSIVE:
            if avg_fps > 40:  # ì„±ëŠ¥ì´ ì¢‹ìœ¼ë©´ í’ˆì§ˆ í–¥ìƒ
                actions.append(('encoding_crf', 'decrease'))
        elif self.mode == TuningMode.CONSERVATIVE:
            # ì•ˆì •ì„± ìš°ì„  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë‚®ì¶¤
            if memory_percent > 70:
                actions.append(('batch_size', 'decrease'))
        
        return actions
    
    def _apply_tuning_actions(self, actions: List[Tuple[str, str]]) -> List[str]:
        """íŠœë‹ ì•¡ì…˜ ì ìš©"""
        improvements = []
        
        for param_name, action in actions:
            if param_name not in self.parameters:
                continue
            
            param = self.parameters[param_name]
            old_value = param.current_value
            
            if action == 'increase' and param.can_increase():
                param.increase()
                improvements.append(f"{param_name}: {old_value} â†’ {param.current_value}")
                logger.info(f"ğŸ“ˆ {param_name} ì¦ê°€: {old_value} â†’ {param.current_value}")
                
            elif action == 'decrease' and param.can_decrease():
                param.decrease()
                improvements.append(f"{param_name}: {old_value} â†’ {param.current_value}")
                logger.info(f"ğŸ“‰ {param_name} ê°ì†Œ: {old_value} â†’ {param.current_value}")
        
        return improvements
    
    def _record_tuning_result(self, 
                            current_perf: Dict[str, float],
                            actions: List[Tuple[str, str]],
                            improvements: List[str]):
        """íŠœë‹ ê²°ê³¼ ê¸°ë¡"""
        result = {
            'round': self.tuning_round,
            'timestamp': time.time(),
            'performance_before': current_perf,
            'actions_taken': actions,
            'improvements': improvements,
            'config_after': self.get_current_config()
        }
        
        self.tuning_history.append(result)
        
        # ì—°ì† ê°œì„ /ì•…í™” ì¶”ì 
        if improvements:
            self.consecutive_improvements += 1
            self.consecutive_degradations = 0
        else:
            self.consecutive_degradations += 1
            self.consecutive_improvements = 0
    
    def get_current_config(self) -> Dict[str, Any]:
        """í˜„ì¬ ì„¤ì • ë°˜í™˜"""
        return {name: param.current_value for name, param in self.parameters.items()}
    
    def apply_config(self, config: Dict[str, Any]):
        """ì„¤ì • ì ìš©"""
        for name, value in config.items():
            if name in self.parameters:
                self.parameters[name].current_value = value
                logger.info(f"âš™ï¸ {name} ì„¤ì •: {value}")
    
    def get_optimal_batch_size(self) -> int:
        """í˜„ì¬ ìƒí™©ì— ë§ëŠ” ìµœì  ë°°ì¹˜ í¬ê¸° ë°˜í™˜"""
        return self.parameters['batch_size'].current_value
    
    def get_recommended_settings(self) -> Dict[str, Any]:
        """í˜„ì¬ ìƒí™©ì— ë§ëŠ” ê¶Œì¥ ì„¤ì •"""
        if self.best_config and self.best_score > 80:
            return self.best_config.copy()
        
        return self.get_current_config()
    
    def reset_to_defaults(self):
        """ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”"""
        defaults = {
            'batch_size': 4,
            'cuda_streams': 4,
            'memory_pool_mb': 2048,
            'encoding_crf': 23,
            'frame_skip_ratio': 0.0
        }
        
        self.apply_config(defaults)
        logger.info("ğŸ”„ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”")
    
    def save_tuning_history(self, file_path: str):
        """íŠœë‹ ê¸°ë¡ ì €ì¥"""
        history_data = {
            'mode': self.mode.value,
            'tuning_rounds': self.tuning_round,
            'best_score': self.best_score,
            'best_config': self.best_config,
            'current_config': self.get_current_config(),
            'tuning_history': self.tuning_history
        }
        
        with open(file_path, 'w') as f:
            json.dump(history_data, f, indent=2)
        
        logger.info(f"ğŸ’¾ íŠœë‹ ê¸°ë¡ ì €ì¥: {file_path}")
    
    def load_tuning_history(self, file_path: str):
        """íŠœë‹ ê¸°ë¡ ë¡œë“œ"""
        try:
            with open(file_path, 'r') as f:
                history_data = json.load(f)
            
            self.tuning_round = history_data.get('tuning_rounds', 0)
            self.best_score = history_data.get('best_score', 0)
            self.best_config = history_data.get('best_config')
            self.tuning_history = history_data.get('tuning_history', [])
            
            # ìµœì  ì„¤ì • ì ìš©
            if self.best_config:
                self.apply_config(self.best_config)
            
            logger.info(f"ğŸ“‚ íŠœë‹ ê¸°ë¡ ë¡œë“œ: {file_path}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ íŠœë‹ ê¸°ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def get_tuning_stats(self) -> Dict[str, Any]:
        """íŠœë‹ í†µê³„ ë°˜í™˜"""
        return {
            'tuning_rounds': self.tuning_round,
            'best_score': self.best_score,
            'current_score': self.performance_history[-1].calculate_score() if self.performance_history else 0,
            'consecutive_improvements': self.consecutive_improvements,
            'consecutive_degradations': self.consecutive_degradations,
            'total_samples': len(self.performance_history),
            'is_tuning': self.is_tuning,
            'mode': self.mode.value
        }
    
    def print_tuning_summary(self):
        """íŠœë‹ ìš”ì•½ ì¶œë ¥"""
        stats = self.get_tuning_stats()
        config = self.get_current_config()
        
        print(f"""
âš™ï¸ ìë™ íŠœë‹ ìš”ì•½:
   â€¢ íŠœë‹ ë¼ìš´ë“œ: {stats['tuning_rounds']}íšŒ
   â€¢ ìµœê³  ì„±ëŠ¥: {stats['best_score']:.1f}ì 
   â€¢ í˜„ì¬ ì„±ëŠ¥: {stats['current_score']:.1f}ì 
   â€¢ ì—°ì† ê°œì„ : {stats['consecutive_improvements']}íšŒ
   â€¢ ëª¨ë“œ: {stats['mode']}

ğŸ›ï¸ í˜„ì¬ ì„¤ì •:
   â€¢ ë°°ì¹˜ í¬ê¸°: {config['batch_size']}
   â€¢ CUDA ìŠ¤íŠ¸ë¦¼: {config['cuda_streams']}
   â€¢ ë©”ëª¨ë¦¬ í’€: {config['memory_pool_mb']}MB
   â€¢ ì¸ì½”ë”© CRF: {config['encoding_crf']}
   â€¢ í”„ë ˆì„ ìŠ¤í‚µ: {config['frame_skip_ratio']:.1f}
        """)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª AutoTuner í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    tuner = AutoTuner(mode=TuningMode.BALANCED, tuning_interval=5.0)
    
    # ê°€ì§œ ì„±ëŠ¥ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
    import random
    
    for i in range(10):
        fps = random.uniform(15, 35)
        gpu_util = random.uniform(40, 90)
        memory_mb = random.uniform(8000, 25000)
        latency = random.uniform(30, 120)
        
        tuner.add_performance_sample(fps, gpu_util, memory_mb, latency)
        
        print(f"ğŸ“Š ìƒ˜í”Œ {i+1}: FPS={fps:.1f}, GPU={gpu_util:.1f}%")
        time.sleep(1)
    
    tuner.print_tuning_summary()
    
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")