"""
í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸

ì‹¤ì œ ìš´ì˜ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ì¢…í•©ì ì¸ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
"""

import asyncio
import time
import random
import psutil
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

from ..utils.logger import logger
from ..monitoring.hardware_monitor import HardwareMonitor
from ..monitoring.performance_reporter import PerformanceReporter, create_video_result
from ..recovery.recovery_manager import StreamRecoveryManager
from ..recovery.memory_manager import MemoryManager


@dataclass
class TestScenario:
    """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜"""
    name: str
    description: str
    video_count: int
    video_duration_minutes: float
    resolution: str
    concurrent_streams: int
    duration_minutes: float
    expected_errors: bool = False
    stress_test: bool = False


@dataclass
class TestResult:
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    scenario_name: str
    start_time: float
    end_time: float
    success: bool
    videos_processed: int
    videos_successful: int
    total_processing_time: float
    average_fps: float
    peak_gpu_util: float
    peak_memory_mb: float
    errors_encountered: List[str]
    performance_score: float
    
    @property
    def duration_minutes(self) -> float:
        return (self.end_time - self.start_time) / 60
    
    @property
    def success_rate(self) -> float:
        if self.videos_processed > 0:
            return (self.videos_successful / self.videos_processed) * 100
        return 0


class ProductionTestSuite:
    """
    í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
    
    ê¸°ëŠ¥:
    - ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì˜ ë¶€í•˜ í…ŒìŠ¤íŠ¸
    - ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
    - ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€
    - ì„±ëŠ¥ íšŒê·€ í…ŒìŠ¤íŠ¸
    - ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ ê²€ì¦
    """
    
    def __init__(self, 
                 test_data_dir: str = "test_data",
                 results_dir: str = "test_results"):
        self.test_data_dir = Path(test_data_dir)
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(exist_ok=True)
        
        # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
        self.scenarios = self._define_test_scenarios()
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼
        self.test_results: List[TestResult] = []
        
        # ëª¨ë‹ˆí„°ë§ ì»´í¬ë„ŒíŠ¸
        self.hardware_monitor: Optional[HardwareMonitor] = None
        self.performance_reporter: Optional[PerformanceReporter] = None
        self.recovery_manager: Optional[StreamRecoveryManager] = None
        self.memory_manager: Optional[MemoryManager] = None
        
        # í…ŒìŠ¤íŠ¸ ìƒíƒœ
        self.current_test: Optional[str] = None
        self.abort_requested = False
        
        logger.info("ğŸ§ª ProductionTestSuite ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _define_test_scenarios(self) -> List[TestScenario]:
        """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜"""
        return [
            TestScenario(
                name="basic_functionality",
                description="ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (4ê°œ ë¹„ë””ì˜¤, ë‹¨ì¼ ë°°ì¹˜)",
                video_count=4,
                video_duration_minutes=2.0,
                resolution="1080p",
                concurrent_streams=4,
                duration_minutes=5
            ),
            TestScenario(
                name="stress_test_multiple_batches",
                description="ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (20ê°œ ë¹„ë””ì˜¤, ë‹¤ì¤‘ ë°°ì¹˜)",
                video_count=20,
                video_duration_minutes=3.0,
                resolution="1080p",
                concurrent_streams=4,
                duration_minutes=15,
                stress_test=True
            ),
            TestScenario(
                name="high_resolution_test",
                description="ê³ í•´ìƒë„ í…ŒìŠ¤íŠ¸ (4K ë¹„ë””ì˜¤)",
                video_count=4,
                video_duration_minutes=1.0,
                resolution="4K",
                concurrent_streams=2,  # ë©”ëª¨ë¦¬ ì ˆì•½
                duration_minutes=8
            ),
            TestScenario(
                name="long_duration_stability",
                description="ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (30ë¶„ ì—°ì†)",
                video_count=100,
                video_duration_minutes=1.0,
                resolution="720p",
                concurrent_streams=4,
                duration_minutes=30
            ),
            TestScenario(
                name="memory_pressure_test",
                description="ë©”ëª¨ë¦¬ ì••ë°• í…ŒìŠ¤íŠ¸ (ëŒ€ìš©ëŸ‰ ë°°ì¹˜)",
                video_count=8,
                video_duration_minutes=5.0,
                resolution="1080p",
                concurrent_streams=8,
                duration_minutes=12,
                stress_test=True
            ),
            TestScenario(
                name="error_recovery_test",
                description="ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ (ì˜ë„ì  ì—ëŸ¬ ë°œìƒ)",
                video_count=10,
                video_duration_minutes=2.0,
                resolution="1080p",
                concurrent_streams=4,
                duration_minutes=8,
                expected_errors=True
            ),
            TestScenario(
                name="mixed_workload_test",
                description="í˜¼í•© ì›Œí¬ë¡œë“œ í…ŒìŠ¤íŠ¸ (ë‹¤ì–‘í•œ í•´ìƒë„)",
                video_count=12,
                video_duration_minutes=2.5,
                resolution="mixed",
                concurrent_streams=4,
                duration_minutes=10
            )
        ]
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹œì‘")
        
        overall_start = time.time()
        self.test_results.clear()
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self._start_monitoring()
        
        try:
            for scenario in self.scenarios:
                if self.abort_requested:
                    logger.warning("âš ï¸ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ ìš”ì²­ë¨")
                    break
                
                logger.info(f"ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ì‹œì‘: {scenario.name}")
                result = await self.run_scenario(scenario)
                self.test_results.append(result)
                
                # ì‹œë‚˜ë¦¬ì˜¤ ê°„ ì •ë¦¬ ì‹œê°„
                if not self.abort_requested:
                    await self._cleanup_between_tests()
        
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        finally:
            self._stop_monitoring()
        
        overall_time = time.time() - overall_start
        
        # ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±
        summary = self._generate_test_summary(overall_time)
        self._save_test_results(summary)
        
        logger.info(f"âœ… í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ({overall_time/60:.1f}ë¶„)")
        
        return summary
    
    async def run_scenario(self, scenario: TestScenario) -> TestResult:
        """ê°œë³„ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        self.current_test = scenario.name
        start_time = time.time()
        
        # ê²°ê³¼ ì´ˆê¸°í™”
        result = TestResult(
            scenario_name=scenario.name,
            start_time=start_time,
            end_time=0,
            success=False,
            videos_processed=0,
            videos_successful=0,
            total_processing_time=0,
            average_fps=0,
            peak_gpu_util=0,
            peak_memory_mb=0,
            errors_encountered=[],
            performance_score=0
        )
        
        try:
            logger.info(f"ğŸ¬ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰: {scenario.description}")
            
            # í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ìƒì„±/ì¤€ë¹„
            test_videos = await self._prepare_test_videos(scenario)
            
            # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤í–‰
            if scenario.name == "error_recovery_test":
                await self._run_error_recovery_test(scenario, test_videos, result)
            elif scenario.name == "long_duration_stability":
                await self._run_stability_test(scenario, test_videos, result)
            elif scenario.name == "memory_pressure_test":
                await self._run_memory_pressure_test(scenario, test_videos, result)
            else:
                await self._run_standard_test(scenario, test_videos, result)
            
            result.success = True
            logger.info(f"âœ… ì‹œë‚˜ë¦¬ì˜¤ ì„±ê³µ: {scenario.name}")
            
        except Exception as e:
            result.errors_encountered.append(str(e))
            logger.error(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤íŒ¨: {scenario.name} - {e}")
        
        finally:
            result.end_time = time.time()
            self.current_test = None
        
        return result
    
    async def _prepare_test_videos(self, scenario: TestScenario) -> List[str]:
        """í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ì¤€ë¹„"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ê¸°ì¡´ ë¹„ë””ì˜¤ë¥¼ ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ê°€ìƒì˜ ë¹„ë””ì˜¤ ê²½ë¡œë¥¼ ë°˜í™˜
        
        videos = []
        for i in range(scenario.video_count):
            if scenario.resolution == "mixed":
                resolution = random.choice(["720p", "1080p", "4K"])
            else:
                resolution = scenario.resolution
            
            video_path = f"test_video_{resolution}_{i+1}.mp4"
            videos.append(video_path)
        
        logger.debug(f"ğŸ“ í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ì¤€ë¹„: {len(videos)}ê°œ")
        return videos
    
    async def _run_standard_test(self, 
                               scenario: TestScenario, 
                               test_videos: List[str], 
                               result: TestResult):
        """í‘œì¤€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        start_time = time.time()
        
        # ê°€ìƒì˜ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        for i, video_path in enumerate(test_videos):
            if self.abort_requested:
                break
            
            try:
                # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë¹„ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ)
                processing_time = await self._simulate_video_processing(
                    video_path, scenario.video_duration_minutes
                )
                
                result.videos_processed += 1
                result.videos_successful += 1
                result.total_processing_time += processing_time
                
                # ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘
                if self.hardware_monitor:
                    status = self.hardware_monitor.get_current_status()
                    result.peak_gpu_util = max(result.peak_gpu_util, status.get('gpu_util', 0))
                    result.peak_memory_mb = max(result.peak_memory_mb, status.get('memory_used_gb', 0) * 1024)
                
                logger.debug(f"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {Path(video_path).name}")
                
            except Exception as e:
                result.errors_encountered.append(f"{video_path}: {str(e)}")
                result.videos_processed += 1
                logger.warning(f"âš ï¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {video_path} - {e}")
        
        # í‰ê·  FPS ê³„ì‚°
        if result.total_processing_time > 0:
            total_frames = result.videos_successful * scenario.video_duration_minutes * 60 * 30  # 30fps ê°€ì •
            result.average_fps = total_frames / result.total_processing_time
        
        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
        result.performance_score = self._calculate_performance_score(result, scenario)
    
    async def _run_error_recovery_test(self, 
                                     scenario: TestScenario, 
                                     test_videos: List[str], 
                                     result: TestResult):
        """ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ›¡ï¸ ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        if not self.recovery_manager:
            self.recovery_manager = StreamRecoveryManager()
        
        for i, video_path in enumerate(test_videos):
            try:
                # ì˜ë„ì ìœ¼ë¡œ ì—ëŸ¬ ë°œìƒ (ì¼ë¶€ ë¹„ë””ì˜¤)
                if i % 3 == 1:  # ë§¤ 3ë²ˆì§¸ë§ˆë‹¤ ì—ëŸ¬ ë°œìƒ
                    raise Exception(f"Simulated error for {video_path}")
                
                processing_time = await self._simulate_video_processing(
                    video_path, scenario.video_duration_minutes
                )
                
                result.videos_processed += 1
                result.videos_successful += 1
                result.total_processing_time += processing_time
                
            except Exception as e:
                # ë³µêµ¬ ë§¤ë‹ˆì €ë¥¼ í†µí•œ ì²˜ë¦¬
                recovery_result = await self.recovery_manager.attempt_recovery(
                    error=e, video_path=video_path, attempt=1
                )
                
                result.videos_processed += 1
                if recovery_result:
                    result.videos_successful += 1
                
                result.errors_encountered.append(f"{video_path}: {str(e)} (ë³µêµ¬: {recovery_result})")
        
        # ë³µêµ¬ í†µê³„ ì¶œë ¥
        if self.recovery_manager:
            self.recovery_manager.print_recovery_summary()
    
    async def _run_stability_test(self, 
                                scenario: TestScenario, 
                                test_videos: List[str], 
                                result: TestResult):
        """ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸"""
        logger.info("â³ ì¥ì‹œê°„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        test_start = time.time()
        round_count = 0
        
        while time.time() - test_start < scenario.duration_minutes * 60:
            if self.abort_requested:
                break
            
            round_count += 1
            logger.info(f"ğŸ”„ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ë¼ìš´ë“œ {round_count}")
            
            # ë¹„ë””ì˜¤ ë°°ì¹˜ ì²˜ë¦¬
            batch_videos = test_videos[:4]  # 4ê°œì”© ì²˜ë¦¬
            
            for video_path in batch_videos:
                try:
                    processing_time = await self._simulate_video_processing(
                        video_path, scenario.video_duration_minutes
                    )
                    
                    result.videos_processed += 1
                    result.videos_successful += 1
                    result.total_processing_time += processing_time
                    
                except Exception as e:
                    result.errors_encountered.append(f"Round {round_count} - {video_path}: {str(e)}")
                    result.videos_processed += 1
            
            # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì²´í¬
            if self.memory_manager and round_count % 5 == 0:
                leak_detected = self.memory_manager.detect_memory_leak()
                if leak_detected:
                    result.errors_encountered.append(f"Memory leak detected at round {round_count}")
            
            await asyncio.sleep(1)  # ë¼ìš´ë“œ ê°„ ì ì‹œ ëŒ€ê¸°
        
        logger.info(f"âœ… ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {round_count}ë¼ìš´ë“œ")
    
    async def _run_memory_pressure_test(self, 
                                      scenario: TestScenario, 
                                      test_videos: List[str], 
                                      result: TestResult):
        """ë©”ëª¨ë¦¬ ì••ë°• í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ’¾ ë©”ëª¨ë¦¬ ì••ë°• í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        if not self.memory_manager:
            self.memory_manager = MemoryManager(threshold_percent=60.0)  # ë” ë‚®ì€ ì„ê³„ê°’
        
        # ëŒ€ìš©ëŸ‰ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì••ë°• ìœ ë„
        batch_size = scenario.concurrent_streams
        
        for i in range(0, len(test_videos), batch_size):
            batch = test_videos[i:i+batch_size]
            
            logger.info(f"ğŸ“¦ ë©”ëª¨ë¦¬ ì••ë°• ë°°ì¹˜ {i//batch_size + 1}: {len(batch)}ê°œ ë¹„ë””ì˜¤")
            
            # ë°°ì¹˜ ë™ì‹œ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            tasks = []
            for video_path in batch:
                task = self._simulate_video_processing(video_path, scenario.video_duration_minutes)
                tasks.append(task)
            
            try:
                processing_times = await asyncio.gather(*tasks)
                
                for j, processing_time in enumerate(processing_times):
                    result.videos_processed += 1
                    result.videos_successful += 1
                    result.total_processing_time += processing_time
                
            except Exception as e:
                result.errors_encountered.append(f"Batch {i//batch_size + 1}: {str(e)}")
                result.videos_processed += len(batch)
            
            # ê°•ì œ ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.memory_manager:
                self.memory_manager.check_and_cleanup(force=True)
    
    async def _simulate_video_processing(self, 
                                       video_path: str, 
                                       duration_minutes: float) -> float:
        """ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
        # ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ì„ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” GPU ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ)
        
        # í•´ìƒë„ì— ë”°ë¥¸ ì²˜ë¦¬ ì‹œê°„ ì¡°ì •
        if "4K" in video_path:
            base_time = duration_minutes * 60 * 0.8  # 4KëŠ” ì‹¤ì‹œê°„ë³´ë‹¤ ë¹ ë¦„
        elif "1080p" in video_path:
            base_time = duration_minutes * 60 * 0.3  # 1080pëŠ” ì‹¤ì‹œê°„ì˜ 30%
        else:  # 720p
            base_time = duration_minutes * 60 * 0.2  # 720pëŠ” ì‹¤ì‹œê°„ì˜ 20%
        
        # ë³€ë™ì„± ì¶”ê°€
        processing_time = base_time * random.uniform(0.8, 1.2)
        
        # ì‹¤ì œ ëŒ€ê¸° (í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜)
        await asyncio.sleep(min(processing_time / 10, 2.0))  # ì‹œë®¬ë ˆì´ì…˜ìš© ë‹¨ì¶•
        
        return processing_time
    
    def _calculate_performance_score(self, result: TestResult, scenario: TestScenario) -> float:
        """ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        # ì„±ê³µë¥  ì ìˆ˜ (40%)
        success_score = result.success_rate
        
        # ì†ë„ ì ìˆ˜ (30%) - ì‹¤ì‹œê°„ ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ë¹ ë¥¸ì§€
        expected_time = scenario.video_count * scenario.video_duration_minutes * 60
        if result.total_processing_time > 0:
            speed_ratio = expected_time / result.total_processing_time
            speed_score = min(100, speed_ratio * 20)  # 5ë°° ë¹ ë¥´ë©´ 100ì 
        else:
            speed_score = 0
        
        # GPU í™œìš©ë¥  ì ìˆ˜ (20%)
        if 70 <= result.peak_gpu_util <= 90:
            gpu_score = 100
        elif result.peak_gpu_util < 70:
            gpu_score = result.peak_gpu_util / 70 * 100
        else:
            gpu_score = max(0, 100 - (result.peak_gpu_util - 90) * 2)
        
        # ì—ëŸ¬ ì²˜ë¦¬ ì ìˆ˜ (10%)
        if len(result.errors_encountered) == 0:
            error_score = 100
        else:
            error_score = max(0, 100 - len(result.errors_encountered) * 10)
        
        total_score = (
            success_score * 0.4 +
            speed_score * 0.3 +
            gpu_score * 0.2 +
            error_score * 0.1
        )
        
        return total_score
    
    def _start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        try:
            self.hardware_monitor = HardwareMonitor(
                log_dir=str(self.results_dir / "monitoring"),
                interval=10.0
            )
            self.hardware_monitor.start_monitoring()
            
            self.performance_reporter = PerformanceReporter(
                report_dir=str(self.results_dir / "performance")
            )
            
            if not self.memory_manager:
                self.memory_manager = MemoryManager()
            self.memory_manager.start_monitoring()
            
            logger.info("ğŸ“Š ëª¨ë‹ˆí„°ë§ ì‹œì‘")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨: {e}")
    
    def _stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        try:
            if self.hardware_monitor:
                self.hardware_monitor.stop_monitoring()
            
            if self.performance_reporter:
                self.performance_reporter.save_reports()
            
            if self.memory_manager:
                self.memory_manager.stop_monitoring()
            
            logger.info("ğŸ“Š ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì‹¤íŒ¨: {e}")
    
    async def _cleanup_between_tests(self):
        """í…ŒìŠ¤íŠ¸ ê°„ ì •ë¦¬"""
        logger.debug("ğŸ§¹ í…ŒìŠ¤íŠ¸ ê°„ ì •ë¦¬ ì¤‘...")
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if TORCH_AVAILABLE and torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬
        import gc
        gc.collect()
        
        # ì ì‹œ ëŒ€ê¸°
        await asyncio.sleep(2.0)
    
    def _generate_test_summary(self, overall_time: float) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
        total_videos = sum(r.videos_processed for r in self.test_results)
        total_successful = sum(r.videos_successful for r in self.test_results)
        total_errors = sum(len(r.errors_encountered) for r in self.test_results)
        
        avg_performance_score = 0
        if self.test_results:
            avg_performance_score = sum(r.performance_score for r in self.test_results) / len(self.test_results)
        
        scenarios_passed = sum(1 for r in self.test_results if r.success)
        
        return {
            'test_summary': {
                'total_scenarios': len(self.scenarios),
                'scenarios_passed': scenarios_passed,
                'overall_success_rate': (scenarios_passed / len(self.scenarios)) * 100 if self.scenarios else 0,
                'total_execution_time_minutes': overall_time / 60,
                'average_performance_score': avg_performance_score
            },
            'video_processing': {
                'total_videos_processed': total_videos,
                'total_videos_successful': total_successful,
                'video_success_rate': (total_successful / total_videos) * 100 if total_videos > 0 else 0,
                'total_errors': total_errors
            },
            'scenario_results': [asdict(result) for result in self.test_results],
            'timestamp': time.time()
        }
    
    def _save_test_results(self, summary: Dict[str, Any]):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        # JSON ê²°ê³¼ ì €ì¥
        import json
        
        results_file = self.results_dir / f"test_results_{int(time.time())}.json"
        with open(results_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
        report_file = self.results_dir / f"test_report_{int(time.time())}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(self._format_test_report(summary))
        
        logger.info(f"ğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {results_file}")
        logger.info(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸: {report_file}")
    
    def _format_test_report(self, summary: Dict[str, Any]) -> str:
        """í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ í¬ë§·íŒ…"""
        report = f"""
================================================================================
ğŸ§ª í”„ë¡œë•ì…˜ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸
================================================================================
ğŸ“… ì‹¤í–‰ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}
â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {summary['test_summary']['total_execution_time_minutes']:.1f}ë¶„

ğŸ“Š ì „ì²´ ìš”ì•½:
   â€¢ ì‹¤í–‰ ì‹œë‚˜ë¦¬ì˜¤: {summary['test_summary']['scenarios_passed']}/{summary['test_summary']['total_scenarios']}ê°œ ì„±ê³µ
   â€¢ ì „ì²´ ì„±ê³µë¥ : {summary['test_summary']['overall_success_rate']:.1f}%
   â€¢ í‰ê·  ì„±ëŠ¥ ì ìˆ˜: {summary['test_summary']['average_performance_score']:.1f}ì 

ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ í†µê³„:
   â€¢ ì²˜ë¦¬ëœ ë¹„ë””ì˜¤: {summary['video_processing']['total_videos_processed']}ê°œ
   â€¢ ì„±ê³µí•œ ë¹„ë””ì˜¤: {summary['video_processing']['total_videos_successful']}ê°œ
   â€¢ ë¹„ë””ì˜¤ ì„±ê³µë¥ : {summary['video_processing']['video_success_rate']:.1f}%
   â€¢ ë°œìƒí•œ ì—ëŸ¬: {summary['video_processing']['total_errors']}ê°œ

ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²°ê³¼:
"""
        
        for result_data in summary['scenario_results']:
            report += f"""
   ğŸ¯ {result_data['scenario_name']}:
      â€¢ ì„±ê³µ: {'âœ…' if result_data['success'] else 'âŒ'}
      â€¢ ì²˜ë¦¬ ì‹œê°„: {result_data['duration_minutes']:.1f}ë¶„
      â€¢ ë¹„ë””ì˜¤ ì„±ê³µë¥ : {result_data['success_rate']:.1f}%
      â€¢ ì„±ëŠ¥ ì ìˆ˜: {result_data['performance_score']:.1f}ì 
      â€¢ ì—ëŸ¬ ìˆ˜: {len(result_data['errors_encountered'])}ê°œ"""
        
        report += "\n================================================================================\n"
        
        return report
    
    def abort_tests(self):
        """í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨"""
        self.abort_requested = True
        logger.warning("âš ï¸ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ ìš”ì²­")
    
    def get_test_status(self) -> Dict[str, Any]:
        """í˜„ì¬ í…ŒìŠ¤íŠ¸ ìƒíƒœ"""
        return {
            'current_test': self.current_test,
            'completed_tests': len(self.test_results),
            'total_tests': len(self.scenarios),
            'abort_requested': self.abort_requested,
            'is_running': self.current_test is not None
        }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    async def main():
        print("ğŸ§ª ProductionTestSuite í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        test_suite = ProductionTestSuite()
        
        # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
        basic_scenario = test_suite.scenarios[0]  # basic_functionality
        result = await test_suite.run_scenario(basic_scenario)
        
        print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {result.scenario_name}")
        print(f"ì„±ê³µ: {result.success}")
        print(f"ì„±ê³µë¥ : {result.success_rate:.1f}%")
        print(f"ì„±ëŠ¥ ì ìˆ˜: {result.performance_score:.1f}ì ")
        
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    asyncio.run(main())