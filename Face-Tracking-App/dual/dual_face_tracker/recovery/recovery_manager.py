"""
ìŠ¤íŠ¸ë¦¼ ë³µêµ¬ ê´€ë¦¬ ì‹œìŠ¤í…œ

ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ì—ëŸ¬ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ë³µêµ¬í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import asyncio
import time
from pathlib import Path
from typing import Dict, Any, Optional, Callable, List, Union
from collections import defaultdict, deque
from dataclasses import dataclass
from enum import Enum

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

from ..utils.logger import logger
from ..utils.exceptions import (
    GPUMemoryError, NVENCSessionError, VideoProcessingError,
    DecodingError, EncodingError, InferenceError
)


class RecoveryStrategy(Enum):
    """ë³µêµ¬ ì „ëµ íƒ€ì…"""
    RETRY = "retry"
    FALLBACK = "fallback"
    SKIP = "skip"
    ABORT = "abort"
    REDUCE_BATCH = "reduce_batch"
    MEMORY_CLEANUP = "memory_cleanup"


@dataclass
class RecoveryAction:
    """ë³µêµ¬ í–‰ë™ ì •ì˜"""
    strategy: RecoveryStrategy
    max_attempts: int = 3
    delay_seconds: float = 1.0
    condition_check: Optional[Callable[[], bool]] = None
    success_callback: Optional[Callable[[], None]] = None
    failure_callback: Optional[Callable[[], None]] = None


@dataclass
class RecoveryRecord:
    """ë³µêµ¬ ê¸°ë¡"""
    timestamp: float
    error_type: str
    error_message: str
    strategy_used: RecoveryStrategy
    attempt_number: int
    success: bool
    recovery_time: float
    video_path: Optional[str] = None
    
    @property
    def formatted_timestamp(self) -> str:
        return time.strftime('%H:%M:%S', time.localtime(self.timestamp))


class StreamRecoveryManager:
    """
    ìŠ¤íŠ¸ë¦¼ ë³µêµ¬ ê´€ë¦¬ì
    
    ê¸°ëŠ¥:
    - ë‹¤ì–‘í•œ ì—ëŸ¬ íƒ€ì…ë³„ ìë™ ë³µêµ¬ ì „ëµ
    - ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
    - ì†Œí”„íŠ¸ì›¨ì–´ í´ë°± (NVENC â†’ CPU ì¸ì½”ë”©)
    - GPU ë©”ëª¨ë¦¬ ìë™ ì •ë¦¬
    - ë°°ì¹˜ í¬ê¸° ë™ì  ì¡°ì •
    - ë³µêµ¬ í†µê³„ ë° ë¡œê¹…
    """
    
    def __init__(self):
        # ë³µêµ¬ ì „ëµ ì •ì˜
        self.recovery_strategies = self._init_recovery_strategies()
        
        # ë³µêµ¬ í†µê³„
        self.recovery_stats = {
            'total_errors': 0,
            'total_recoveries': 0,
            'recovery_success_rate': 0.0,
            'errors_by_type': defaultdict(int),
            'recoveries_by_strategy': defaultdict(int)
        }
        
        # ë³µêµ¬ ê¸°ë¡ (ìµœê·¼ 100ê°œ)
        self.recovery_history = deque(maxlen=100)
        
        # í˜„ì¬ ì²˜ë¦¬ ì„¤ì •
        self.current_batch_size = 4
        self.min_batch_size = 1
        self.max_batch_size = 32
        
        # í´ë°± ìƒíƒœ
        self.software_fallback_enabled = True
        self.use_software_encoding = False
        
        logger.info("ğŸ›¡ï¸ StreamRecoveryManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_recovery_strategies(self) -> Dict[type, RecoveryAction]:
        """ë³µêµ¬ ì „ëµ ì´ˆê¸°í™”"""
        return {
            GPUMemoryError: RecoveryAction(
                strategy=RecoveryStrategy.MEMORY_CLEANUP,
                max_attempts=2,
                delay_seconds=2.0
            ),
            NVENCSessionError: RecoveryAction(
                strategy=RecoveryStrategy.FALLBACK,
                max_attempts=1,
                delay_seconds=1.0
            ),
            DecodingError: RecoveryAction(
                strategy=RecoveryStrategy.RETRY,
                max_attempts=3,
                delay_seconds=1.0
            ),
            EncodingError: RecoveryAction(
                strategy=RecoveryStrategy.FALLBACK,
                max_attempts=2,
                delay_seconds=1.0
            ),
            InferenceError: RecoveryAction(
                strategy=RecoveryStrategy.REDUCE_BATCH,
                max_attempts=2,
                delay_seconds=0.5
            ),
            Exception: RecoveryAction(  # ì¼ë°˜ ì˜ˆì™¸
                strategy=RecoveryStrategy.RETRY,
                max_attempts=1,
                delay_seconds=2.0
            )
        }
    
    async def process_with_recovery(self, 
                                  video_path: str,
                                  processor_func: Callable,
                                  stream_id: int = 0,
                                  **kwargs) -> Any:
        """
        ë³µêµ¬ ë¡œì§ì´ ë‚´ì¥ëœ ë¹„ë””ì˜¤ ì²˜ë¦¬
        
        Args:
            video_path: ì²˜ë¦¬í•  ë¹„ë””ì˜¤ ê²½ë¡œ
            processor_func: ì‹¤ì œ ì²˜ë¦¬ í•¨ìˆ˜
            stream_id: ìŠ¤íŠ¸ë¦¼ ì‹ë³„ì
            **kwargs: ì²˜ë¦¬ í•¨ìˆ˜ì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë˜ëŠ” ì—ëŸ¬ ì‹œ None
        """
        video_name = Path(video_path).name
        
        for attempt in range(3):  # ìµœëŒ€ 3ë²ˆ ì‹œë„
            try:
                logger.info(f"ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘: {video_name} (ì‹œë„ {attempt + 1})")
                
                result = await self._execute_with_monitoring(
                    processor_func, video_path, stream_id, **kwargs
                )
                
                logger.info(f"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì„±ê³µ: {video_name}")
                return result
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {video_name} - {str(e)}")
                
                # ë³µêµ¬ ì‹œë„
                recovery_success = await self.attempt_recovery(
                    error=e, 
                    video_path=video_path,
                    attempt=attempt + 1
                )
                
                if not recovery_success and attempt == 2:
                    # ìµœì¢… ì‹¤íŒ¨ - ì—ëŸ¬ ì¶œë ¥ íŒŒì¼ ìƒì„±
                    logger.error(f"âŒ ìµœì¢… ì‹¤íŒ¨: {video_name} - ë³µêµ¬ ë¶ˆê°€")
                    return self._create_error_output(video_path, str(e))
                
                # ë‹¤ìŒ ì‹œë„ ì „ ëŒ€ê¸°
                if attempt < 2:
                    await asyncio.sleep(2.0)
        
        return None
    
    async def _execute_with_monitoring(self, 
                                     processor_func: Callable,
                                     video_path: str,
                                     stream_id: int,
                                     **kwargs) -> Any:
        """ëª¨ë‹ˆí„°ë§ì´ í¬í•¨ëœ ì²˜ë¦¬ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            if TORCH_AVAILABLE and torch.cuda.is_available():
                initial_memory = torch.cuda.memory_allocated() / 1024**2
                logger.debug(f"ğŸ” ì²˜ë¦¬ ì‹œì‘ GPU ë©”ëª¨ë¦¬: {initial_memory:.1f}MB")
            
            # ì‹¤ì œ ì²˜ë¦¬ ì‹¤í–‰
            result = await processor_func(video_path, stream_id=stream_id, **kwargs)
            
            processing_time = time.time() - start_time
            logger.debug(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            return result
            
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒì‹œ ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
            if TORCH_AVAILABLE and torch.cuda.is_available():
                error_memory = torch.cuda.memory_allocated() / 1024**2
                logger.debug(f"âŒ ì—ëŸ¬ ì‹œì  GPU ë©”ëª¨ë¦¬: {error_memory:.1f}MB")
            
            raise e
    
    async def attempt_recovery(self, 
                             error: Exception, 
                             video_path: str,
                             attempt: int) -> bool:
        """
        ì—ëŸ¬ íƒ€ì…ì— ë”°ë¥¸ ë³µêµ¬ ì‹œë„
        
        Returns:
            ë³µêµ¬ ì„±ê³µ ì—¬ë¶€
        """
        error_type = type(error)
        error_message = str(error)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.recovery_stats['total_errors'] += 1
        self.recovery_stats['errors_by_type'][error_type.__name__] += 1
        
        # ë³µêµ¬ ì „ëµ ì„ íƒ
        recovery_action = self._get_recovery_action(error_type)
        
        if not recovery_action:
            logger.warning(f"âš ï¸ ë³µêµ¬ ì „ëµ ì—†ìŒ: {error_type.__name__}")
            return False
        
        logger.info(f"ğŸ”§ ë³µêµ¬ ì‹œë„: {recovery_action.strategy.value} "
                   f"({attempt}/{recovery_action.max_attempts})")
        
        recovery_start = time.time()
        success = False
        
        try:
            # ë³µêµ¬ ì „ëµ ì‹¤í–‰
            if recovery_action.strategy == RecoveryStrategy.MEMORY_CLEANUP:
                success = await self._memory_cleanup_recovery()
                
            elif recovery_action.strategy == RecoveryStrategy.FALLBACK:
                success = await self._fallback_recovery(error_type)
                
            elif recovery_action.strategy == RecoveryStrategy.REDUCE_BATCH:
                success = await self._reduce_batch_recovery()
                
            elif recovery_action.strategy == RecoveryStrategy.RETRY:
                # ë‹¨ìˆœ ì¬ì‹œë„ (ëŒ€ê¸° í›„)
                await asyncio.sleep(recovery_action.delay_seconds)
                success = True
                
            else:
                logger.warning(f"âš ï¸ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë³µêµ¬ ì „ëµ: {recovery_action.strategy}")
                success = False
            
            # ë³µêµ¬ ê²°ê³¼ ê¸°ë¡
            recovery_time = time.time() - recovery_start
            
            self._record_recovery(
                error_type=error_type.__name__,
                error_message=error_message,
                strategy=recovery_action.strategy,
                attempt=attempt,
                success=success,
                recovery_time=recovery_time,
                video_path=video_path
            )
            
            if success:
                self.recovery_stats['total_recoveries'] += 1
                self.recovery_stats['recoveries_by_strategy'][recovery_action.strategy.value] += 1
                logger.info(f"âœ… ë³µêµ¬ ì„±ê³µ: {recovery_action.strategy.value}")
            else:
                logger.warning(f"âŒ ë³µêµ¬ ì‹¤íŒ¨: {recovery_action.strategy.value}")
            
        except Exception as recovery_error:
            logger.error(f"âŒ ë³µêµ¬ ê³¼ì • ì—ëŸ¬: {recovery_error}")
            success = False
        
        # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        if self.recovery_stats['total_errors'] > 0:
            self.recovery_stats['recovery_success_rate'] = (
                self.recovery_stats['total_recoveries'] / 
                self.recovery_stats['total_errors'] * 100
            )
        
        return success
    
    def _get_recovery_action(self, error_type: type) -> Optional[RecoveryAction]:
        """ì—ëŸ¬ íƒ€ì…ì— ë”°ë¥¸ ë³µêµ¬ ì•¡ì…˜ ë°˜í™˜"""
        # ì •í™•í•œ íƒ€ì… ë§¤ì¹­ ì‹œë„
        if error_type in self.recovery_strategies:
            return self.recovery_strategies[error_type]
        
        # ìƒìœ„ í´ë˜ìŠ¤ ë§¤ì¹­ ì‹œë„
        for registered_type, action in self.recovery_strategies.items():
            if issubclass(error_type, registered_type):
                return action
        
        # ê¸°ë³¸ ë³µêµ¬ ì „ëµ
        return self.recovery_strategies.get(Exception)
    
    async def _memory_cleanup_recovery(self) -> bool:
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ë³µêµ¬"""
        try:
            logger.info("ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")
            
            if TORCH_AVAILABLE and torch.cuda.is_available():
                # GPU ìºì‹œ ì •ë¦¬
                torch.cuda.empty_cache()
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                allocated = torch.cuda.memory_allocated() / 1024**2
                reserved = torch.cuda.memory_reserved() / 1024**2
                
                logger.info(f"ğŸ” ì •ë¦¬ í›„ GPU ë©”ëª¨ë¦¬: {allocated:.1f}MB (ì˜ˆì•½: {reserved:.1f}MB)")
                
                # ì¶”ê°€ ì •ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°
                if allocated > 20000:  # 20GB ì´ìƒ
                    logger.warning("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì—¬ì „íˆ ë†’ìŒ - ë°°ì¹˜ í¬ê¸° ê°ì†Œ")
                    await self._reduce_batch_recovery()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    async def _fallback_recovery(self, error_type: type) -> bool:
        """ì†Œí”„íŠ¸ì›¨ì–´ í´ë°± ë³µêµ¬"""
        try:
            if error_type == NVENCSessionError:
                logger.info("ğŸ”„ NVENC â†’ ì†Œí”„íŠ¸ì›¨ì–´ ì¸ì½”ë”© í´ë°±")
                self.use_software_encoding = True
                
            elif error_type == DecodingError:
                logger.info("ğŸ”„ í•˜ë“œì›¨ì–´ â†’ ì†Œí”„íŠ¸ì›¨ì–´ ë””ì½”ë”© í´ë°±")
                # TODO: ì†Œí”„íŠ¸ì›¨ì–´ ë””ì½”ë”© í”Œë˜ê·¸ ì„¤ì •
                
            return True
            
        except Exception as e:
            logger.error(f"âŒ í´ë°± ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    async def _reduce_batch_recovery(self) -> bool:
        """ë°°ì¹˜ í¬ê¸° ê°ì†Œ ë³µêµ¬"""
        try:
            old_batch_size = self.current_batch_size
            self.current_batch_size = max(self.min_batch_size, self.current_batch_size // 2)
            
            logger.info(f"ğŸ“‰ ë°°ì¹˜ í¬ê¸° ê°ì†Œ: {old_batch_size} â†’ {self.current_batch_size}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
            return False
    
    def _record_recovery(self, 
                        error_type: str,
                        error_message: str,
                        strategy: RecoveryStrategy,
                        attempt: int,
                        success: bool,
                        recovery_time: float,
                        video_path: Optional[str] = None):
        """ë³µêµ¬ ê¸°ë¡ ì €ì¥"""
        record = RecoveryRecord(
            timestamp=time.time(),
            error_type=error_type,
            error_message=error_message,
            strategy_used=strategy,
            attempt_number=attempt,
            success=success,
            recovery_time=recovery_time,
            video_path=video_path
        )
        
        self.recovery_history.append(record)
    
    def _create_error_output(self, video_path: str, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ë°œìƒì‹œ ë¹ˆ ì¶œë ¥ ìƒì„±"""
        return {
            'video_path': video_path,
            'success': False,
            'error': error_message,
            'output_path': None,
            'recovery_attempted': True,
            'final_failure': True
        }
    
    def get_recovery_stats(self) -> Dict[str, Any]:
        """ë³µêµ¬ í†µê³„ ë°˜í™˜"""
        recent_errors = len([r for r in self.recovery_history if r.timestamp > time.time() - 3600])
        recent_successes = len([r for r in self.recovery_history 
                               if r.timestamp > time.time() - 3600 and r.success])
        
        return {
            **self.recovery_stats,
            'recent_hour_errors': recent_errors,
            'recent_hour_success_rate': (recent_successes / max(1, recent_errors)) * 100,
            'current_batch_size': self.current_batch_size,
            'software_fallback_active': self.use_software_encoding
        }
    
    def print_recovery_summary(self):
        """ë³µêµ¬ ìš”ì•½ ì¶œë ¥"""
        stats = self.get_recovery_stats()
        
        print(f"""
ğŸ›¡ï¸ ë³µêµ¬ ì‹œìŠ¤í…œ ìš”ì•½:
   â€¢ ì´ ì—ëŸ¬ ìˆ˜: {stats['total_errors']}
   â€¢ ë³µêµ¬ ì„±ê³µ: {stats['total_recoveries']}
   â€¢ ë³µêµ¬ ì„±ê³µë¥ : {stats['recovery_success_rate']:.1f}%
   â€¢ í˜„ì¬ ë°°ì¹˜ í¬ê¸°: {stats['current_batch_size']}
   â€¢ ì†Œí”„íŠ¸ì›¨ì–´ í´ë°±: {'í™œì„±' if stats['software_fallback_active'] else 'ë¹„í™œì„±'}
        """)
        
        if stats['errors_by_type']:
            print("ğŸ“Š ì—ëŸ¬ íƒ€ì…ë³„ í†µê³„:")
            for error_type, count in stats['errors_by_type'].items():
                print(f"   â€¢ {error_type}: {count}íšŒ")
        
        if stats['recoveries_by_strategy']:
            print("ğŸ”§ ë³µêµ¬ ì „ëµë³„ ì‚¬ìš©:")
            for strategy, count in stats['recoveries_by_strategy'].items():
                print(f"   â€¢ {strategy}: {count}íšŒ")
    
    def reset_to_optimal_settings(self):
        """ìµœì  ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”"""
        self.current_batch_size = 4  # ê¸°ë³¸ê°’ ë³µì›
        self.use_software_encoding = False
        
        logger.info("ğŸ”„ ë³µêµ¬ ì„¤ì • ì´ˆê¸°í™” ì™„ë£Œ")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    async def test_recovery_manager():
        print("ğŸ§ª StreamRecoveryManager í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        manager = StreamRecoveryManager()
        
        # ê°€ì§œ ì²˜ë¦¬ í•¨ìˆ˜
        async def mock_processor(video_path, **kwargs):
            if "fail" in video_path:
                raise GPUMemoryError("Test GPU memory error")
            return {"success": True, "output": f"processed_{Path(video_path).name}"}
        
        # ì„±ê³µ ì¼€ì´ìŠ¤
        result = await manager.process_with_recovery("success_video.mp4", mock_processor)
        print(f"ì„±ê³µ ê²°ê³¼: {result}")
        
        # ì‹¤íŒ¨ í›„ ë³µêµ¬ ì¼€ì´ìŠ¤
        result = await manager.process_with_recovery("fail_video.mp4", mock_processor)
        print(f"ë³µêµ¬ ê²°ê³¼: {result}")
        
        # í†µê³„ ì¶œë ¥
        manager.print_recovery_summary()
        
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    asyncio.run(test_recovery_manager())