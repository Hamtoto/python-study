"""
YOLOv8 ê¸°ë°˜ ì–¼êµ´ ê°ì§€ê¸° (ONNX Runtime GPU ê°€ì†).

ì´ ëª¨ë“ˆì€ ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ YOLOv8 ëª¨ë¸ë¡œ ê³ ì„±ëŠ¥ ì–¼êµ´ ê°ì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
RTX 5090ì—ì„œ CUDA ê°€ì†ì„ í†µí•´ 1.95msì˜ ì´ˆê³ ì† ì¶”ë¡ ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.
"""

import time
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Union
import numpy as np
import cv2

from .onnx_engine import ONNXRuntimeEngine
from ..utils.logger import UnifiedLogger
from ..utils.exceptions import InferenceError, PreprocessingError


class Detection:
    """
    ì–¼êµ´ ê°ì§€ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ëž˜ìŠ¤.
    """
    def __init__(
        self, 
        bbox: Tuple[float, float, float, float],  # x1, y1, x2, y2
        confidence: float,
        class_id: int = 0  # YOLOv8ì—ì„œëŠ” person=0, ì–¼êµ´ íŠ¹í™” ëª¨ë¸ì—ì„œëŠ” face=0
    ):
        self.bbox = bbox
        self.confidence = confidence  
        self.class_id = class_id
        
        # íŽ¸ì˜ ì†ì„±ë“¤
        self.x1, self.y1, self.x2, self.y2 = bbox
        self.width = self.x2 - self.x1
        self.height = self.y2 - self.y1
        self.center_x = (self.x1 + self.x2) / 2
        self.center_y = (self.y1 + self.y2) / 2
        self.area = self.width * self.height
    
    def __repr__(self):
        return (f"Detection(bbox=({self.x1:.1f}, {self.y1:.1f}, {self.x2:.1f}, {self.y2:.1f}), "
                f"conf={self.confidence:.3f}, class_id={self.class_id})")


class FaceDetector:
    """
    YOLOv8 ê¸°ë°˜ ì‹¤ì‹œê°„ ì–¼êµ´ ê°ì§€ê¸°.
    
    ONNX Runtime GPU ê°€ì†ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê³ ì† ì–¼êµ´ ê°ì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    - ì¶”ë¡  ì‹œê°„: ~1.95ms (YOLOv8n), ~2.56ms (YOLOv8s)
    - ìž…ë ¥: 640x640 RGB ì´ë¯¸ì§€
    - ì¶œë ¥: NMS í›„ì²˜ë¦¬ëœ ì–¼êµ´ ê°ì§€ ê²°ê³¼
    """
    
    def __init__(
        self,
        model_path: Union[str, Path],
        confidence_threshold: float = 0.5,
        nms_threshold: float = 0.4,
        input_size: Tuple[int, int] = (640, 640),
        max_detections: int = 100,
        target_class_ids: Optional[List[int]] = None,  # Noneì´ë©´ ëª¨ë“  í´ëž˜ìŠ¤, [0]ì´ë©´ personë§Œ
        enable_warmup: bool = True
    ):
        """
        ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™”.
        
        Args:
            model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            confidence_threshold: ì‹ ë¢°ë„ ìž„ê³„ê°’
            nms_threshold: NMS IoU ìž„ê³„ê°’  
            input_size: ëª¨ë¸ ìž…ë ¥ í¬ê¸° (width, height)
            max_detections: ìµœëŒ€ ê°ì§€ ê²°ê³¼ ìˆ˜
            target_class_ids: íƒ€ê²Ÿ í´ëž˜ìŠ¤ ID ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  í´ëž˜ìŠ¤)
            enable_warmup: ì´ˆê¸°í™”ì‹œ ì›Œë°ì—… ìˆ˜í–‰ ì—¬ë¶€
        """
        self.logger = UnifiedLogger("FaceDetector")
        
        # ì„¤ì • ì €ìž¥
        self.model_path = Path(model_path)
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        self.input_size = input_size
        self.max_detections = max_detections
        self.target_class_ids = target_class_ids
        
        # ëª¨ë¸ë³„ í´ëž˜ìŠ¤ ì •ë³´ (YOLOv8 ê¸°ë³¸: 80ê°œ í´ëž˜ìŠ¤, person=0)
        self.class_names = self._get_class_names()
        
        # ONNX Runtime ì—”ì§„ ì´ˆê¸°í™”
        try:
            self.engine = ONNXRuntimeEngine(
                model_path=self.model_path,
                providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],
                enable_optimization=True,
                enable_profiling=False
            )
            self.logger.success(f"ONNX Engine initialized: {self.model_path.name}")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize ONNX engine: {e}")
            raise InferenceError(f"Face detector initialization failed: {e}")
        
        # ìž…ì¶œë ¥ ì •ë³´ ê²€ì¦
        self._validate_model_io()
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.detection_count = 0
        self.total_detection_time = 0.0
        
        # ì›Œë°ì—… ìˆ˜í–‰
        if enable_warmup:
            warmup_time = self.engine.warmup(num_runs=5)
            self.logger.success(f"ðŸ”¥ Face detector warmed up: {warmup_time:.2f}ms")
    
    def _get_class_names(self) -> List[str]:
        """YOLOv8 í´ëž˜ìŠ¤ ì´ë¦„ ì •ì˜."""
        # YOLOv8 COCO í´ëž˜ìŠ¤ë“¤ (personì´ 0ë²ˆ)
        return [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
    
    def _validate_model_io(self):
        """ëª¨ë¸ ìž…ì¶œë ¥ í˜•íƒœ ê²€ì¦."""
        # ìž…ë ¥ ê²€ì¦
        if len(self.engine.input_names) != 1:
            raise InferenceError(f"Expected 1 input, got {len(self.engine.input_names)}")
        
        input_name = self.engine.input_names[0]
        input_shape = self.engine.input_shapes[input_name]
        
        # YOLOv8 ìž…ë ¥ í˜•íƒœ: [batch, 3, 640, 640]
        if len(input_shape) != 4:
            raise InferenceError(f"Expected 4D input, got {len(input_shape)}D: {input_shape}")
        
        if input_shape[1] != 3:  # ì±„ë„ ìˆ˜
            raise InferenceError(f"Expected 3 channels, got {input_shape[1]}")
        
        if input_shape[2] != self.input_size[1] or input_shape[3] != self.input_size[0]:
            self.logger.warning(f"Input size mismatch: model={input_shape[2:]} vs config={self.input_size}")
        
        # ì¶œë ¥ ê²€ì¦
        if len(self.engine.output_names) != 1:
            raise InferenceError(f"Expected 1 output, got {len(self.engine.output_names)}")
        
        output_name = self.engine.output_names[0]
        output_shape = self.engine.output_shapes[output_name]
        
        # YOLOv8 ì¶œë ¥ í˜•íƒœ: [batch, 84, 8400] (4ë°•ìŠ¤+80í´ëž˜ìŠ¤)
        if len(output_shape) != 3:
            raise InferenceError(f"Expected 3D output, got {len(output_shape)}D: {output_shape}")
        
        self.logger.debug(f"Model I/O validated - Input: {input_shape}, Output: {output_shape}")
    
    def preprocess(self, image: np.ndarray) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬: ë¦¬ì‚¬ì´ì¦ˆ, ì •ê·œí™”, í…ì„œ ë³€í™˜.
        
        Args:
            image: ìž…ë ¥ ì´ë¯¸ì§€ (H, W, C) BGR ë˜ëŠ” RGB
            
        Returns:
            Tuple[ì „ì²˜ë¦¬ëœ í…ì„œ (1, 3, H, W), ìŠ¤ì¼€ì¼ë§ ì •ë³´]
        """
        try:
            original_height, original_width = image.shape[:2]
            target_width, target_height = self.input_size
            
            # BGR â†’ RGB ë³€í™˜ (í•„ìš”ì‹œ)
            if len(image.shape) == 3 and image.shape[2] == 3:
                # OpenCVëŠ” ë³´í†µ BGRì´ë¯€ë¡œ RGBë¡œ ë³€í™˜
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Letterbox ë¦¬ì‚¬ì´ì§• (ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ íŒ¨ë”©)
            scale = min(target_width / original_width, target_height / original_height)
            new_width = int(original_width * scale)
            new_height = int(original_height * scale)
            
            # ë¦¬ì‚¬ì´ì¦ˆ
            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
            
            # íŒ¨ë”©ìœ¼ë¡œ íƒ€ê²Ÿ í¬ê¸° ë§žì¶”ê¸°
            padded = np.full((target_height, target_width, 3), 114, dtype=np.uint8)  # íšŒìƒ‰ íŒ¨ë”©
            
            # ì¤‘ì•™ ë°°ì¹˜
            pad_x = (target_width - new_width) // 2
            pad_y = (target_height - new_height) // 2
            padded[pad_y:pad_y + new_height, pad_x:pad_x + new_width] = resized
            
            # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
            # [H, W, C] â†’ [C, H, W] â†’ [1, C, H, W]
            tensor = padded.astype(np.float32) / 255.0
            tensor = tensor.transpose(2, 0, 1)  # HWC â†’ CHW
            tensor = tensor[np.newaxis, ...]    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            
            # ìŠ¤ì¼€ì¼ë§ ì •ë³´
            scale_info = {
                'scale': scale,
                'pad_x': pad_x,
                'pad_y': pad_y,
                'original_width': original_width,
                'original_height': original_height
            }
            
            return tensor, scale_info
            
        except Exception as e:
            self.logger.error(f"Preprocessing failed: {e}")
            raise PreprocessingError(f"Image preprocessing failed: {e}")
    
    def postprocess(
        self, 
        outputs: np.ndarray, 
        scale_info: Dict[str, float]
    ) -> List[Detection]:
        """
        ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬: NMS, ì¢Œí‘œ ë³€í™˜, í´ëž˜ìŠ¤ í•„í„°ë§.
        
        Args:
            outputs: ëª¨ë¸ ì›ì‹œ ì¶œë ¥ (1, 84, 8400)
            scale_info: ì „ì²˜ë¦¬ì—ì„œ ìƒì„±ëœ ìŠ¤ì¼€ì¼ë§ ì •ë³´
            
        Returns:
            ê°ì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì¶œë ¥ í˜•íƒœ í™•ì¸: (1, 84, 8400)
            if len(outputs.shape) != 3:
                raise InferenceError(f"Unexpected output shape: {outputs.shape}")
            
            predictions = outputs[0]  # (84, 8400)
            
            # Transpose: (84, 8400) â†’ (8400, 84)
            predictions = predictions.transpose()
            
            # ë°•ìŠ¤ ì¢Œí‘œ (ì²˜ìŒ 4ê°œ) + í´ëž˜ìŠ¤ í™•ë¥ ë“¤ (ë‚˜ë¨¸ì§€ 80ê°œ)
            boxes = predictions[:, :4]  # (8400, 4) - cx, cy, w, h
            class_scores = predictions[:, 4:]  # (8400, 80)
            
            # ê° ì˜ˆì¸¡ì— ëŒ€í•œ ìµœê³  í´ëž˜ìŠ¤ ë° ì ìˆ˜
            max_scores = np.max(class_scores, axis=1)  # (8400,)
            max_classes = np.argmax(class_scores, axis=1)  # (8400,)
            
            # ì‹ ë¢°ë„ í•„í„°ë§
            conf_mask = max_scores >= self.confidence_threshold
            
            if not np.any(conf_mask):
                return []
            
            # í•„í„°ë§ëœ ê²°ê³¼ë“¤
            filtered_boxes = boxes[conf_mask]
            filtered_scores = max_scores[conf_mask]
            filtered_classes = max_classes[conf_mask]
            
            # í´ëž˜ìŠ¤ í•„í„°ë§ (íƒ€ê²Ÿ í´ëž˜ìŠ¤ë§Œ)
            if self.target_class_ids is not None:
                class_mask = np.isin(filtered_classes, self.target_class_ids)
                
                if not np.any(class_mask):
                    return []
                
                filtered_boxes = filtered_boxes[class_mask]
                filtered_scores = filtered_scores[class_mask]
                filtered_classes = filtered_classes[class_mask]
            
            # ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜: center_x, center_y, w, h â†’ x1, y1, x2, y2
            x1 = filtered_boxes[:, 0] - filtered_boxes[:, 2] / 2
            y1 = filtered_boxes[:, 1] - filtered_boxes[:, 3] / 2
            x2 = filtered_boxes[:, 0] + filtered_boxes[:, 2] / 2
            y2 = filtered_boxes[:, 1] + filtered_boxes[:, 3] / 2
            
            # ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œê³„ë¡œ ë³€í™˜
            scale = scale_info['scale']
            pad_x = scale_info['pad_x']
            pad_y = scale_info['pad_y']
            
            x1 = (x1 - pad_x) / scale
            y1 = (y1 - pad_y) / scale
            x2 = (x2 - pad_x) / scale
            y2 = (y2 - pad_y) / scale
            
            # ì´ë¯¸ì§€ ê²½ê³„ í´ë¦¬í•‘
            original_width = scale_info['original_width']
            original_height = scale_info['original_height']
            
            x1 = np.clip(x1, 0, original_width)
            y1 = np.clip(y1, 0, original_height)
            x2 = np.clip(x2, 0, original_width)
            y2 = np.clip(y2, 0, original_height)
            
            # NMS ì ìš©
            boxes_for_nms = np.column_stack([x1, y1, x2, y2])
            indices = cv2.dnn.NMSBoxes(
                boxes_for_nms.tolist(),
                filtered_scores.tolist(),
                self.confidence_threshold,
                self.nms_threshold
            )
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            detections = []
            
            if len(indices) > 0:
                indices = indices.flatten()
                
                for i in indices[:self.max_detections]:
                    detection = Detection(
                        bbox=(float(x1[i]), float(y1[i]), float(x2[i]), float(y2[i])),
                        confidence=float(filtered_scores[i]),
                        class_id=int(filtered_classes[i])
                    )
                    detections.append(detection)
            
            return detections
            
        except Exception as e:
            self.logger.error(f"Postprocessing failed: {e}")
            raise InferenceError(f"Output postprocessing failed: {e}")
    
    def detect(self, image: np.ndarray) -> List[Detection]:
        """
        ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´/ê°ì²´ ê°ì§€ ìˆ˜í–‰.
        
        Args:
            image: ìž…ë ¥ ì´ë¯¸ì§€ (H, W, C) numpy array
            
        Returns:
            ê°ì§€ëœ ì–¼êµ´/ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        start_time = time.time()
        
        try:
            # ì „ì²˜ë¦¬
            input_tensor, scale_info = self.preprocess(image)
            
            # ì¶”ë¡ 
            input_name = self.engine.input_names[0]
            output_name = self.engine.output_names[0]
            
            outputs = self.engine.run({input_name: input_tensor})
            raw_output = outputs[output_name]
            
            # í›„ì²˜ë¦¬
            detections = self.postprocess(raw_output, scale_info)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            detection_time = (time.time() - start_time) * 1000  # ms
            self.detection_count += 1
            self.total_detection_time += detection_time
            
            self.logger.debug(f"Detection completed: {len(detections)} objects in {detection_time:.2f}ms")
            
            return detections
            
        except Exception as e:
            self.logger.error(f"Detection failed: {e}")
            raise InferenceError(f"Face detection failed: {e}")
    
    @property
    def average_detection_time(self) -> float:
        """í‰ê·  ê°ì§€ ì‹œê°„ (ms)."""
        if self.detection_count == 0:
            return 0.0
        return self.total_detection_time / self.detection_count
    
    @property
    def fps(self) -> float:
        """ì´ˆë‹¹ ê°ì§€ í”„ë ˆìž„ ìˆ˜."""
        if self.average_detection_time == 0:
            return 0.0
        return 1000.0 / self.average_detection_time
    
    def get_performance_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜."""
        base_stats = self.engine.get_performance_stats()
        detector_stats = {
            'detector_inference_count': self.detection_count,
            'detector_total_time_ms': self.total_detection_time,
            'detector_average_time_ms': self.average_detection_time,
            'detector_fps': self.fps,
            'confidence_threshold': self.confidence_threshold,
            'nms_threshold': self.nms_threshold,
            'input_size': self.input_size,
            'target_classes': self.target_class_ids
        }
        
        return {**base_stats, **detector_stats}
    
    def reset_stats(self):
        """ì„±ëŠ¥ í†µê³„ ì´ˆê¸°í™”."""
        self.detection_count = 0
        self.total_detection_time = 0.0
        self.engine.reset_stats()
        self.logger.debug("Face detector statistics reset")
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬."""
        if hasattr(self, 'engine') and self.engine is not None:
            self.engine.close()
        self.logger.debug("Face detector closed")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()