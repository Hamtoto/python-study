"""
ê²½ëŸ‰ ReID(Re-Identification) ëª¨ë¸ êµ¬í˜„.

ì´ ëª¨ë“ˆì€ ì–¼êµ´ ì¬ì‹ë³„ì„ ìœ„í•œ ê²½ëŸ‰ ì„ë² ë”© ì¶”ì¶œ ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤.
ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ ê³ ì† ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ë©°, ConditionalReID ì‹œìŠ¤í…œì—ì„œ
ID ìŠ¤ì™‘ì´ ê°ì§€ë  ë•Œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤.
"""

import time
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Union, Any
import numpy as np
import cv2
import torch
import torch.nn.functional as F

from .onnx_engine import ONNXRuntimeEngine
from ..utils.logger import UnifiedLogger
from ..utils.exceptions import InferenceError, ModelLoadError, PreprocessingError


class ReIDModel:
    """
    ê²½ëŸ‰ ReID ëª¨ë¸ í´ë˜ìŠ¤.
    
    ì–¼êµ´ ì´ë¯¸ì§€ë¡œë¶€í„° ê³ ìœ í•œ ì„ë² ë”© ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ì—¬
    ë™ì¼ ì¸ë¬¼ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆëŠ” íŠ¹ì§•ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        model_path: Optional[Union[str, Path]] = None,
        embedding_dim: int = 256,
        input_size: Tuple[int, int] = (112, 112),
        enable_l2_norm: bool = True,
        enable_warmup: bool = True,
        batch_size: int = 8
    ):
        """
        ReID ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ëª¨ì˜ ëª¨ë¸ ì‚¬ìš©)
            embedding_dim: ì„ë² ë”© ë²¡í„° ì°¨ì› ìˆ˜
            input_size: ëª¨ë¸ ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (width, height)
            enable_l2_norm: L2 ì •ê·œí™” í™œì„±í™” ì—¬ë¶€
            enable_warmup: ì´ˆê¸°í™”ì‹œ ì›Œë°ì—… ìˆ˜í–‰ ì—¬ë¶€  
            batch_size: ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
        """
        self.logger = UnifiedLogger("ReIDModel")
        
        # ì„¤ì • ì €ì¥
        self.model_path = Path(model_path) if model_path else None
        self.embedding_dim = embedding_dim
        self.input_size = input_size
        self.enable_l2_norm = enable_l2_norm
        self.batch_size = batch_size
        
        # ëª¨ë¸ ìƒíƒœ
        self.engine = None
        self.use_mock_model = model_path is None
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_extractions': 0,
            'total_time_ms': 0.0,
            'avg_time_ms': 0.0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        
        # ì´ˆê¸°í™”
        self._initialize_model()
        
        if enable_warmup:
            self._warmup_model()
    
    def _initialize_model(self):
        """ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            if self.use_mock_model:
                self.logger.info("ğŸ”§ Mock ReID ëª¨ë¸ ì´ˆê¸°í™” (ì‹¤ì œ ëª¨ë¸ ì—†ìŒ)")
                # Mock ëª¨ë¸ì€ ë³„ë„ ì´ˆê¸°í™” ë¶ˆí•„ìš”
                return
            
            # ì‹¤ì œ ONNX ëª¨ë¸ ë¡œë“œ
            self.logger.stage(f"ReID ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_path.name}")
            
            if not self.model_path.exists():
                raise ModelLoadError(f"ReID ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
            
            # ONNX Runtime ì—”ì§„ ì´ˆê¸°í™”
            self.engine = ONNXRuntimeEngine(
                model_path=self.model_path,
                providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],
                enable_optimization=True,
                enable_profiling=False
            )
            
            self.logger.success(f"ReID ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path.name}")
            
        except Exception as e:
            self.logger.error(f"ReID ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise ModelLoadError(f"Failed to initialize ReID model: {e}")
    
    def _warmup_model(self):
        """ëª¨ë¸ ì›Œë°ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            self.logger.stage("ReID ëª¨ë¸ ì›Œë°ì—… ì‹œì‘")
            
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ ì›Œë°ì—…
            dummy_image = np.random.randint(0, 255, (*self.input_size[::-1], 3), dtype=np.uint8)
            
            warmup_times = []
            for i in range(5):
                start_time = time.perf_counter()
                _ = self.extract_embedding(dummy_image)
                warmup_times.append((time.perf_counter() - start_time) * 1000)
            
            avg_warmup_time = np.mean(warmup_times)
            self.logger.success(f"ReID ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ: {avg_warmup_time:.2f}ms")
            
        except Exception as e:
            self.logger.warning(f"ReID ëª¨ë¸ ì›Œë°ì—… ì‹¤íŒ¨: {e}")
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ReID ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR ë˜ëŠ” RGB)
            
        Returns:
            np.ndarray: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë°°ì—´ (1, 3, H, W)
        """
        try:
            if image is None or image.size == 0:
                raise PreprocessingError("ì…ë ¥ ì´ë¯¸ì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # RGB ë³€í™˜ (BGRì¸ ê²½ìš°)
            if len(image.shape) == 3 and image.shape[2] == 3:
                # OpenCVëŠ” BGRì´ë¯€ë¡œ RGBë¡œ ë³€í™˜ 
                preprocessed = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            else:
                preprocessed = image.copy()
            
            # í¬ê¸° ì¡°ì •
            if preprocessed.shape[:2] != self.input_size[::-1]:  # (H, W)
                preprocessed = cv2.resize(preprocessed, self.input_size)
            
            # ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)
            preprocessed = preprocessed.astype(np.float32) / 255.0
            
            # í‘œì¤€í™” (ImageNet í‰ê· /í‘œì¤€í¸ì°¨)
            mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
            std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
            preprocessed = (preprocessed - mean) / std
            
            # ì°¨ì› ë³€ê²½: (H, W, C) -> (1, C, H, W)
            preprocessed = preprocessed.transpose(2, 0, 1)  # (C, H, W)
            preprocessed = np.expand_dims(preprocessed, axis=0)  # (1, C, H, W)
            
            return preprocessed
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise PreprocessingError(f"Image preprocessing failed: {e}")
    
    def extract_embedding(self, image: np.ndarray) -> np.ndarray:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ë¡œë¶€í„° ì„ë² ë”©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            image: ì–¼êµ´ ì´ë¯¸ì§€ (H, W, C)
            
        Returns:
            np.ndarray: ì„ë² ë”© ë²¡í„° (embedding_dim,)
        """
        try:
            start_time = time.perf_counter()
            
            if self.use_mock_model:
                # Mock ëª¨ë¸: ëœë¤ ì„ë² ë”© ìƒì„±
                embedding = self._generate_mock_embedding(image)
            else:
                # ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ 
                preprocessed = self.preprocess_image(image)
                
                # ONNX ì¶”ë¡ 
                outputs = self.engine.run_inference(preprocessed)
                embedding = outputs[0].flatten()  # ì²« ë²ˆì§¸ ì¶œë ¥ì„ ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©
            
            # L2 ì •ê·œí™”
            if self.enable_l2_norm:
                embedding = self._l2_normalize(embedding)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            inference_time = (time.perf_counter() - start_time) * 1000
            self._update_stats(inference_time)
            
            return embedding
            
        except Exception as e:
            self.logger.error(f"ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise InferenceError(f"Embedding extraction failed: {e}")
    
    def extract_embeddings_batch(self, images: List[np.ndarray]) -> List[np.ndarray]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¡œë¶€í„° ë°°ì¹˜ë¡œ ì„ë² ë”©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            images: ì–¼êµ´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[np.ndarray]: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        try:
            if not images:
                return []
            
            embeddings = []
            
            # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
            for i in range(0, len(images), self.batch_size):
                batch_images = images[i:i + self.batch_size]
                
                if self.use_mock_model:
                    # Mock ëª¨ë¸: ê° ì´ë¯¸ì§€ë³„ë¡œ ì„ë² ë”© ìƒì„±
                    batch_embeddings = [self._generate_mock_embedding(img) for img in batch_images]
                else:
                    # ì‹¤ì œ ë°°ì¹˜ ì²˜ë¦¬
                    batch_embeddings = self._process_batch(batch_images)
                
                embeddings.extend(batch_embeddings)
            
            return embeddings
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise InferenceError(f"Batch embedding extraction failed: {e}")
    
    def _process_batch(self, batch_images: List[np.ndarray]) -> List[np.ndarray]:
        """ì‹¤ì œ ëª¨ë¸ë¡œ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        # ë°°ì¹˜ ì „ì²˜ë¦¬
        batch_input = []
        for image in batch_images:
            preprocessed = self.preprocess_image(image)
            batch_input.append(preprocessed[0])  # (C, H, W)
        
        # ë°°ì¹˜ í…ì„œ ìƒì„±: (N, C, H, W)
        batch_tensor = np.stack(batch_input, axis=0)
        
        # ë°°ì¹˜ ì¶”ë¡ 
        start_time = time.perf_counter()
        outputs = self.engine.run_inference(batch_tensor)
        inference_time = (time.perf_counter() - start_time) * 1000
        
        # ê²°ê³¼ ë¶„ë¦¬
        batch_embeddings = outputs[0]  # (N, embedding_dim)
        
        # ê°œë³„ ì„ë² ë”©ìœ¼ë¡œ ë¶„ë¦¬
        embeddings = []
        for embedding in batch_embeddings:
            if self.enable_l2_norm:
                embedding = self._l2_normalize(embedding)
            embeddings.append(embedding)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self._update_stats(inference_time, batch_size=len(batch_images))
        
        return embeddings
    
    def _generate_mock_embedding(self, image: np.ndarray) -> np.ndarray:
        """
        Mock ëª¨ë¸ìš© ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        ì´ë¯¸ì§€ì˜ ê°„ë‹¨í•œ íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        # ì´ë¯¸ì§€ì˜ ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        resized = cv2.resize(gray, (32, 32))
        
        # ê¸°ë³¸ í†µê³„ íŠ¹ì§•
        mean_intensity = np.mean(resized)
        std_intensity = np.std(resized)
        
        # íˆìŠ¤í† ê·¸ë¨ íŠ¹ì§•
        hist = cv2.calcHist([resized], [0], None, [16], [0, 256])
        hist = hist.flatten() / np.sum(hist)
        
        # LBP ìœ ì‚¬ íŠ¹ì§• (ê°„ë‹¨í•œ í…ìŠ¤ì²˜)
        lbp_features = []
        for i in range(1, 31, 3):
            for j in range(1, 31, 3):
                center = resized[i, j]
                neighbors = [
                    resized[i-1, j-1], resized[i-1, j], resized[i-1, j+1],
                    resized[i, j-1], resized[i, j+1],
                    resized[i+1, j-1], resized[i+1, j], resized[i+1, j+1]
                ]
                lbp_value = sum([(1 if n >= center else 0) * (2**k) for k, n in enumerate(neighbors)])
                lbp_features.append(lbp_value / 255.0)
        
        # íŠ¹ì§• ê²°í•©
        features = [mean_intensity/255.0, std_intensity/255.0] + hist.tolist() + lbp_features[:self.embedding_dim-18]
        
        # ì›í•˜ëŠ” ì°¨ì›ìœ¼ë¡œ ë§ì¶”ê¸°
        while len(features) < self.embedding_dim:
            features.append(np.random.normal(0, 0.1))
        
        embedding = np.array(features[:self.embedding_dim], dtype=np.float32)
        
        # L2 ì •ê·œí™”
        if self.enable_l2_norm:
            embedding = self._l2_normalize(embedding)
        
        return embedding
    
    def _l2_normalize(self, embedding: np.ndarray) -> np.ndarray:
        """ì„ë² ë”©ì„ L2 ì •ê·œí™”í•©ë‹ˆë‹¤."""
        norm = np.linalg.norm(embedding)
        if norm > 1e-6:  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            return embedding / norm
        else:
            return embedding
    
    def calculate_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """
        ë‘ ì„ë² ë”© ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            embedding1: ì²« ë²ˆì§¸ ì„ë² ë”©
            embedding2: ë‘ ë²ˆì§¸ ì„ë² ë”©
            
        Returns:
            float: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0.0 ~ 1.0, ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
        """
        try:
            # L2 ì •ê·œí™”ê°€ ë˜ì–´ìˆë‹¤ë©´ ë‚´ì ì´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            similarity = np.dot(embedding1, embedding2)
            
            # ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•´ [-1, 1] ë²”ìœ„ë¡œ í´ë¦¬í•‘
            similarity = np.clip(similarity, -1.0, 1.0)
            
            # [0, 1] ë²”ìœ„ë¡œ ë³€í™˜
            similarity = (similarity + 1.0) / 2.0
            
            return float(similarity)
            
        except Exception as e:
            self.logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def calculate_similarities_batch(self, 
                                   embeddings1: List[np.ndarray], 
                                   embeddings2: List[np.ndarray]) -> np.ndarray:
        """
        ë‘ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            embeddings1: ì²« ë²ˆì§¸ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ (Nê°œ)
            embeddings2: ë‘ ë²ˆì§¸ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ (Mê°œ)
            
        Returns:
            np.ndarray: ìœ ì‚¬ë„ í–‰ë ¬ (N, M)
        """
        try:
            if not embeddings1 or not embeddings2:
                return np.empty((len(embeddings1), len(embeddings2)), dtype=np.float32)
            
            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            emb1_matrix = np.stack(embeddings1)  # (N, dim)
            emb2_matrix = np.stack(embeddings2)  # (M, dim)
            
            # ë°°ì¹˜ ë‚´ì  ê³„ì‚°: (N, dim) @ (dim, M) = (N, M)
            similarity_matrix = np.dot(emb1_matrix, emb2_matrix.T)
            
            # ìˆ˜ì¹˜ì  ì•ˆì •ì„±
            similarity_matrix = np.clip(similarity_matrix, -1.0, 1.0)
            
            # [0, 1] ë²”ìœ„ë¡œ ë³€í™˜
            similarity_matrix = (similarity_matrix + 1.0) / 2.0
            
            return similarity_matrix
            
        except Exception as e:
            self.logger.error(f"ë°°ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.zeros((len(embeddings1), len(embeddings2)), dtype=np.float32)
    
    def _update_stats(self, inference_time_ms: float, batch_size: int = 1):
        """í†µê³„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        self.stats['total_extractions'] += batch_size
        self.stats['total_time_ms'] += inference_time_ms
        
        if self.stats['total_extractions'] > 0:
            self.stats['avg_time_ms'] = self.stats['total_time_ms'] / self.stats['total_extractions']
    
    def get_statistics(self) -> Dict[str, Any]:
        """ReID ëª¨ë¸ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        stats = self.stats.copy()
        stats['model_type'] = "Mock" if self.use_mock_model else "ONNX"
        stats['embedding_dim'] = self.embedding_dim
        stats['input_size'] = self.input_size
        stats['l2_norm_enabled'] = self.enable_l2_norm
        return stats
    
    def __repr__(self):
        model_type = "Mock" if self.use_mock_model else "ONNX"
        return (f"ReIDModel(type={model_type}, dim={self.embedding_dim}, "
                f"extractions={self.stats['total_extractions']}, "
                f"avg_time={self.stats['avg_time_ms']:.2f}ms)")


class ReIDModelConfig:
    """ReID ëª¨ë¸ ì„¤ì • í´ë˜ìŠ¤."""
    
    def __init__(self):
        self.model_path = None
        self.embedding_dim = 256
        self.input_size = (112, 112)
        self.enable_l2_norm = True
        self.enable_warmup = True
        self.batch_size = 8
    
    @classmethod
    def for_face_reid(cls):
        """ì–¼êµ´ ì¬ì‹ë³„ì— ìµœì í™”ëœ ì„¤ì •."""
        config = cls()
        config.embedding_dim = 128  # ì–¼êµ´ìš© ê²½ëŸ‰ ì„ë² ë”©
        config.input_size = (112, 112)  # í‘œì¤€ ì–¼êµ´ í¬ê¸°
        config.batch_size = 4  # ì–¼êµ´ì€ ë³´í†µ ì ì€ ìˆ˜
        return config
    
    @classmethod
    def for_high_performance(cls):
        """ê³ ì„±ëŠ¥ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •."""
        config = cls()
        config.embedding_dim = 512  # ê³ ì°¨ì› ì„ë² ë”©
        config.batch_size = 16  # í° ë°°ì¹˜ ì‚¬ì´ì¦ˆ
        return config
    
    def to_dict(self) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜."""
        return {
            'model_path': self.model_path,
            'embedding_dim': self.embedding_dim,
            'input_size': self.input_size,
            'enable_l2_norm': self.enable_l2_norm,
            'enable_warmup': self.enable_warmup,
            'batch_size': self.batch_size
        }