# CLAUDE.md - Face-Tracking-App v1.0 Development Guide

> **For future Claude instances working on this repository**

## ğŸ¯ Project Overview - Version 1.0

Face-Tracking-App is a GPU-optimized video processing pipeline that uses MTCNN and FaceNet (InceptionResnetV1) models for face detection, recognition, and tracking. The system processes video files to extract face-tracked segments with high performance through Producer-Consumer patterns and multiprocessing architecture.

**Key Achievement**: GPU utilization optimized to 97.3% with 67% processing time reduction (45-60s â†’ 15-20s)

## ğŸš€ Quick Commands

### Development Environment
```bash
# Activate virtual environment (MANDATORY)
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Main execution
./start.sh
# or
python face_tracker.py

# Check logs
tail -f face_tracker.log
```

## ğŸ“ˆ Version 1.0 - Major Updates (2024)

### ğŸ”§ **ë¡œê¹… ì‹œìŠ¤í…œ í†µí•© ë° ìµœì í™”**
- **ë‹¨ì¼ ë¡œê·¸ íŒŒì¼**: `face_tracker.log`ë¡œ ëª¨ë“  ë¡œê·¸ í†µí•©
- **í†µí•© ë¡œê±°**: `UnifiedLogger` í´ë˜ìŠ¤ë¡œ ì²´ê³„ì  ê´€ë¦¬
- **76ê°œ printë¬¸ ìµœì í™”**: ì˜ë¯¸ìˆëŠ” ë¡œê·¸ ë©”ì‹œì§€ë¡œ ë³€ê²½
- **ì´ëª¨ì§€ ê¸°ë°˜ ë¡œê·¸**: `ğŸ”„ stage()`, `âœ… success()`, `âš ï¸ warning()`, `âŒ error()`
- **tqdm í”„ë¡œê·¸ë ˆìŠ¤ë°” ìµœì í™”**: `ncols=60, leave=False`ë¡œ í™”ë©´ ê³µê°„ 60% ì ˆì•½

### ğŸ“Š **ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ ì¶”ê°€**
- **ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¸¡ì •**: ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„, ë°°ì¹˜ í¬ê¸°, FPS ìë™ ì¸¡ì •
- **ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥**: ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ ì‹œ ì½˜ì†”ì— 80ì¤„ì§œë¦¬ ìƒì„¸ ë¦¬í¬íŠ¸
- **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§**: CPU ì½”ì–´ ì‚¬ìš©ëŸ‰, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
- **ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°**: ì „ì²´ ì²˜ë¦¬ ì†ë„, í”„ë ˆì„ë‹¹ í‰ê·  ì‹œê°„ ìë™ ê³„ì‚°

### ğŸ—ï¸ **ì½”ë“œ ì•„í‚¤í…ì²˜ ìµœì í™”**
- **ì¤‘ë³µ FFmpeg ë¡œì§ í†µí•©**: 40ì¤„ â†’ 10ì¤„ë¡œ ì¶•ì†Œ (75% ê°ì†Œ)
- **ë˜í¼ í•¨ìˆ˜ ì œê±°**: 15ì¤„ â†’ 3ì¤„ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
- **Import ê²½ë¡œ í†µí•©**: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©ìœ¼ë¡œ ëª¨ë“ˆ ì°¸ì¡° ì•ˆì •í™”

### Input/Output Structure
```
videos/input/     # Place video files here (.mp4, .mov, .avi)
videos/output/    # Processed segments output here
temp_proc/        # Temporary processing files (auto-cleaned)
face_tracker.log  # Unified log file
```

### Performance Report Example
```
================================================================================
ğŸ“Š sample.mp4 ì²˜ë¦¬ ì™„ë£Œ ë¦¬í¬íŠ¸
================================================================================
ğŸ¬ ì˜ìƒ: sample.mp4
â±ï¸  ì´ ì²˜ë¦¬ì‹œê°„: 2ë¶„ 15.3ì´ˆ
ğŸ–¼ï¸  ì´ í”„ë ˆì„ ìˆ˜: 3,240
ğŸ“¦ ìƒì„±ëœ ì„¸ê·¸ë¨¼íŠ¸: 5ê°œ
ğŸ–¥ï¸  ì‚¬ìš©ëœ CPU ì½”ì–´: 8/32ê°œ

âš™ï¸ ì„¤ì • ì •ë³´:
   â€¢ ì–¼êµ´ ë¶„ì„ ë°°ì¹˜ í¬ê¸°: 256
   â€¢ ì–¼êµ´ ì¸ì‹ ë°°ì¹˜ í¬ê¸°: 128

ğŸ“ˆ ë‹¨ê³„ë³„ ì„±ëŠ¥:
   â€¢ ì–¼êµ´ ê°ì§€: 45.2ì´ˆ (33.6%) - 71.7 FPS - ë°°ì¹˜: 256
   â€¢ ì–¼êµ´ ì¸ì‹: 38.1ì´ˆ (28.3%) - 85.0 FPS - ë°°ì¹˜: 128
   â€¢ ì–¼êµ´ í¬ë¡­: 28.7ì´ˆ (21.3%) - ì„¸ê·¸ë¨¼íŠ¸: 5ê°œ
   â€¢ ìš”ì•½ë³¸ ìƒì„±: 15.4ì´ˆ (11.4%)

ğŸ¯ ì„±ëŠ¥ ì§€í‘œ:
   â€¢ ì´ ì²˜ë¦¬ ì‹œê°„: 2ë¶„ 15.3ì´ˆ
   â€¢ ì „ì²´ ì²˜ë¦¬ ì†ë„: 24.1 FPS
   â€¢ í”„ë ˆì„ë‹¹ í‰ê·  ì‹œê°„: 41.5ms
   â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 1,247.3 MB
================================================================================
```

### Development Container Setup
```bash
# If using dev container (with GPU support)
cd .devcontainer
docker-compose up --build

# PyTorch CUDA installation (custom)
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Custom OpenCV installation
dpkg -i build_20250710-1_amd64.deb
```

### Input/Output Structure
```
videos/input/     # Place video files here (.mp4, .mov, .avi)
videos/output/    # Processed segments output here
temp_proc/        # Temporary processing files (auto-cleaned)
```

## ğŸ—ï¸ Architecture Deep Dive

### 1. High-Level Processing Pipeline
```
Input Video â†’ Face Analysis â†’ ID Timeline â†’ Condensed Video â†’ 
Target Selection â†’ Video Trimming â†’ Segment Slicing â†’ 
GPU Cropping (Producer-Consumer) â†’ CPU FFmpeg Encoding (Pool) â†’ Final Output
```

### 2. GPU-Optimized Architecture (Key Innovation)

**GPU Worker + CPU Pool Pattern**:
- **Single GPU Worker Process**: Handles all GPU operations sequentially to prevent CUDA OOM
- **CPU Process Pool**: Handles FFmpeg encoding in parallel (max(1, cpu_count()-1) processes)
- **Queue-based Communication**: Tasks flow through multiprocessing Queues

**Producer-Consumer Implementation**:
- **face_analyzer.py**: Frame I/O Thread + GPU Processing Thread
- **id_timeline_generator.py**: Similar threading for face recognition
- **Dynamic Batch Sizing**: 64â†’128â†’256 based on queue depth and GPU memory

### 3. Memory Management System

**ModelManager (Singleton)**:
- MTCNN and InceptionResnetV1 loaded once globally
- GPU memory pool pre-allocation for tensors
- Prevents model reloading across processes

**GPU Memory Safety**:
- `expandable_segments:True` CUDA configuration
- Memory monitoring with automatic batch size adjustment
- Context managers for MoviePy resource cleanup

## ğŸ“ Critical File Structure

```
processors/
â”œâ”€â”€ video_processor.py     # Main pipeline orchestrator
â”œâ”€â”€ face_analyzer.py       # Producer-Consumer face detection
â”œâ”€â”€ id_timeline_generator.py # Producer-Consumer face recognition  
â”œâ”€â”€ gpu_worker.py          # GPU worker process implementation
â””â”€â”€ video_trimmer.py       # Video segmentation and trimming

core/
â”œâ”€â”€ model_manager.py       # Singleton model management
â””â”€â”€ embedding_manager.py   # Face embedding vector management

utils/
â”œâ”€â”€ logger.py              # Advanced logging (console + file)
â”œâ”€â”€ console_logger.py      # Console output to file capture
â”œâ”€â”€ exceptions.py          # Custom exception classes
â””â”€â”€ input_validator.py     # Input file validation

config.py                  # Central configuration
main.py                    # Entry point with logging wrapper
```

## âš™ï¸ Key Configuration Parameters

**Performance Settings** (`config.py`):
```python
BATCH_SIZE_ANALYZE = 256        # Face detection batch size
BATCH_SIZE_ID_TIMELINE = 128    # Face recognition batch size
DEVICE = 'cuda:0'               # GPU device
SEGMENT_LENGTH_SECONDS = 10     # Output segment length
```

**GPU Memory Settings**:
```python
# In main process
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
```

## ğŸ”§ Development Guidelines

### 1. GPU Operations
- **NEVER** create multiple CUDA contexts in different processes
- **ALWAYS** use the single GPU worker pattern for GPU operations
- **USE** ModelManager singleton for all model access
- **MONITOR** GPU memory usage before increasing batch sizes

### 2. Multiprocessing Best Practices
- **USE** `spawn` start method: `set_start_method('spawn', force=True)`
- **SEPARATE** GPU work (single process) from CPU work (process pool)
- **COMMUNICATE** via multiprocessing Queues, not shared memory for complex objects
- **HANDLE** process cleanup in finally blocks

### 3. Error Handling
- **USE** custom exceptions: `GPUMemoryError`, `VideoProcessingError`, `FFmpegError`
- **LOG** all errors to `error_logger` with structured information
- **IMPLEMENT** graceful degradation for GPU memory issues
- **VALIDATE** input files before processing starts

### 4. Performance Optimization
- **IMPLEMENT** Producer-Consumer for I/O-GPU separation
- **USE** dynamic batch sizing based on queue depth
- **PREALLOCATE** tensors in ModelManager memory pool
- **AVOID** PIL â†’ Tensor conversion; use direct OpenCV â†’ Tensor

## ğŸš¨ Common Issues & Solutions

### GPU Memory Issues
```python
# If CUDA OOM occurs:
torch.cuda.empty_cache()
# Reduce batch size in config.py
# Check if multiple processes accessing GPU
```

### Multiprocessing Warnings
```python
# Use spawn method, avoid fork on CUDA
set_start_method('spawn', force=True)
```

### FFmpeg Failures
```python
# Check process_cpu_task() in video_processor.py
# Ensure proper thread allocation: max(1, cpu_count() // 4)
# Validate video codec compatibility
```

### MoviePy Memory Leaks
```python
# Always use context managers or explicit .close()
if clip: clip.close()
```

## ğŸ“Š Performance Monitoring

**Current Benchmarks**:
- GPU Utilization: 97.3% (target: 95%+)
- Processing Speed: 15-20 seconds per video
- Memory Efficiency: Optimized with pre-allocated pools

**Monitor Commands**:
```bash
# GPU monitoring
nvidia-smi -l 1

# Process monitoring  
htop

# Log analysis
tail -f log.log
tail -f videos/output/detailed.log
```

## ğŸ§ª Testing Strategy

**Test Organization**:
- **ALL tests** go in `test/` directory
- **Sample video**: Use `videos/input/sample.mp4` for quick tests
- **Manual testing**: User handles all test execution
- **Never** assume pytest/unittest framework availability

**Testing Workflow**:
1. Create test in `test/` directory
2. User runs test manually
3. Check logs in `log.log` and `videos/output/detailed.log`

## ğŸ”„ Future Development Areas

**Immediate Priority (Stability)**:
1. Enhance exception handling with more granular custom exceptions
2. Implement comprehensive input validation system
3. Add Context Manager pattern for all resource management
4. Create unit tests for core functionality

**Performance Enhancements**:
1. CUDA Stream utilization for async batch processing
2. Memory-mapped file I/O for large video handling
3. Early exit optimization for similarity calculations
4. Advanced caching for embeddings and computations

**Face Recognition Improvements**:
1. **L2 Normalization Implementation (Priority: High)**
   - Add L2 normalization before cosine similarity calculation
   - Location: `src/face_tracker/utils/similarity.py`
   - Expected impact: Improved accuracy in lighting/angle variations
   - Implementation: `torch.nn.functional.normalize(embedding, p=2, dim=1)`
2. **Euclidean Distance Alternative**
   - Alternative distance metric for face comparison
   - May provide better performance for specific data characteristics
3. **SVM Classifier (Long-term)**
   - Machine learning approach for same/different person classification
   - Requires dataset preparation and model training pipeline

**Operational Improvements**:
1. Real-time monitoring dashboard (Flask/FastAPI)
2. Async pipeline for entire workflow
3. Multi-video concurrent processing capability
4. RESTful API with progress tracking

## ğŸ’¡ Critical Development Notes

1. **Always activate virtual environment**: `source .venv/bin/activate`
2. **Test files location**: Create all test files in `test/` directory
3. **Quick testing**: Use `videos/input/sample.mp4` for short video tests
4. **GPU resource management**: Single GPU worker prevents resource conflicts
5. **Memory optimization**: Producer-Consumer pattern eliminates I/O bottlenecks
6. **Error resilience**: System handles GPU memory issues gracefully
7. **Development container**: Full GPU support with custom PyTorch/OpenCV builds
8. **Unified logging system**: Single `face_tracker.log` file with structured logging
9. **Performance reporting**: Automatic detailed reports after each video processing

## ğŸ“ˆ Performance Achievements v1.0

- âœ… **97.3% GPU utilization** (exceeded 95% target)
- âœ… **67% processing time reduction** (45-60s â†’ 15-20s)
- âœ… **Producer-Consumer pattern** implemented in critical paths
- âœ… **Dynamic batch sizing** with memory safety
- âœ… **Zero GPU resource conflicts** through single worker architecture
- âœ… **Unified logging system** with 76 print statements optimized
- âœ… **Performance monitoring** with detailed per-video reports
- âœ… **Code optimization** with 75% reduction in FFmpeg logic duplication
- âœ… **Memory efficiency** through wrapper function elimination

## ğŸ”„ Version History

### v1.0 (2024) - Production Ready
- âœ… Unified logging system implementation
- âœ… Performance reporting system
- âœ… Code architecture optimization
- âœ… 76 print statements â†’ structured logging
- âœ… Single log file (`face_tracker.log`)
- âœ… tqdm progress bar optimization
- âœ… FFmpeg logic consolidation

---

**Version**: 1.0  
**Last Updated**: 2024  
**Status**: Production Ready  
**GPU Optimization**: 97.3%  
**Performance Report**: âœ… Enabled

**For Questions**: Check `README.md`, `refactor.md`, and source code comments