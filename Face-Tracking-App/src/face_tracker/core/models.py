"""
ModelManager í´ë˜ìŠ¤ - ëª¨ë¸ ì‹±ê¸€í†¤ ë§¤ë‹ˆì €
ëª¨ë¸ ì¬ìƒì„± ë°©ì§€ë¡œ ì„±ëŠ¥ í–¥ìƒ
"""
import torch
import torch.nn as nn
import numpy as np
import cv2
from PIL import Image
from facenet_pytorch import MTCNN, InceptionResnetV1
from torchvision import transforms
from src.face_tracker.config import DEVICE, BATCH_SIZE_ANALYZE, FACE_EMBEDDING_DIM, USE_HIGH_DIM_EMBEDDING


class ModelManager:
    """ëª¨ë¸ ì‹±ê¸€í†¤ ë§¤ë‹ˆì € - ëª¨ë¸ ì¬ìƒì„± ë°©ì§€ë¡œ ì„±ëŠ¥ í–¥ìƒ"""
    _instance = None
    _initialized = False
    
    def __new__(cls, device=None):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, device=None, multiprocessing_mode=False):
        if not self._initialized:
            if device is None:
                device = DEVICE
            
            # CUDA ê°€ìš©ì„± ê²€ì‚¬ ë° ì•ˆì „í•œ ë””ë°”ì´ìŠ¤ ì„¤ì •
            import torch
            if 'cuda' in str(device):
                if not torch.cuda.is_available():
                    print(f"âš ï¸ CONSOLE: CUDAê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    device = 'cpu'
                else:
                    # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
                    try:
                        torch.cuda.empty_cache()
                        gpu_memory = torch.cuda.get_device_properties(0).total_memory
                        gpu_allocated = torch.cuda.memory_allocated(0)
                        gpu_available = gpu_memory - gpu_allocated
                        print(f"ğŸ” CONSOLE: GPU ë©”ëª¨ë¦¬ - ì´ ìš©ëŸ‰: {gpu_memory/1024**3:.1f}GB, ì‚¬ìš© ê°€ëŠ¥: {gpu_available/1024**3:.1f}GB")
                    except Exception as e:
                        print(f"âš ï¸ CONSOLE: GPU ë©”ëª¨ë¦¬ í™•ì¸ ì‹¤íŒ¨ - {e}")
            
            self.device = torch.device(device)
            self.multiprocessing_mode = multiprocessing_mode
            
            # ë©€í‹°í”„ë¡œì„¸ì‹± í™˜ê²½ì—ì„œ ë©”ëª¨ë¦¬ ì ˆì•½ ì„¤ì •
            if multiprocessing_mode:
                batch_size = 32  # ë©€í‹°í”„ë¡œì„¸ì‹±ì‹œ ë” ì‘ì€ ë°°ì¹˜
            else:
                batch_size = BATCH_SIZE_ANALYZE
                
            try:
                self.mtcnn = MTCNN(
                    keep_all=True, 
                    device=self.device, 
                    post_process=False,
                    min_face_size=10,  # 15 -> 10ìœ¼ë¡œ í›¨ì”¬ ì‘ì€ ì–¼êµ´ë„ ê°ì§€
                    thresholds=[0.4, 0.5, 0.5],  # [0.5,0.6,0.6] -> [0.4,0.5,0.5] ë§¤ìš° ê´€ëŒ€í•œ íƒì§€
                    factor=0.509,  # 0.609 -> 0.509ë¡œ ë” ì„¸ë°€í•œ ìŠ¤ì¼€ì¼ í”¼ë¼ë¯¸ë“œ 
                    selection_method='probability'  # í™•ë¥  ê¸°ë°˜ ì–¼êµ´ ì„ íƒ
                )
                print(f"âœ… CONSOLE: MTCNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - device: {self.device}")
            except Exception as e:
                print(f"âŒ CONSOLE: MTCNN ë¡œë“œ ì‹¤íŒ¨ - {e}")
                raise
            
            # FaceNet ëª¨ë¸ ì´ˆê¸°í™” (ê³ ì°¨ì› ì„ë² ë”© ì§€ì›)
            try:
                if USE_HIGH_DIM_EMBEDDING:
                    self.resnet = self._create_high_dim_resnet(FACE_EMBEDDING_DIM).to(self.device)
                else:
                    self.resnet = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)
                print(f"âœ… CONSOLE: FaceNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - device: {self.device}")
            except Exception as e:
                print(f"âŒ CONSOLE: FaceNet ë¡œë“œ ì‹¤íŒ¨ - {e}")
                raise
            
            # GPU ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™”
            try:
                self._init_memory_pool()
            except Exception as e:
                print(f"âŒ CONSOLE: GPU ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì‹¤íŒ¨ - {e}")
                # ë©”ëª¨ë¦¬ í’€ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            
            self._initialized = True
            self.batch_size = batch_size  # ë°°ì¹˜ í¬ê¸° ì €ì¥  # ë°°ì¹˜ í¬ê¸° ì €ì¥
    
    def _create_high_dim_resnet(self, embedding_dim):
        """ê³ ì°¨ì› ì„ë² ë”©ìš© FaceNet ëª¨ë¸ ìƒì„±"""
        # ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
        base_resnet = InceptionResnetV1(pretrained='vggface2')
        
        # ê¸°ì¡´ 512ì°¨ì› ì¶œë ¥ì„ ì‚¬ìš©í•˜ì—¬ ê³ ì°¨ì›ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ì¶”ê°€ ë ˆì´ì–´ ìƒì„±
        class HighDimWrapper(nn.Module):
            def __init__(self, base_model, target_dim, device):
                super().__init__()
                self.base_model = base_model
                self._device = device  # device ì†ì„± ì €ì¥
                # 512ì°¨ì› â†’ target_dimìœ¼ë¡œ í™•ì¥í•˜ëŠ” ë ˆì´ì–´ ì¶”ê°€
                self.expansion_layer = nn.Linear(512, target_dim)
                
                # Xavier ì´ˆê¸°í™”
                nn.init.xavier_uniform_(self.expansion_layer.weight)
                nn.init.zeros_(self.expansion_layer.bias)
            
            @property 
            def device(self):
                """device ì†ì„± ì ‘ê·¼ì"""
                return self._device
            
            def forward(self, x):
                # ê¸°ì¡´ 512ì°¨ì› ì„ë² ë”© ì¶”ì¶œ
                base_embedding = self.base_model(x)
                # ê³ ì°¨ì›ìœ¼ë¡œ í™•ì¥
                expanded_embedding = self.expansion_layer(base_embedding)
                return expanded_embedding
        
        return HighDimWrapper(base_resnet, embedding_dim, self.device).eval()
    
    def _init_memory_pool(self):
        """GPU ë©”ëª¨ë¦¬ í’€ ì‚¬ì „ í• ë‹¹"""
        import torch
        from torchvision import transforms
        
        if self.device.type == 'cuda':
            try:
                # ë°°ì¹˜ í…ì„œ í’€ (config ë°°ì¹˜ í¬ê¸° ê¸°ì¤€)
                self.tensor_pool = torch.zeros(BATCH_SIZE_ANALYZE, 3, 224, 224, device=self.device)
                # ë‹¨ì¼ ì–¼êµ´ ì„ë² ë”©ìš© í…ì„œ í’€
                self.face_tensor_pool = torch.zeros(1, 3, 160, 160, device=self.device)
                # ë³€í™˜ ê°ì²´ ì‚¬ì „ ìƒì„±
                self.to_tensor = transforms.ToTensor()
                
                # ë©”ëª¨ë¦¬ í’€ ì„±ê³µì ìœ¼ë¡œ í• ë‹¹
                allocated_memory = torch.cuda.memory_allocated(self.device)
                print(f"âœ… CONSOLE: GPU ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì™„ë£Œ - device: {self.device}, ë°°ì¹˜í¬ê¸°: {BATCH_SIZE_ANALYZE}")
                print(f"ğŸ” CONSOLE: í• ë‹¹ëœ GPU ë©”ëª¨ë¦¬: {allocated_memory/1024**2:.1f}MB")
                
            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    print(f"âš ï¸ CONSOLE: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë©”ëª¨ë¦¬ í’€ ë¹„í™œì„±í™” - {e}")
                    # ë©”ëª¨ë¦¬ í’€ ì—†ì´ ë™ì‘í•˜ë„ë¡ None ì„¤ì •
                    self.tensor_pool = None
                    self.face_tensor_pool = None
                    self.to_tensor = transforms.ToTensor()
                    # GPU ìºì‹œ ì •ë¦¬
                    torch.cuda.empty_cache()
                else:
                    print(f"âŒ CONSOLE: GPU ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì—ëŸ¬ - {e}")
                    raise
            except Exception as e:
                print(f"âŒ CONSOLE: ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ - {e}")
                # ì•ˆì „ì„ ìœ„í•´ Noneìœ¼ë¡œ ì„¤ì •
                self.tensor_pool = None  
                self.face_tensor_pool = None
                self.to_tensor = transforms.ToTensor()
        else:
            # CPU ëª¨ë“œì—ì„œëŠ” ë©”ëª¨ë¦¬ í’€ ë¹„í™œì„±í™”
            self.tensor_pool = None
            self.face_tensor_pool = None 
            self.to_tensor = transforms.ToTensor()
            print(f"ğŸ” CONSOLE: CPU ëª¨ë“œ - ë©”ëª¨ë¦¬ í’€ ë¹„í™œì„±í™”")
    
    def get_mtcnn(self):
        return self.mtcnn
    
    def detect_faces_multi_scale(self, frame):
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ë¡œ ì–¼êµ´ ê°ì§€ (ë” ê°•ë ¥í•œ ê°ì§€)"""
        import cv2
        original_size = frame.shape[:2]  # (height, width)
        
        # ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ì—ì„œ ì–¼êµ´ ê°ì§€ ì‹œë„ (ë” ë§ì€ ìŠ¤ì¼€ì¼)
        scales = [1.0, 0.8, 1.2, 0.6, 1.5, 0.5, 1.8, 0.4]  # ë” ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼
        all_boxes = []
        all_probs = []
        
        for scale in scales:
            if scale != 1.0:
                # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
                new_h, new_w = int(original_size[0] * scale), int(original_size[1] * scale)
                if new_h < 50 or new_w < 50:  # ë„ˆë¬´ ì‘ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                    continue
                scaled_frame = cv2.resize(frame, (new_w, new_h))
            else:
                scaled_frame = frame
            
            try:
                # MTCNNìœ¼ë¡œ ì–¼êµ´ ê°ì§€
                boxes, probs = self.mtcnn.detect(scaled_frame)
                
                if boxes is not None and len(boxes) > 0:
                    # ìŠ¤ì¼€ì¼ì— ë”°ë¥¸ ì¢Œí‘œ ë³´ì •
                    if scale != 1.0:
                        boxes = boxes / scale
                    
                    all_boxes.extend(boxes)
                    all_probs.extend(probs)
                    
            except Exception as e:
                # íŠ¹ì • ìŠ¤ì¼€ì¼ì—ì„œ ì˜¤ë¥˜ ë°œìƒì‹œ ê±´ë„ˆë›°ê¸°
                continue
        
        if len(all_boxes) == 0:
            return None, None
        
        # ì¤‘ë³µ ì œê±° ë° ìµœê³  í™•ë¥  ì„ íƒ
        import numpy as np
        all_boxes = np.array(all_boxes)
        all_probs = np.array(all_probs)
        
        # í™•ë¥  ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_indices = np.argsort(all_probs)[::-1]
        
        return all_boxes[sorted_indices], all_probs[sorted_indices]
    
    def get_resnet(self):
        return self.resnet
    
    def get_tensor_pool(self, batch_size=BATCH_SIZE_ANALYZE):
        """ì‚¬ì „ í• ë‹¹ëœ í…ì„œ í’€ ë°˜í™˜"""
        if self.device.type == 'cuda':
            if batch_size <= BATCH_SIZE_ANALYZE:
                return self.tensor_pool[:batch_size]
            else:
                # ë” í° ë°°ì¹˜ ì‚¬ì´ì¦ˆë©´ ë™ì  í• ë‹¹
                return torch.zeros(batch_size, 3, 224, 224, device=self.device)
        return None
    
    def get_face_tensor_pool(self):
        """ì–¼êµ´ ì„ë² ë”©ìš© í…ì„œ í’€ ë°˜í™˜"""
        if self.device.type == 'cuda':
            return self.face_tensor_pool
        return None
    
    def get_transform(self):
        """ì‚¬ì „ ìƒì„±ëœ ë³€í™˜ ê°ì²´ ë°˜í™˜"""
        return self.to_tensor
    
    def opencv_to_tensor_batch(self, frames_list):
        """OpenCV í”„ë ˆì„ë“¤ì„ ë°°ì¹˜ í…ì„œë¡œ ì§ì ‘ ë³€í™˜ (PIL ê±´ë„ˆë›°ê¸°)"""
        if not frames_list:
            return None
            
        batch_size = len(frames_list)
        if batch_size == 0:
            return None
            
        # OpenCV BGR â†’ RGB ë³€í™˜ê³¼ ë™ì‹œì— numpy ë°°ì—´ë¡œ ë³€í™˜
        rgb_frames = []
        for frame in frames_list:
            if isinstance(frame, Image.Image):
                # PIL ì´ë¯¸ì§€ë©´ numpyë¡œ ë³€í™˜
                rgb_frame = np.array(frame)
            else:
                # OpenCV í”„ë ˆì„ì´ë©´ BGR â†’ RGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            rgb_frames.append(rgb_frame)
        
        # numpy ë°°ì—´ ìŠ¤íƒ
        batch_array = np.stack(rgb_frames, axis=0)
        
        # numpy â†’ tensor ì§ì ‘ ë³€í™˜ (HWC â†’ CHW, 0-255 â†’ 0-1)
        batch_tensor = torch.from_numpy(batch_array).permute(0, 3, 1, 2).float() / 255.0
        
        # GPUë¡œ ì „ì†¡
        if self.device.type == 'cuda':
            batch_tensor = batch_tensor.to(self.device, non_blocking=True)
            
        return batch_tensor