# Face-Tracking-App 최적화 진행 상황
# 세션 날짜: 2025-01-15

## 🎯 전체 최적화 목표
- 처리 속도 향상을 위한 성능 최적화
- 기능은 그대로 유지하면서 속도만 개선
- 배치 사이즈: 현재 256 (1단계에서 128로 변경됨)

## ✅ 완료된 최적화 (우선순위 순)

### 1순위: ModelManager 싱글톤 패턴 ✅
**문제**: 3개 함수에서 각각 MTCNN, ResNet 모델 재생성
- analyze_video_faces:135 - MTCNN 생성
- generate_id_timeline:45-46 - MTCNN + ResNet 재생성  
- track_and_crop_video:205,208 - MTCNN + ResNet 또 재생성

**해결**: 싱글톤 패턴으로 모델 1번만 생성하여 재사용
**예상 효과**: GPU 메모리 로딩 시간 40-60% 단축

### 1순위-A: generate_id_timeline 배치 처리 ✅
**문제**: 매 프레임마다 개별 처리 → 배치 처리로 변경
**해결**: 128개 프레임씩 배치로 처리
**예상 효과**: 300-500% 성능 향상

### 2순위: GPU 메모리 풀 ✅
**문제**: 매 프레임마다 새로운 텐서 생성/해제
**해결**: 사전 할당된 메모리 풀에서 텐서 재사용
- 배치 텐서 풀: 256개 프레임용
- 얼굴 임베딩용 텐서 풀: 1개 프레임용
**예상 효과**: 메모리 할당/해제 오버헤드 20-30% 감소

### 3순위: CPU↔GPU 전송 최적화 ✅
**문제**: PIL → transforms.ToTensor() → GPU (3단계)
**해결**: PIL → numpy → torch.from_numpy() → GPU (2단계)
**최적화 지점**:
- track_and_crop_video 재초기화 시 BGR→RGB 변환 1번만 실행
- generate_id_timeline 배치 처리 시 변환 순서 최적화
- analyze_video_faces 배치 변환 패턴 일관성 개선
**예상 효과**: CPU↔GPU 전송 시간 15-25% 감소

### 4순위: I/O 최적화 (일부 롤백) ❌→✅
**시도**: 세그먼트 병렬 처리
**문제**: 병렬 처리로 인한 GPU 경합, 세그먼트 손실, 트래킹 품질 저하
**해결**: 순차 처리로 복원, 인코딩 최적화만 유지
**결과**: 안정성 우선으로 복원

### 2순위 추가: 동적 재초기화 ✅
**문제**: 무조건 40프레임마다 MTCNN 재실행
**해결**: 트래커 성능 기반 적응적 재초기화
**구현**:
- TrackerMonitor 클래스 (20프레임 성공률 추적)
- 성공률 95%+ → 80프레임 간격
- 성공률 80%+ → 40프레임 간격  
- 성공률 60%+ → 20프레임 간격
- 성공률 60%- → 10프레임 간격
**예상 효과**: 30-50% 성능 향상

### 3순위 추가: 중복 연산 제거 ✅
**문제**: 같은 프레임에서 여러 번 BGR→RGB 변환, PIL 객체 생성
**해결**: 
- track_and_crop_video: 재초기화 시 1번만 변환하여 재사용
- generate_id_timeline: 배치 처리 시 변환 순서 최적화
- analyze_video_faces: 배치 변환 패턴 개선
**예상 효과**: CPU 연산 20-30% 감소

### 코드 정리 ✅
**제거된 항목**:
- 사용되지 않는 매개변수: track_and_crop_video의 batch_size
- 사용되지 않는 import: argparse, ThreadPoolExecutor, as_completed, threading
- 중복 import: from tqdm import tqdm
- 사용되지 않는 함수: process_single_segment
- Pylance 경고 수정

### 4순위: 메모리 최적화 ✅
**문제**: prev_embs 딕셔너리 무제한 누적, 유사도 계산 O(n)
**해결**: SmartEmbeddingManager 클래스 구현
**기능**:
- LRU 캐시: 최대 15개 ID 제한
- TTL 정리: 30초간 미사용 ID 자동 만료  
- 접근 빈도 추적: 자주 사용되는 ID 우선 보존
- 통계 정보: 실시간 메모리 사용량 모니터링
**예상 효과**: 메모리 사용량 대폭 절약, 유사도 계산 O(15) 상수 시간

## 🔄 진행 중인 이슈

### VAD (Voice Activity Detection) 기능
**현재 상태**: 구현되어 있지만 사용되지 않음
**원래 목적**: 화자별 음성 구간 분할을 위한 준비 작업
**최종 목표**: 
- 영상에서 말하는 사람별로 구분
- 각 화자가 말할 때만 세그먼트 생성
- 현재는 1명만 말하는 샘플로 테스트 중
**결정**: 1차 성능 개선 완료 후 기능 구현 예정

## 🚀 남은 개선사항 (우선순위 순)

### 5순위: 알고리즘 개선 (10-20% 향상 가능)

#### A. 코사인 유사도 계산 조기 종료 ⭐ 다음 우선순위
**문제**: 매번 모든 ID와 비교 후 최대값 찾기
**위치**: 
- generate_id_timeline:306
- track_and_crop_video:544
**현재**: 모든 ID 비교 → 최대값 찾기 → 0.8 이상 체크
**개선**: 0.8 이상 찾으면 즉시 중단 (조기 종료)
**예상 효과**: 10-15% 향상

#### B. 트래커 타입 최적화
**문제**: cv2.TrackerCSRT_create() - 정확하지만 느림
**해결**: 상황별 트래커 선택 (CSRT → KCF/MOSSE)
**예상 효과**: 15-25% 향상

### 6순위: 세부 최적화 (5-10% 향상)

#### A. 불필요한 변수 할당 제거
**문제**: 중간 변수들이 메모리 점유
**예**: all_embs = emb_manager.get_all_embeddings() → 직접 사용

#### B. 프레임 스키핑 최적화
**문제**: 모든 프레임 처리 (30fps 전체)
**해결**: 중요하지 않은 프레임 건너뛰기 (15fps로 다운샘플링)

#### C. 텐서 연산 최적화
**문제**: 개별 cosine similarity 계산
**해결**: 배치 cosine similarity 계산

## 📊 누적 성능 향상 예상치
- 1순위 (모델 싱글톤): 40-60%
- 1순위-A (배치 처리): 300-500%
- 2순위 (GPU 메모리 풀): 20-30%
- 2순위 추가 (동적 재초기화): 30-50%
- 3순위 (전송 최적화): 15-25%
- 3순위 추가 (중복 제거): 20-30%
- 4순위 (메모리 최적화): 20-30%

**예상 총 성능 향상**: 대략 5-10배 향상 (특히 긴 영상에서)

## 🔧 현재 설정값
- 배치 사이즈: analyze_video_faces=256, generate_id_timeline=128
- 임베딩 매니저: max_size=15, ttl_seconds=30
- 트래커 모니터: window_size=20
- 재초기화 간격: 10-80프레임 (적응적)
- 유사도 임계값: 0.8

## 💡 다음 세션에서 할 일
1. 5A (유사도 조기 종료) 구현 - 가장 간단하고 효과적
2. 5B (트래커 최적화) 검토
3. 전체 성능 테스트 및 측정
4. VAD 기능 활용 방안 논의

## 🗂️ 주요 파일
- track_and_draw_video.py: 메인 처리 파일
- 입력: ./videos/input/
- 출력: ./videos/output/
- 임시: temp_proc/

## 📝 개발 노트
- 기능 변화 없이 속도만 개선하는 것이 목표
- 각 최적화 후 동일한 결과 확인 필요
- 롤백 가능하도록 단계별 적용
- 1분 샘플 → 4개 세그먼트 (10초씩) 결과 확인