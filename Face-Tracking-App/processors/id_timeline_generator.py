"""
ID íƒ€ì„ë¼ì¸ ìƒì„± ëª¨ë“ˆ - Producer-Consumer ìµœì í™”
"""
import cv2
import torch
import numpy as np
import threading
import time
from PIL import Image
from tqdm import tqdm
from queue import Queue, Empty
import torch.nn.functional as F
from torchvision import transforms
from core.model_manager import ModelManager
from core.embedding_manager import SmartEmbeddingManager
from config import DEVICE, BATCH_SIZE_ID_TIMELINE, SIMILARITY_THRESHOLD
from utils.similarity_utils import find_matching_id_with_best_fallback


def generate_id_timeline(video_path: str, device=DEVICE, batch_size: int = BATCH_SIZE_ID_TIMELINE):
    """
    Producer-Consumer íŒ¨í„´ì„ ì‚¬ìš©í•œ ìµœì í™”ëœ ID íƒ€ì„ë¼ì¸ ìƒì„±
    
    Args:
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
        batch_size: ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
    
    Returns:
        tuple: (ID íƒ€ì„ë¼ì¸, fps)
    """
    print("ğŸ¯ refactor.md ID íƒ€ì„ë¼ì¸ Producer-Consumer ì‹œì‘")
    print("ğŸ”„ Producer Thread: ë¹„ë””ì˜¤ í”„ë ˆì„ I/O") 
    print("âš¡ Consumer Thread: MTCNN + ResNet GPU ì²˜ë¦¬")
    
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    # Producer-Consumer ì„¤ì •
    frame_queue = Queue(maxsize=512)  # refactor.md ê¸°ì¤€ í í¬ê¸°
    id_timeline = []
    timeline_lock = threading.Lock()
    producer_finished = threading.Event()
    
    # ê³µìœ  ëª¨ë¸ ë° ë°ì´í„°
    model_manager = ModelManager(device)
    mtcnn = model_manager.get_mtcnn()
    resnet = model_manager.get_resnet()
    emb_manager = SmartEmbeddingManager()
    next_id = [1]  # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ìŠ¤ë ˆë“œ ê°„ ê³µìœ 
    
    pbar = tqdm(total=total_frames, desc="[ID íƒ€ì„ë¼ì¸ Producer-Consumer]")
    
    def producer():
        """Producer Thread: ë¹„ë””ì˜¤ í”„ë ˆì„ I/O ì „ë‹´"""
        frame_index = 0
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # í”„ë ˆì„ê³¼ ì¸ë±ìŠ¤ë¥¼ í•¨ê»˜ íì— ì „ë‹¬ (ìˆœì„œ ë³´ì¡´)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_queue.put((frame_index, rgb_frame), timeout=30)  # 5â†’30ì´ˆë¡œ ì¦ê°€
                frame_index += 1
                
        except Exception as e:
            print(f"Producer ì˜¤ë¥˜: {e}")
        finally:
            cap.release()
            producer_finished.set()
            print("ğŸ”„ Producer ì™„ë£Œ")
    
    def consumer():
        """Consumer Thread: MTCNN + ResNet GPU ì²˜ë¦¬ ì „ë‹´"""
        batch_buffer = []
        processed_frames = 0
        
        # ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ì €ì¥í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        results_dict = {}
        
        try:
            while not producer_finished.is_set() or not frame_queue.empty():
                try:
                    # ë°°ì¹˜ ìˆ˜ì§‘
                    while len(batch_buffer) < batch_size:
                        try:
                            frame_data = frame_queue.get(timeout=1.0)  # 0.1â†’1.0ì´ˆë¡œ ì¦ê°€
                            batch_buffer.append(frame_data)
                        except Empty:
                            if producer_finished.is_set():
                                break
                            continue
                    
                    if batch_buffer:
                        # ë°°ì¹˜ ë°ì´í„° ë¶„ë¦¬
                        frame_indices, rgb_frames = zip(*batch_buffer)
                        pil_images = [Image.fromarray(rgb_frame) for rgb_frame in rgb_frames]
                        
                        # GPU ë°°ì¹˜ ì²˜ë¦¬
                        start_gpu = time.time()
                        
                        # 1. MTCNN ì–¼êµ´ ê°ì§€ (ë°°ì¹˜)
                        boxes_list, _ = mtcnn.detect(pil_images)
                        
                        # 2. ResNet ì–¼êµ´ ì¸ì‹ (ë°°ì¹˜)
                        valid_faces = []
                        valid_indices = []
                        
                        for i, boxes in enumerate(boxes_list):
                            if boxes is not None and len(boxes) > 0:
                                x1, y1, x2, y2 = boxes[0]
                                face_crop = pil_images[i].crop((x1, y1, x2, y2)).resize((160, 160))
                                valid_faces.append(face_crop)
                                valid_indices.append(i)
                        
                        # ResNet ë°°ì¹˜ ì²˜ë¦¬
                        track_ids = []
                        if valid_faces:
                            face_tensors = torch.stack([
                                transforms.ToTensor()(face) for face in valid_faces
                            ]).to(device)
                            
                            embeddings = resnet(face_tensors)  # ë°°ì¹˜ GPU ì²˜ë¦¬
                            
                            # ID í• ë‹¹
                            for emb in embeddings:
                                all_embs = emb_manager.get_all_embeddings()
                                track_id = find_matching_id_with_best_fallback(
                                    emb.unsqueeze(0), all_embs, SIMILARITY_THRESHOLD
                                )
                                if track_id is None:
                                    track_id = next_id[0]
                                    next_id[0] += 1
                                emb_manager.add_embedding(track_id, emb.unsqueeze(0))
                                track_ids.append(track_id)
                        
                        gpu_time = time.time() - start_gpu
                        
                        # ê²°ê³¼ ì €ì¥ (Thread-safe)
                        valid_idx = 0
                        for i, frame_idx in enumerate(frame_indices):
                            if i in valid_indices:
                                results_dict[frame_idx] = track_ids[valid_idx]
                                valid_idx += 1
                            else:
                                results_dict[frame_idx] = None
                        
                        processed_frames += len(batch_buffer)
                        pbar.update(len(batch_buffer))
                        
                        # ì„±ëŠ¥ ë¡œê·¸
                        if len(batch_buffer) >= 256:
                            print(f"ğŸš€ ID ë°°ì¹˜: {len(batch_buffer)}í”„ë ˆì„, GPU: {gpu_time:.2f}ì´ˆ")
                        
                        batch_buffer.clear()
                        
                except Exception as e:
                    print(f"Consumer ë°°ì¹˜ ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"Consumer ì˜¤ë¥˜: {e}")
        finally:
            # ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ì¬ì¡°ë¦½
            with timeline_lock:
                if results_dict:  # ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ
                    for i in range(total_frames):
                        id_timeline.append(results_dict.get(i, None))
                else:
                    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ëª¨ë“  í”„ë ˆì„ì„ Noneìœ¼ë¡œ ì„¤ì •
                    print("âš ï¸ ê²½ê³ : ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ì–´ ëª¨ë“  í”„ë ˆì„ì„ Noneìœ¼ë¡œ ì„¤ì •")
                    for i in range(total_frames):
                        id_timeline.append(None)
            
            print(f"âš¡ Consumer ì™„ë£Œ: {processed_frames}í”„ë ˆì„ ì²˜ë¦¬")
    
    # ìŠ¤ë ˆë“œ ì‹œì‘
    producer_thread = threading.Thread(target=producer, daemon=True)
    consumer_thread = threading.Thread(target=consumer, daemon=True)
    
    start_time = time.time()
    producer_thread.start()
    consumer_thread.start()
    
    # ì™„ë£Œ ëŒ€ê¸°
    producer_thread.join()
    consumer_thread.join()
    pbar.close()
    
    total_time = time.time() - start_time
    print(f"ğŸ¯ ID íƒ€ì„ë¼ì¸ ìµœì í™” ì™„ë£Œ: {total_time:.2f}ì´ˆ")
    
    return id_timeline, fps