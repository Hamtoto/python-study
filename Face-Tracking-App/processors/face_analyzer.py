"""
ì–¼êµ´ íƒì§€ ë° ë¶„ì„ ëª¨ë“ˆ - Producer-Consumer ìµœì í™”
"""
import os
import cv2
import torch
import numpy as np
import threading
import time
from PIL import Image
from tqdm import tqdm
from queue import Queue, Empty
from core.model_manager import ModelManager
from config import DEVICE, BATCH_SIZE_ANALYZE

# OpenCV ìµœì í™” í”Œë˜ê·¸ ì„¤ì •
os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'hwaccel;auto'
os.environ['OPENCV_VIDEOIO_PRIORITY_MSMF'] = '0'


def calculate_optimal_batch_size(frame_queue, gpu_memory_usage=None):
    """Queue ê¹Šì´ ê¸°ë°˜ ë™ì  ë°°ì¹˜ í¬ê¸° ê³„ì‚° - GPU ë©”ëª¨ë¦¬ ì•ˆì „"""
    try:
        queue_depth = frame_queue.qsize()
        if queue_depth > 256:  # ì¶©ë¶„í•œ í”„ë ˆì„ ëŒ€ê¸° ì¤‘
            return 256  # ì¤‘ê°„ ë°°ì¹˜ë¡œ ì œí•œ (ë©”ëª¨ë¦¬ ì•ˆì „)
        elif queue_depth > 128:
            return 128  # ì‘ì€ ë°°ì¹˜
        else:
            return 64  # ìµœì†Œ ë°°ì¹˜ (ë¹ ë¥¸ ì‹œì‘)
    except:
        return 64  # ê¸°ë³¸ê°’ (ì•ˆì „)


def analyze_video_faces(video_path: str, batch_size: int = BATCH_SIZE_ANALYZE, device=DEVICE) -> tuple[list[bool], float]:
    """
    Producer-Consumer íŒ¨í„´ì„ ì‚¬ìš©í•œ ìµœì í™”ëœ ì–¼êµ´ íƒì§€ ë¶„ì„
    
    Args:
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        batch_size: ê¸°ë³¸ ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° (ë™ì  ì¡°ì •ë¨)
        device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (CPU/GPU)
    
    Returns:
        tuple: (ì–¼êµ´ íƒì§€ íƒ€ì„ë¼ì¸, fps)
    """
    print("ğŸ¯ refactor.md ì–¼êµ´ ë¶„ì„ Producer-Consumer ì‹œì‘")
    print("ğŸ”„ Producer Thread: ë¹„ë””ì˜¤ I/O")
    print("âš¡ Consumer Thread: MTCNN GPU ì²˜ë¦¬")
    
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ìµœì†Œí™”
    
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    # Producer-Consumer ì„¤ì •
    frame_queue = Queue(maxsize=512)  # refactor.md ê¸°ì¤€ í í¬ê¸°
    face_detected_timeline = []
    timeline_lock = threading.Lock()
    producer_finished = threading.Event()
    
    model_manager = ModelManager(device)
    mtcnn = model_manager.get_mtcnn()
    pbar = tqdm(total=frame_count, desc="[GPU 97%+ ë¶„ì„]")
    
    def producer():
        """Producer Thread: ë¹„ë””ì˜¤ í”„ë ˆì„ I/O ì „ë‹´"""
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # OpenCV BGR â†’ RGB ë³€í™˜ (I/O ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_queue.put(rgb_frame, timeout=5)
                
        except Exception as e:
            print(f"Producer ì˜¤ë¥˜: {e}")
        finally:
            cap.release()
            producer_finished.set()
            print("ğŸ”„ Producer ì™„ë£Œ")
    
    def consumer():
        """Consumer Thread: MTCNN GPU ì²˜ë¦¬ ì „ë‹´"""
        buffer = []
        processed_frames = 0
        
        try:
            while not producer_finished.is_set() or not frame_queue.empty():
                try:
                    # ë™ì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
                    optimal_batch = calculate_optimal_batch_size(frame_queue)
                    
                    # í”„ë ˆì„ ìˆ˜ì§‘
                    while len(buffer) < optimal_batch:
                        try:
                            frame = frame_queue.get(timeout=0.1)
                            buffer.append(frame)
                        except Empty:
                            if producer_finished.is_set():
                                break
                            continue
                    
                    if buffer:
                        # MTCNN GPU ë°°ì¹˜ ì²˜ë¦¬
                        start_gpu = time.time()
                        boxes_list, _ = mtcnn.detect(buffer)  # GPU ì²˜ë¦¬
                        gpu_time = time.time() - start_gpu
                        
                        # ê²°ê³¼ ì €ì¥ (Thread-safe)
                        face_results = [b is not None for b in boxes_list]
                        with timeline_lock:
                            face_detected_timeline.extend(face_results)
                        
                        processed_frames += len(buffer)
                        pbar.update(len(buffer))
                        
                        # ì„±ëŠ¥ ë¡œê·¸ (í° ë°°ì¹˜ë§Œ)
                        if len(buffer) >= 256:
                            print(f"ğŸš€ ë™ì  ë°°ì¹˜: {len(buffer)}í”„ë ˆì„, GPU: {gpu_time:.2f}ì´ˆ")
                        
                        buffer.clear()
                        
                except Exception as e:
                    print(f"Consumer ë°°ì¹˜ ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"Consumer ì˜¤ë¥˜: {e}")
        finally:
            print(f"âš¡ Consumer ì™„ë£Œ: {processed_frames}í”„ë ˆì„ ì²˜ë¦¬")
    
    # ìŠ¤ë ˆë“œ ì‹œì‘
    producer_thread = threading.Thread(target=producer, daemon=True)
    consumer_thread = threading.Thread(target=consumer, daemon=True)
    
    start_time = time.time()
    producer_thread.start()
    consumer_thread.start()
    
    # ì™„ë£Œ ëŒ€ê¸°
    producer_thread.join()
    consumer_thread.join()
    pbar.close()
    
    total_time = time.time() - start_time
    print(f"ğŸ¯ GPU ìµœì í™” ì™„ë£Œ: {total_time:.2f}ì´ˆ")
    
    return face_detected_timeline, fps