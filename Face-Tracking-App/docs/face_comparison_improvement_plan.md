# 얼굴 인식 비교 방식 개선 계획서

**문서 목적**: 현재 Face-Tracking-App의 얼굴 임베딩 벡터 비교 방식의 한계를 분석하고, 정확도 향상을 위한 기술적 개선 방안을 제시합니다.

---

## 1. 현재 시스템 분석

- **현재 방식**: **코사인 유사도 (Cosine Similarity)**
- **프로세스**:
    1. ResNet 기반의 모델로 각 얼굴에서 512차원의 임베딩 벡터를 추출합니다.
    2. 두 임베딩 벡터 간의 코사인 유사도를 계산합니다.
    3. 계산된 유사도 값이 사전에 정의된 임계값(`SIMILARITY_THRESHOLD`, 예: 0.6)보다 높으면 '같은 사람'으로, 낮으면 '다른 사람'으로 판단합니다.
- **한계점**:
    - 코사인 유사도는 벡터의 '방향'에만 집중하므로, 조명이나 표정 변화로 인한 벡터의 '크기(magnitude)' 변화에 강건한 편입니다. 하지만, 이것이 항상 최적의 성능을 보장하지는 않습니다.
    - 단순 임계값 방식은 다양한 예외 상황(쌍둥이, 비슷한 외모, 조명 변화가 극심한 경우 등)에 정교하게 대응하기 어렵습니다.

---

## 2. 개선 방안 제안

정확도와 구현 복잡도를 고려하여 다음과 같은 세 가지 개선 방안을 제안합니다.

### 방안 1: L2 정규화 (L2 Normalization) 추가 (권장)

- **개념**: 임베딩 벡터를 비교하기 전에, 각 벡터의 크기(L2 Norm)를 1로 만들어주는 정규화 단계를 추가합니다.
- **프로세스**:
    1. 임베딩 벡터 `A`와 `B`를 각각 L2 정규화하여 `A_norm`과 `B_norm`을 생성합니다.
    2. `A_norm`과 `B_norm` 간의 코사인 유사도를 계산합니다.
- **장점**:
    - **성능 향상**: 벡터의 크기(magnitude) 정보를 제거하고 순수하게 방향(얼굴 특징의 패턴) 정보에만 집중하게 만들어, 조명이나 미세한 각도 변화에 더욱 강건해집니다. 많은 SOTA(최신 기술) 얼굴 인식 모델에서 표준적으로 사용되는 기법입니다.
    - **낮은 구현 복잡도**: PyTorch의 `torch.nn.functional.normalize` 함수를 사용하여 단 한 줄의 코드로 구현 가능합니다.
    - **안정성**: 기존 코사인 유사도 로직을 그대로 활용하면서 정확도를 안정적으로 개선할 수 있습니다.
- **단점**: 거의 없음. 표준적인 개선 방식입니다.
- **예상 구현 위치**: `src/face_tracker/utils/similarity.py` 내 유사도 계산 함수.

### 방안 2: 유클리드 거리 (Euclidean Distance) 사용

- **개념**: 두 임베딩 벡터의 끝점을 잇는 가장 짧은 직선 거리를 측정합니다. 거리가 가까울수록(값이 작을수록) 유사한 얼굴입니다.
- **프로세스**:
    1. 두 임베딩 벡터 `A`와 `B`의 차이를 구합니다.
    2. 차이 벡터의 L2 Norm(크기)을 계산합니다.
    3. 이 거리가 특정 임계값보다 작으면 '같은 사람'으로 판단합니다.
- **장점**:
    - 코사인 유사도와는 다른 관점(거리)에서 유사성을 측정하므로, 데이터 특성에 따라 더 나은 성능을 보일 수 있습니다.
- **단점**:
    - **L2 정규화와 병행 시 의미 희석**: 만약 L2 정규화를 적용한다면, 모든 벡터는 단위 구(unit sphere) 상의 한 점이 됩니다. 이 경우, 두 점 사이의 유클리드 거리는 코사인 유사도와 단조적인(monotonic) 관계가 되어 사실상 거의 동일한 결과를 냅니다. 따라서 L2 정규화를 채택한다면 유클리드 거리를 별도로 구현할 실익이 적습니다.

### 방안 3: SVM (Support Vector Machine) 분류기 도입

- **개념**: 단순 임계값 비교를 넘어, 두 임베딩 벡터의 차이를 입력받아 '같은 사람'인지 '다른 사람'인지 분류하는 머신러닝 모델을 학습시킵니다.
- **프로세스**:
    1. **데이터셋 준비**: '같은 사람'의 임베딩 벡터 쌍과 '다른 사람'의 임베딩 벡터 쌍으로 구성된 학습 데이터셋을 구축합니다.
    2. **모델 학습**: 이 데이터셋을 사용하여 SVM 모델을 학습시킵니다. 모델은 두 클래스를 가장 잘 구분하는 최적의 결정 경계(decision boundary)를 찾습니다.
    3. **추론**: 새로운 두 임베딩이 들어오면, 벡터의 차이를 SVM 모델에 입력하여 'same' 또는 'different' 클래스로 분류합니다.
- **장점**:
    - **높은 정확도**: 데이터에 특화된 최적의 분류 기준을 학습하므로, 세 가지 방안 중 가장 높은 정확도를 기대할 수 있습니다.
- **단점**:
    - **높은 구현 복잡도**: 별도의 학습 데이터셋 구축, 모델 학습 및 관리 파이프라인이 필요합니다.
    - **유지보수 비용**: 새로운 데이터가 추가되면 모델을 재학습해야 할 수 있습니다.

---

## 3. 최종 결론 및 실행 계획

**단기적이고 효율적인 성능 개선을 위해 `방안 1: L2 정규화 추가`를 최우선으로 진행할 것을 강력히 권장합니다.**

1.  **1단계 (즉시 실행 가능)**: `similarity` 관련 모듈에 L2 정규화 로직을 추가합니다. 기존 코사인 유사도 계산 전에 각 벡터를 정규화하도록 수정합니다.
2.  **2단계 (성능 검증)**: L2 정규화 적용 후, 기존과 동일한 데이터셋으로 테스트를 진행하여 정확도 개선 여부를 확인합니다. 필요시 `SIMILARITY_THRESHOLD` 값을 미세 조정합니다.
3.  **3단계 (장기 과제)**: 만약 L2 정규화만으로 목표 성능에 도달하지 못할 경우, `방안 3: SVM 분류기 도입`을 위한 데이터셋 구축 및 모델 학습을 장기 과제로 검토합니다.
