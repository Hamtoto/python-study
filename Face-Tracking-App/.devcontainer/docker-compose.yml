version: '3.8'

services:
  face-tracking-app:
    build:
      context: ..
      dockerfile: .devcontainer/Dockerfile
    
    # GPU 지원 활성화
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # 컨테이너 이름
    container_name: face-tracking-dev
    
    # 볼륨 마운트
    volumes:
      # 소스 코드 마운트
      - ..:/workspace:cached
      # Git 설정 유지
      - ~/.gitconfig:/home/developer/.gitconfig:ro
      # SSH 키 마운트 (선택사항)
      - ~/.ssh:/home/developer/.ssh:ro
      # Python 캐시 볼륨
      - python-cache:/home/developer/.cache
      # 출력 데이터 영구 보존
      - ./data:/workspace/videos:cached
      # 모델 캐시 볼륨
      - model-cache:/home/developer/.torch
    
    # 환경 변수
    environment:
      - DISPLAY=${DISPLAY:-:0}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
      - CUDA_VISIBLE_DEVICES=all
      # GPU 메모리 최적화
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - OMP_NUM_THREADS=8
      # 개발 모드
      - PYTHONPATH=/workspace
      - PYTHONDONTWRITEBYTECODE=1
    
    # 네트워크 설정
    network_mode: host
    
    # 특권 모드 (GPU 접근용)
    privileged: true
    
    # IPC 설정 (멀티프로세싱용)
    ipc: host
    
    # 메모리 제한 (선택사항)
    mem_limit: 32g
    memswap_limit: 32g
    
    # CPU 제한 (선택사항)
    cpus: '16'
    
    # 워킹 디렉토리
    working_dir: /workspace
    
    # 컨테이너 유지
    stdin_open: true
    tty: true
    
    # 헬스체크
    healthcheck:
      test: ["CMD", "python3", "-c", "import torch; import cv2; import facenet_pytorch; print('OK')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # 재시작 정책
    restart: unless-stopped
    
    # 로그 설정
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

# 명명된 볼륨
volumes:
  python-cache:
    driver: local
  model-cache:
    driver: local