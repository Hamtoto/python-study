# Face-Tracking-App 시스템 아키텍처 분석

## 현재 시스템 구조

### 1. 처리 파이프라인
1. **오디오 VAD**: FFmpeg 기반 음성 구간 감지
2. **얼굴 감지**: MTCNN + Producer-Consumer 패턴 (배치 256)
3. **요약본 생성**: FFmpeg 기반 고속 비디오 생성
4. **얼굴 인식**: FaceNet + Producer-Consumer 패턴 (배치 128)
5. **타겟 선택**: most_frequent 모드 기반 자동 선택
6. **비디오 트리밍**: FFmpeg 기반 고속 처리
7. **세그먼트 분할**: 병렬 FFmpeg 처리 (10초 단위)
8. **얼굴 크롭**: CPU 멀티프로세싱 기반 병렬 처리

### 2. 핵심 구성 요소

#### ModelManager (Singleton)
- MTCNN, FaceNet 모델 전역 관리
- GPU 메모리 풀(256 배치, 3x224x224) 사전 할당
- 모델 재생성 방지로 성능 향상

#### Producer-Consumer 패턴
- **Producer**: 비디오 프레임 I/O 전담 스레드
- **Consumer**: GPU 처리 전담 스레드  
- Queue 크기: 1024 (긴 영상 처리 최적화)
- 동적 배치 크기: Queue 깊이 기반 자동 조정

#### 병렬 처리 시스템
- **CPU 프로세스 풀**: FFmpeg 인코딩 병렬화
- **멀티프로세싱**: 세그먼트별 독립 처리
- **CUDA 스트림**: 4개 스트림 비동기 GPU 처리 (미사용)

### 3. 메모리 관리
- **GPU 메모리 풀**: 텐서 사전 할당으로 메모리 할당 오버헤드 제거
- **LRU 캐시**: 임베딩 벡터 효율적 관리 (15개, 30초 TTL)
- **스트림별 메모리**: 독립적인 메모리 풀 관리